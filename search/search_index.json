{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"about/","text":"Hi, My name is V\u0169 Quang Tr\u1ecdng, Code Inside Out is my personal blog in which I take notes about what I've learned, and what I'm interested in. I am working in Embedded Automotive field, mainly focusing on In Vehicle Infotainment (IVI) and Advanced Driver-Assistance Systems (ADAS). I also do some personal projects for my sweet home, and some others as my freelance jobs. I cannot remember all of them in details, so I need somewhere to write down, I also need them searchable to quickly jump to what I want. That's the reason for me to start blogging. Hope you can find something helpful here too. Let's code ^^ .md-typeset p { text-align: justify; }","title":"About"},{"location":"projects/","text":"I have published some of my projects on vuquangtrong , if you are interested, feel free to ask me for more details. Here are some featured ones: Blogging with Material for MkDocs is the theme I am using for this blog, which has some modification to support blogging like homepage, list of posts, and tags. Simplify Theme for Pelican static site generator. It was used for this blog once. VAcamera make use of Accord framework and FFMPEG engine to record video streams from 2 cameras and write output to mp4 files. Tiva C TM4C123G LaunchPad practice on ARM Cortext-M4F , contain Bring Up, Sensors, LCD, BootLoader and Firmware Update labs. SMS WebHub use a mobile phone to process commands from a VPS via websocket , include sending SMS, checking Balance, calling a number, forwarding messages Other Proof of Concept projects has prototypes for freelance projects I have done, as their source code are not allowed to be published","title":"Projects"},{"location":"tags/","text":"","title":"Tags"},{"location":"posts/","text":"","title":"Featured posts"},{"location":"posts/markdown/syntax/","text":"Metadata \u2693\ufe0e In a markdown file, if you add metadata in YAML format at the beginning of the file, it will be used to create page.meta object. Metadata is not shown in the page content, but it is used in rendering template to HTML. It is recommended to have at least 3 fields title , description , and tags , in each post. --- title : Lorem ipsum dolor sit amet description : Nullam urna elit, malesuada eget finibus ut, ac tortor. tags : - tag1 - tag2 --- Headings \u2693\ufe0e To create a heading, add number signs ( # ) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three ( <h3> ), use three number signs ( ### My Header level 3 ). Please remember to always put a space between the number signs and the heading name. Paragraphs \u2693\ufe0e Writing a paragraph is very straight forward. You just write down your sentences and they will be wrapped in <p> tags. To create paragraphs, use a blank line to separate one or more lines of text. To create a line break ( <br> ), end a line with two or more spaces, and then type return. You can add emphasis by making text bold or italic : To bold text, add two asterisks or underscores before and after a word or phrase To italicize text, add one asterisk or underscore before and after a word or phrase. To create a blockquote, add a > in front of a paragraph. Here is an example: Markdown: Paragraphs are the **building blocks** of papers. Many students define paragraphs in _terms of length_ : a paragraph is a group of at least five sentences, a paragraph is half a page long, etc. In reality, though, the __unity and coherence of ideas__ among sentences is what constitutes a paragraph. > excerpt from: _https://writingcenter.unc.edu/tips-and-tools/paragraphs_ Rendered: Paragraphs are the building blocks of papers. Many students define paragraphs in terms of length : a paragraph is a group of at least five sentences, a paragraph is half a page long, etc. In reality, though, the unity and coherence of ideas among sentences is what constitutes a paragraph. excerpt from: https://writingcenter.unc.edu/tips-and-tools/paragraphs Marks \u2693\ufe0e Beside standard marks to emphasize text as bold or italic , extended markdown supports some extra ways as below: Markdown: * ==This was marked== * ^^This was inserted^^ * ~~This was deleted~~ * H~2~0 * A^T^A Rendered: This was marked This was inserted This was deleted H 2 0 A T A List \u2693\ufe0e You can organize items into ordered and unordered lists. To create an ordered list, add line items with numbers followed by periods. The numbers don\u2019t have to be in numerical order, but the list should start with the number one. To create an unordered list, add dashes ( - ), asterisks ( * ), or plus signs ( + ) in front of line items. Indent one or more items to create a nested list. To create Task List, use checked box ( [ ] or [x] ) to show completed or uncompleted tasks. Markdown: 1. First item - Sub 1.1 - Sub 1.2 2. Second item * Sub 2.1 * Sub 2.2 3. Third item + Sub 3.1 + Sub 3.2 4. Fourth item 1. Sub 4.1 2. Sub 4.2 5. Task list * [x] Done * [ ] Not done yet Rendered: First item Sub 1.1 Sub 1.2 Second item Sub 2.1 Sub 2.2 Third item Sub 3.1 Sub 3.2 Fourth item Sub 4.1 Sub 4.2 Task list Done Not done yet Links \u2693\ufe0e To create a link, enclose the link text in brackets (e.g., [Google] ) and then follow it immediately with the URL in parentheses (e.g., (https://google.com) ). To quickly turn a URL or email address into a link, enclose it in angle brackets ( <> ). Markdown: [ Google ]( https://google.com ). <https://codeinsideout.com> <vuquangtrong@gmail.com> Rendered: Google https://codeinsideout.com vuquangtrong@gmail.com Reference-style links are a special kind of link that make URLs easier to display and read in Markdown. Reference-style links are constructed in two parts: the part you keep inline with your text and the part you store somewhere else in the file to keep the text easy to read. Markdown: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [ hobbit-hole ][ 1 ], and that means comfort. [ 1 ]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" Rendered: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole , and that means comfort. Images \u2693\ufe0e To add an image, add an exclamation mark ( ! ), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![ Image alt title ]( https://dummyimage.com/300x200 \"Image title\" ) Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image alt title Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image alt title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Admonitions \u2693\ufe0e Default title !!! note Default title Note Default title Custom title !!! tip \"Custom title\" Custom title Custom title Custom title No title !!! info \"\" No title No title No title More details More content !!! success Embedded code ``` python def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` in side Success Embedded code def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] in side Other types note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error bug example quote, cite Collapse \u2693\ufe0e Collapsed ??? note Details Note Details Expanded ???+ note Expanded details Note Expanded details Tables \u2693\ufe0e markdown: | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | | Column 1 | Column 2 | Column 3 | | :----------: | -------- | -------- | | expanded || expanded | | not expanded | | | | expanded | ~~| | | expanded | ~~ | | | expanded | a cell | | | _ _ | a cell | | | a cell | a cell | _ _ | rendered: Syntax Description Header Title Paragraph Text Syntax Description Test Text Header Title Here's this Paragraph Text And more Method Description GET Fetch resource PUT Update resource DELETE Delete resource Column 1 Column 2 Column 3 expanded expanded not expanded expanded expanded expanded a cell a cell a cell a cell Actions \u2693\ufe0e The KBD Extension is an inline processor for adding markdown syntax for inline <kbd> tags. Text that is wrapped in: double brackets [[button]] double braces {{menu}} or double parenthesis ((action)) will be wrapped with an HTML <kbd> tag with different classes. markdown: [[Ctrl]]+[[Alt]]+[[Del]] or [[Details]] ((Save)) or ((Run > Run As)) {{Double click}} or {{Long press}} rendered: Ctrl + Alt + Del or Details Save or Run > Run As Double click or Long press Code blocks \u2693\ufe0e Numbered ``` python linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighted ``` python linenums=\"1\" hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Inline The `#!python range()` function is used to generate a sequence of numbers. The `#!cpp int main(void)` function is the entry point of user application. The range () function is used to generate a sequence of numbers. The int main ( void ) function is the entry point of user application. Tabs \u2693\ufe0e markdown: === \"C\" ``` c #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } ``` === \"C++\" ``` c ++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } ``` rendered: C #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Footnotes \u2693\ufe0e Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ( [^1] ). Identifiers can be numbers or words, but they can\u2019t contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself \u2014 in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ( [^1] : My footnote.). You don\u2019t have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. Here's a simple footnote,[^1] and here's a longer one.[^bignote] [ ^1 ]: This is the first footnote. [ ^bignote ]: Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. `{ my code }` \\ Add as many paragraphs as you like. Here's a simple footnote, 1 and here's a longer one. 2 This is the first footnote. \u21a9 Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. { my code } Add as many paragraphs as you like. \u21a9","title":"Markdown Syntax"},{"location":"posts/markdown/syntax/#metadata","text":"In a markdown file, if you add metadata in YAML format at the beginning of the file, it will be used to create page.meta object. Metadata is not shown in the page content, but it is used in rendering template to HTML. It is recommended to have at least 3 fields title , description , and tags , in each post. --- title : Lorem ipsum dolor sit amet description : Nullam urna elit, malesuada eget finibus ut, ac tortor. tags : - tag1 - tag2 ---","title":"Metadata"},{"location":"posts/markdown/syntax/#headings","text":"To create a heading, add number signs ( # ) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three ( <h3> ), use three number signs ( ### My Header level 3 ). Please remember to always put a space between the number signs and the heading name.","title":"Headings"},{"location":"posts/markdown/syntax/#paragraphs","text":"Writing a paragraph is very straight forward. You just write down your sentences and they will be wrapped in <p> tags. To create paragraphs, use a blank line to separate one or more lines of text. To create a line break ( <br> ), end a line with two or more spaces, and then type return. You can add emphasis by making text bold or italic : To bold text, add two asterisks or underscores before and after a word or phrase To italicize text, add one asterisk or underscore before and after a word or phrase. To create a blockquote, add a > in front of a paragraph. Here is an example:","title":"Paragraphs"},{"location":"posts/markdown/syntax/#marks","text":"Beside standard marks to emphasize text as bold or italic , extended markdown supports some extra ways as below:","title":"Marks"},{"location":"posts/markdown/syntax/#list","text":"You can organize items into ordered and unordered lists. To create an ordered list, add line items with numbers followed by periods. The numbers don\u2019t have to be in numerical order, but the list should start with the number one. To create an unordered list, add dashes ( - ), asterisks ( * ), or plus signs ( + ) in front of line items. Indent one or more items to create a nested list. To create Task List, use checked box ( [ ] or [x] ) to show completed or uncompleted tasks.","title":"List"},{"location":"posts/markdown/syntax/#links","text":"To create a link, enclose the link text in brackets (e.g., [Google] ) and then follow it immediately with the URL in parentheses (e.g., (https://google.com) ). To quickly turn a URL or email address into a link, enclose it in angle brackets ( <> ).","title":"Links"},{"location":"posts/markdown/syntax/#images","text":"To add an image, add an exclamation mark ( ! ), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![ Image alt title ]( https://dummyimage.com/300x200 \"Image title\" ) Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image alt title Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image alt title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.","title":"Images"},{"location":"posts/markdown/syntax/#admonitions","text":"Default title !!! note Default title Note Default title Custom title !!! tip \"Custom title\" Custom title Custom title Custom title No title !!! info \"\" No title No title No title More details More content !!! success Embedded code ``` python def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` in side Success Embedded code def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] in side Other types note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error bug example quote, cite","title":"Admonitions"},{"location":"posts/markdown/syntax/#collapse","text":"Collapsed ??? note Details Note Details Expanded ???+ note Expanded details Note Expanded details","title":"Collapse"},{"location":"posts/markdown/syntax/#tables","text":"","title":"Tables"},{"location":"posts/markdown/syntax/#actions","text":"The KBD Extension is an inline processor for adding markdown syntax for inline <kbd> tags. Text that is wrapped in: double brackets [[button]] double braces {{menu}} or double parenthesis ((action)) will be wrapped with an HTML <kbd> tag with different classes.","title":"Actions"},{"location":"posts/markdown/syntax/#code-blocks","text":"Numbered ``` python linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighted ``` python linenums=\"1\" hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Inline The `#!python range()` function is used to generate a sequence of numbers. The `#!cpp int main(void)` function is the entry point of user application. The range () function is used to generate a sequence of numbers. The int main ( void ) function is the entry point of user application.","title":"Code blocks"},{"location":"posts/markdown/syntax/#tabs","text":"","title":"Tabs"},{"location":"posts/markdown/syntax/#footnotes","text":"Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ( [^1] ). Identifiers can be numbers or words, but they can\u2019t contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself \u2014 in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ( [^1] : My footnote.). You don\u2019t have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. Here's a simple footnote,[^1] and here's a longer one.[^bignote] [ ^1 ]: This is the first footnote. [ ^bignote ]: Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. `{ my code }` \\ Add as many paragraphs as you like. Here's a simple footnote, 1 and here's a longer one. 2 This is the first footnote. \u21a9 Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. { my code } Add as many paragraphs as you like. \u21a9","title":"Footnotes"},{"location":"posts/raspberrypi/backup_sdcard/","text":"Win32 Disk Imager \u2693\ufe0e Win32 Disk Images is a popular and famous application on Windows to clone or burn disk images. Download it from https://sourceforge.net/projects/win32diskimager and install it. Backup \u2693\ufe0e Select the Image File to save the SDCard content Select the source Device Click on Read Win32 Disk Imager: save device to image Restore \u2693\ufe0e Select the Image File of the SDCard content Select the target Device Click on Write Win32 Disk Imager: restore from image to device Acronis True Image \u2693\ufe0e This application is a commercial product, you can try it for free at https://www.acronis.com/en-us/products/true-image This application does not backup all bits on your SDCard, so its backup file is dependent on your actual data size. It also has incremental backup mode which only writes modified data hence it can save a lot of disk space. Acronis True Image: backup/restore disk","title":"Backup and Restore an SDCard"},{"location":"posts/raspberrypi/backup_sdcard/#win32-disk-imager","text":"Win32 Disk Images is a popular and famous application on Windows to clone or burn disk images. Download it from https://sourceforge.net/projects/win32diskimager and install it.","title":"Win32 Disk Imager"},{"location":"posts/raspberrypi/backup_sdcard/#backup","text":"Select the Image File to save the SDCard content Select the source Device Click on Read Win32 Disk Imager: save device to image","title":"Backup"},{"location":"posts/raspberrypi/backup_sdcard/#restore","text":"Select the Image File of the SDCard content Select the target Device Click on Write Win32 Disk Imager: restore from image to device","title":"Restore"},{"location":"posts/raspberrypi/backup_sdcard/#acronis-true-image","text":"This application is a commercial product, you can try it for free at https://www.acronis.com/en-us/products/true-image This application does not backup all bits on your SDCard, so its backup file is dependent on your actual data size. It also has incremental backup mode which only writes modified data hence it can save a lot of disk space. Acronis True Image: backup/restore disk","title":"Acronis True Image"},{"location":"posts/raspberrypi/check_camera_i2c/","text":"Camera is not detected! I bought 2 Pi Cameras, one is working, but the other is not . vcgencmd get_camera printed out supported=1 detected=0 then I didn't think that the plat ribbon cable was loosen. I swapped the camera module, the working one was detected successfully while the failure one was not detected in any way. I googled and found this interesting posts: Camera not detected despite being plugged in on official Raspberry forum . At the end of this post, 6by9 , an engineer from Raspberry Pi showed a method to check the connection to Camera board and Camera Sensor via I2C interface. 1. Install I2C tools \u2693\ufe0e I need to install some tools to work on I2C bus. Here it comes i2c-tools for Linux: sudo apt-get install i2c-tools This package contains a heterogeneous set of I2C tools for Linux: a bus probing tool, a chip dumper, register-level access helpers, EEPROM decoding scripts, and more. i2cdetect detect I2C chips i2cdump examine I2C registers i2cget read from I2C/SMBus chip registers i2cset set I2C registers i2ctransfer send user-defined I2C messages in one transfer 2. Load I2C driver \u2693\ufe0e You can permanently enable I2C interface by running sudo raspi-config or adding i2c-dev to /etc/modules , but I just need a quick check so I enable I2C by loading driver: sudo modprobe i2c-dev Enable I2C Interface via raspi-config 3. Config GPIOs \u2693\ufe0e GPIO pin number Please look at this document for more understanding about setting GPIOs: https://www.raspberrypi.org/documentation/configuration/config-txt/gpio.md . Note that GPIO number is defined in BCM2835 ARM processor, not the number printed on Pi boards. Read more at https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf You can use raspi-gpio get to get the current status of GPIOs Change GPIO 0 and GPIO 1 to input, by default they are set to SDA0 and SCL0 raspi-gpio set 0 ip raspi-gpio set 1 ip Make sure GPIO 28 is SDA0 , GPIO 29 is SCL0 by setting Alternate Function 0 (A0) on those pins. raspi-gpio set 28 a0 raspi-gpio set 29 a0 Power on Camera by setting High on output pins GPIO 44 and GPIO 45 raspi-gpio set 44 dh raspi-gpio set 40 dh 4. Scan for attached I2C \u2693\ufe0e Run i2cdetect on I2C BUS 0 /dev/i2c-0 : i2cdetect 0 press Y to continue and it should print out: 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: 10 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- 64 -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- Consider that i2cdetect tries to ping every address on a network and reports whether they respond. If you see any number shown in report, it means there is an device at that address. Camera's I2C addresses If you see 0x64 , your camera board is connected properly, there is no problem with your cable and connectors. If you see 0x10 , it means your camera sensor responded. If there is no 0x10 , your sensor either fails or the little connector between the camera module to the sensor has become detached. In my case, there was only 0x64 address responded, even I have checked the sensor's connector again, it did not show any sign of a working sensor . Poor me! I have to call the Pi retailer.","title":"Diagnostic I2C connection with Pi Camera"},{"location":"posts/raspberrypi/check_camera_i2c/#1-install-i2c-tools","text":"I need to install some tools to work on I2C bus. Here it comes i2c-tools for Linux: sudo apt-get install i2c-tools This package contains a heterogeneous set of I2C tools for Linux: a bus probing tool, a chip dumper, register-level access helpers, EEPROM decoding scripts, and more. i2cdetect detect I2C chips i2cdump examine I2C registers i2cget read from I2C/SMBus chip registers i2cset set I2C registers i2ctransfer send user-defined I2C messages in one transfer","title":"1. Install I2C tools"},{"location":"posts/raspberrypi/check_camera_i2c/#2-load-i2c-driver","text":"You can permanently enable I2C interface by running sudo raspi-config or adding i2c-dev to /etc/modules , but I just need a quick check so I enable I2C by loading driver: sudo modprobe i2c-dev Enable I2C Interface via raspi-config","title":"2. Load I2C driver"},{"location":"posts/raspberrypi/check_camera_i2c/#3-config-gpios","text":"GPIO pin number Please look at this document for more understanding about setting GPIOs: https://www.raspberrypi.org/documentation/configuration/config-txt/gpio.md . Note that GPIO number is defined in BCM2835 ARM processor, not the number printed on Pi boards. Read more at https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf You can use raspi-gpio get to get the current status of GPIOs Change GPIO 0 and GPIO 1 to input, by default they are set to SDA0 and SCL0 raspi-gpio set 0 ip raspi-gpio set 1 ip Make sure GPIO 28 is SDA0 , GPIO 29 is SCL0 by setting Alternate Function 0 (A0) on those pins. raspi-gpio set 28 a0 raspi-gpio set 29 a0 Power on Camera by setting High on output pins GPIO 44 and GPIO 45 raspi-gpio set 44 dh raspi-gpio set 40 dh","title":"3. Config GPIOs"},{"location":"posts/raspberrypi/check_camera_i2c/#4-scan-for-attached-i2c","text":"Run i2cdetect on I2C BUS 0 /dev/i2c-0 : i2cdetect 0 press Y to continue and it should print out: 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: 10 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- 64 -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- Consider that i2cdetect tries to ping every address on a network and reports whether they respond. If you see any number shown in report, it means there is an device at that address. Camera's I2C addresses If you see 0x64 , your camera board is connected properly, there is no problem with your cable and connectors. If you see 0x10 , it means your camera sensor responded. If there is no 0x10 , your sensor either fails or the little connector between the camera module to the sensor has become detached. In my case, there was only 0x64 address responded, even I have checked the sensor's connector again, it did not show any sign of a working sensor . Poor me! I have to call the Pi retailer.","title":"4. Scan for attached I2C"},{"location":"posts/raspberrypi/compile_ffmpeg/","text":"If you want to use the latest version of FFMPEG with new features or new libraries, you can download FFMPEG and its packages manually and compile it on your Raspberry Pi. Pre-built FFMPEG in Raspbian OS The FFMPEG package in Raspbian OS is built with H264 Hardware Acceleration already, you just need to download it from the distribution repositories. sudo apt install ffmpeg -y and then check the encoder for h264_omx : ffmpeg -hide_banner -encoders | grep omx which should print out: V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) The pi_streaming_setup script \u2693\ufe0e Thank cdgriffith for this awesome script There are many guides published on the internet but I found pi_streaming_setup of cdgriffith is very easy to follow. This script is designed to help automate turning a raspberry pi with a compatible video4linux2 camera into a MPEG-DASH / HLS streaming server. The steps it will attempt to take: * Install FFmpeg OR (optional) Compile and Install FFmpeg ( with h264 hardware acceleration and nonfree libraries) * Install nginx for DASH / HLS OR install RTSP server if desired * (DASH/HLS) Update rc.local to run required setup script on reboot * (DASH/HLS) Create index.html file to view video stream * Create systemd service and enable it This script requires Python 3.6+ The usage of this script is simple and clear, but I am only interested about options to compile ffmpeg. --compile-ffmpeg --compile-only Compile FFMPEG \u2693\ufe0e I need to clone a git repo, so I have to install git , of course ^^. sudo apt-get install git then pi_streaming_setup from github: git clone https://github.com/cdgriffith/pi_streaming_setup.git Go into the script's folder cd pi_streaming_setup and finally, run the script with sudo and python3 as user pi : sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi This will take about 4~5 hours, so I am better to go to sleep now :) Test compiled ffmpeg \u2693\ufe0e After the compilation finishes, reboot your Pi, and when it's booted up, run below command to check compiled tool: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG)","title":"Compile FFMPEG with Hardware Acceleration"},{"location":"posts/raspberrypi/compile_ffmpeg/#the-pi_streaming_setup-script","text":"Thank cdgriffith for this awesome script There are many guides published on the internet but I found pi_streaming_setup of cdgriffith is very easy to follow. This script is designed to help automate turning a raspberry pi with a compatible video4linux2 camera into a MPEG-DASH / HLS streaming server. The steps it will attempt to take: * Install FFmpeg OR (optional) Compile and Install FFmpeg ( with h264 hardware acceleration and nonfree libraries) * Install nginx for DASH / HLS OR install RTSP server if desired * (DASH/HLS) Update rc.local to run required setup script on reboot * (DASH/HLS) Create index.html file to view video stream * Create systemd service and enable it This script requires Python 3.6+ The usage of this script is simple and clear, but I am only interested about options to compile ffmpeg. --compile-ffmpeg --compile-only","title":"The pi_streaming_setup script"},{"location":"posts/raspberrypi/compile_ffmpeg/#compile-ffmpeg","text":"I need to clone a git repo, so I have to install git , of course ^^. sudo apt-get install git then pi_streaming_setup from github: git clone https://github.com/cdgriffith/pi_streaming_setup.git Go into the script's folder cd pi_streaming_setup and finally, run the script with sudo and python3 as user pi : sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi This will take about 4~5 hours, so I am better to go to sleep now :)","title":"Compile FFMPEG"},{"location":"posts/raspberrypi/compile_ffmpeg/#test-compiled-ffmpeg","text":"After the compilation finishes, reboot your Pi, and when it's booted up, run below command to check compiled tool: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG)","title":"Test compiled ffmpeg"},{"location":"posts/raspberrypi/monitor_usage/","text":"The final script Download monitor.sh then save this file to ~/monitor.sh . Add below line to ~/.bashrc : source monitor.sh Usage: monitor title command params ... Example: monitor test ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 Install gnuplot if you want to see the result on graphical drawings. sudo apt-get install gnuplot This post is written as a walk through guide to help you understand about how the script is built. Export a function in bash \u2693\ufe0e Writing a function in bash script is very easy, as you only need to define the function name and its body, you even don't need to declare its params. myfunc.sh #!/bin/bash myfunc () { echo \"Params: $@ \" } export -f myfunc If you run source myfunc.sh , you can use the function myfunc as a normal program, such as myfunc param1 param2 . All params are implicit saved into local macros, such as the first, the second, and the n-th param are saved into $1 , $2 , ..., $n , and the total of param is saved in $# . Here is the list of basic macros: Macro Description $BASHPID Process ID of the current instance of Bash. This is not the same as the $$ variable, but it often gives the same result. $PPID Process ID of the parent process $$ Process ID of the script itself $! Process ID of last job run in background $PWD The directory you are in at the time $FUNCNAME Name of the current function, effective inside a function only $SECONDS The number of seconds the script has been running $1 , $2 , $n The first, the second and the n-th param $# The number of command-line arguments $* All of the positional parameters, seen as a single word, must be quoted $@ Same as $* , but each parameter is a quoted string, that is, the parameters are passed on intact, without interpretation or expansion. This means, among other things, that each parameter in the argument list is seen as a separate word $? Exit status of a command, function, or the script itself Read more in chapter Advanced Bash-Scripting Guide: 9.1. Internal Variables One more thing about Grouping Commands Bash provides two ways to group a list of commands to be executed as a unit. When commands are grouped, re-directions may be applied to the entire command list. For example, the output of all the commands in the list may be redirected to a single stream. ( list ) Placing a list of commands between parentheses causes a sub-shell environment to be created (see Command Execution Environment), and each of the commands in list to be executed in that sub-shell. Since the list is executed in a sub-shell, variable assignments do not remain in effect after the sub-shell completes. { list; } Placing a list of commands between curly braces causes the list to be executed in the current shell context. No sub-shell is created. The semicolon (or newline) following list is required. In addition to the creation of a sub-shell, there is a subtle difference between these two constructs due to historical reasons. The braces are reserved words, so they must be separated from the list by blanks or other shell meta-characters. The parentheses are operators, and are recognized as separate tokens by the shell even if they are not separated from the list by whitespace. The exit status of both of these constructs is the exit status of list. OK, let's start to create a new script Run a process and monitor it \u2693\ufe0e I need a script to run a process with its params, monitor that process to detect when it is running. The function is created with parentheses () to run in a sub-shell. monitor.sh #!/bin/bash monitor () ( # run process in background echo \"Executing $* \" $* & # get PID of last job in background pid = $! echo \"Executed in PID: $pid \" ps --no-headers -p $pid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do # use ps to get cpu and memory usage ps --no-headers -o '%cpu,%mem' -p $pid sleep 1 done ) export -f monitor top and ps CPU Usage report \u2693\ufe0e When I check the CPU usage using top and ps , I see a big different in the returned values, so that I have to dig deeper into how they work. ps \u2693\ufe0e Using ps to get the CPU and Memory usage is not exactly what I am looking for. In the NOTES section in man ps , there a small note: CPU usage is currently expressed as the percentage of time spent running during the entire lifetime of a process. This is not ideal, and it does not conform to the standards that ps otherwise conforms to. CPU usage is unlikely to add up to exactly 100%. It means ps does not show the instant CPU usage at the time I run ps , it shows an average CPU usage over the lifetime of the process. top \u2693\ufe0e Check the manual for top , I see a description for %CPU report: %CPU -- CPU Usage The task's share of the elapsed CPU time since the last screen update, expressed as a percentage of total CPU time So, it means if I set 1 second interval for top , it will report CPU usage for the last 1 second . That is what I want. Let's check top 's options -b : Batch-mode operation Starts top in Batch mode, which could be useful for sending output from top to other programs or to a file. In this mode, top will not accept input and runs until the iterations limit you've set with the `-n' command-line option or until killed. -d : Delay-time interval as: -d ss.t (secs.tenths) Specifies the delay between screen updates, and overrides the corresponding value in one's personal configuration file or the startup default. Later this can be changed with the d or s interactive commands. -p : Monitor-PIDs mode as: -pN1 -pN2 ... or -pN1,N2,N3 ... Monitor only processes with specified process IDs. OK, I switch to use top and grep to get the report line of the process. monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process top -b -d 1 -p $pid & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Example of result: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 top - 02:59:46 up 23:37, 1 user, load average: 0.15, 0.10, 0.04 Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie % Cpu ( s ) : 21 .0 us, 34 .0 sy, 0 .0 ni, 25 .0 id, 16 .0 wa, 0 .0 hi, 4 .0 si, 0 .0 st MiB Mem : 241.7 total, 136.9 free, 32.7 used, 72.1 buff/cache MiB Swap: 100.0 total, 89.2 free, 10.8 used. 161.3 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg frame= 29 fps= 24 q=-0.0 size= 0kB time=00:00:00.83 bitrate= 0.5kbits/s dup=23 drop=0 speed=0.702x The output from top is not good, because it has many unuseful data for me, what I need are %CPU and %MEM , so I have to filter the output of top . That comes a place for grep and awk . Export data with grep and awk \u2693\ufe0e grep manual: https://www.gnu.org/software/grep/manual/grep.html awk manual: https://www.gnu.org/software/gawk/manual/gawk.html First, I need to extract lines similar to: 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg so I use grep to extract them with keyword being pid number: top -b -d 1 -p $pid | grep $pid & Then I need to cut out 2 columns: %CPU and %MEM from the line after the grep command. By default, awk use space(s) to detect columns, so I count the column number for those 2 values: %CPU at 9th column, and %MEM at top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines # use awk to extract data columns top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Surprisingly, there is no output for CPU and MEM usage reported in the output. monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 CPU MEM Input #0, video4linux2,v4l2, from '/dev/video0': Duration: N/A, start: 456.466868, bitrate: 283115 kb/s Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 1024x768, 283115 kb/s, 30 fps, 30 tbr, 1000k tbn, 1000k tbc Stream mapping: Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (h264_omx)) Press [q] to stop, [?] for help [h264_omx @ 0x1fdc330] Using OMX.broadcom.video_encode Output #0, mp4, to 'test.mp4': Metadata: encoder : Lavf58.64.100 Stream #0:0: Video: h264 (h264_omx) (avc1 / 0x31637661), yuv420p(progressive), 1024x768, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc Metadata: encoder : Lavc58.114.100 h264_omx frame= 300 fps= 30 q=-0.0 Lsize= 264kB time=00:00:09.96 bitrate= 216.9kbits/s dup=250 drop=0 speed=0.984x video:262kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.793225% Line buffered mode \u2693\ufe0e When using pipeline of commands, there is pipeline buffer between them. The output from grep is no longer line buffered but block buffered, usually the block is 4KB, leading to the problem that the next awk cannot see new data immediately on its input. Using man grep , I see that --line-buffered Use line buffering on output. This can cause a performance penalty. and using man awk , I also see that: -W interactive sets un-buffered writes to stdout and line buffered reads from stdin. Records from stdin are lines regardless of the value of RS. Well, combining them together and testing again, I can see the CPU and MEM usage reported. monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data column, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 CPU MEM 20.0 0.8 21.0 3.5 67.3 5.1 89.1 6.0 77.2 9.4 Input #0, video4linux2,v4l2, from '/dev/video0': Duration: N/A, start: 216.047338, bitrate: 283115 kb/s Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 1024x768, 283115 kb/s, 30 fps, 30 tbr, 1000k tbn, 1000k tbc Stream mapping: Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (h264_omx)) Press [q] to stop, [?] for help 45.5 27.5 [h264_omx @ 0x2d53330] Using OMX.broadcom.video_encode Output #0, mp4, to 'test.mp4': Metadata: encoder : Lavf58.64.100 Stream #0:0: Video: h264 (h264_omx) (avc1 / 0x31637661), yuv420p(progressive), 1024x768, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc Metadata: encoder : Lavc58.114.100 h264_omx 16.2 28.423 fps=0.0 q=-0.0 size= 0kB time=00:00:00.63 bitrate= 0.6kbits/s dup=18 drop=0 speed=1.09x 30.7 28.849 fps= 30 q=-0.0 size= 0kB time=00:00:01.50 bitrate= 0.3kbits/s dup=39 drop=0 speed=0.931x 11.8 28.889 fps= 32 q=-0.0 size= 0kB time=00:00:02.83 bitrate= 0.1kbits/s dup=72 drop=0 speed=1.02x 10.8 28.817 fps= 31 q=-0.0 size= 0kB time=00:00:03.76 bitrate= 0.1kbits/s dup=95 drop=0 speed=0.997x 14.3 28.949 fps= 31 q=-0.0 size= 0kB time=00:00:04.83 bitrate= 0.1kbits/s dup=121 drop=0 speed=1.01x 11.9 28.986 fps= 31 q=-0.0 size= 0kB time=00:00:06.06 bitrate= 0.1kbits/s dup=151 drop=0 speed=1.01x 15.7 28.914 fps= 30 q=-0.0 size= 0kB time=00:00:07.00 bitrate= 0.1kbits/s dup=174 drop=0 speed=0.996x 13.9 28.930 fps= 30 q=-0.0 size= 0kB time=00:00:07.53 bitrate= 0.1kbits/s dup=187 drop=0 speed=0.994x 16.8 28.965 fps= 30 q=-0.0 size= 256kB time=00:00:08.70 bitrate= 241.1kbits/s dup=216 drop=0 speed=0.991x frame= 300 fps= 30 q=-0.0 size= 307kB time=00:00:09.96 bitrate= 252.1kbits/s dup=245 drop=0 speed=1.01x video:305kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.681766% 15.5 28.9 22.8 14.3 Save log while printing out with tee \u2693\ufe0e I want to save the log of the process and the resource usage for later use, but still want to see them printed out in terminal. Here tee comes to do that. Checking man tee , I know that it's very easy to use tee - read from standard input and write to standard output and files then I can use it in my monitor script $* | tee log.txt & top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & and here is the modified script: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and what I got are an empty log.txt file, and an usage.txt log with 0% CPU Usage (which should be about 22% to 99% as shown in previous test). I must have done something wrong! I add some debug line to ps -p $pid to check the process ID monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee > usage.txt & # save top PID to control it toppid = $! ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 Then, it prints out the PID of tee , not the PID of ffmpeg or top . PID TTY TIME CMD 647 pts/0 00:00:00 tee PID TTY TIME CMD 652 pts/0 00:00:00 tee The problem of empty log file, I can see it is caused by ffmpeg prints output on STDERR(2) not on STDOUT(1) so when I create a pipe to tee , only STDOUT(1) is piped. To fix this, I just need to redirect ffmpeg STDERR(2) to STDOUT(1): $* 2 > & 1 | tee log.txt & Get PID of a process in pipeline \u2693\ufe0e Move to the problem of getting wrong PID, in bash, pipeline cause commands to run in sub-shells, for example, $* | tee > log.txt & will run $* in a sub-shell, tee > log.txt will run in background and its PID will be saved in the macro $! . To save the PID of the command $* , I have to do that in the sub-shell in which $* is executed. However, I cannot transfer variable to the main function as it is limited in bash shells, so I save PID to a file. Here is the modified code for save and load pid: # save to pid.txt ( $* 2 > & 1 & echo $! > pid.txt ) | tee > log.txt & # load from pid.txt pid = $( <pid.txt ) then apply into the script: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & # get PID of last job in background pid = $( <pid.txt ) ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $( <pid.txt ) ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and I get correct PID for ffmpeg and top . PID TTY TIME CMD 2352 pts/0 00:00:00 ffmpeg PID TTY TIME CMD 2360 pts/0 00:00:00 top Visualize resource usage with gnuplot \u2693\ufe0e GnuPlot Gnuplot is a portable command-line driven graphing utility for Linux, OS/2, MS Windows, OSX, VMS, and many other platforms. It can produce many different types of output, including terminal and file. I have seen many example of using gnuplot to visualize data, therefore, I would like to have resource usage in graphical format. I have the usage.txt and then I can use it as the input for gnuplot : Terminal output \u2693\ufe0e gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" PNG Image output \u2693\ufe0e gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \" then the script is updated as: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & sleep 1 # get PID of last job in background pid = $( <pid.txt ) # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) \\ | grep --line-buffered $pid \\ | awk -W interactive '{print $9, $10}' \\ | tee usage.txt & sleep 1 # save top PID to control it toppid = $( <pid.txt ) echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt # draw gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" ) export -f monitor It prints out a good graph in terminal and PNG image: monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" 100 +--------------------------------------------------------------------+ | *** + + + + + | 90 |-+ * % CPU *******-| | ** MEM ####### | 80 |-+ +-| | * | 70 |-+ * +-| | * | 60 |-+ * +-| | * | 50 |-+ * +-| | * | 40 |-+ * +-| | * | 30 |-+ ######################################################### | | # * | 20 |-+ ## * +-| | # ****** ************************* | 10 |-+ # ********* ******| | ###### + + + + + | 0 +--------------------------------------------------------------------+ 0 2 4 6 8 10 12 Resource Usage Use template for naming commands \u2693\ufe0e I need to test some different commands, so the output should be saved into different filenames. Let's modify the script to accept params in this format monitor \"title\" \"command\" by extracting those params at the beginning of the script monitor () ( # extract params title = $1 command = ${ @: 2 } # get params from the 2nd one I will put all log into a subfolder named $title , so create I also change the output of awk to print out in CPU= X MEM= Y format: awk -W interactive '{printf \"CPU= %d MEM= %d\\n\", $9, $10}' which leads to change the data column index in gnuplot : # *-usage.txt content: # CPU= X MEM= Y # X is at 2nd column, # Y is at 4th column gnuplot -e \" \\ set term dumb; \\ plot \\ ' ${ title } / ${ title } -usage.txt' using 2 title '%CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \" But the output of ffmpeg is overwritten by CPU and MEM usage as below: CPU= 80 MEM= 26=0.0 q=-1.0 size= 1792kB time=00:00:01.59 bitrate=9177.0kbits/s speed=3.16x CPU= 42 MEM= 25= 53 q=-1.0 size= 3072kB time=00:00:02.59 bitrate=9681.1kbits/s speed=1.72x CPU= 9 MEM= 25s= 44 q=-1.0 size= 4352kB time=00:00:03.63 bitrate=9814.3kbits/s speed=1.44x Therefore, I have to tweak the output from awk to write in new line: awk -W interactive '{printf \"\\nCPU= %d MEM= %d\\n\", $9, $10}' and filter empty lines before saving them to usage.txt : tee > ( grep CPU > \" ${ title } / ${ title } _usage.txt\" ) & And here it is The final script \u2693\ufe0e monitor.sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 #!/bin/bash # vuquangtrong@gmail.com # # usage: # monitor \"title\" \"command\" # example # monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" # monitor () ( # extract params title = $1 command = ${ @: 2 } # get params from the 2nd one # create result folder if not existed [ ! -d $title ] && mkdir $title # measure execution time start = $SECONDS # run command in background ( $command 2 > & 1 & echo $! > pid.txt ) | tee \" ${ title } / ${ title } _log.txt\" & sleep 1 # get command's PID of last job in background pid = $( <pid.txt ) # use top to monitor the process # use grep to catch useful lines, using line buffered mode to send output in lines # use awk to extract data columns, reading input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) \\ | grep --line-buffered $pid \\ | awk -W interactive '{printf \"\\nCPU= %d MEM= %d\\n\", $9, $10}' \\ | tee > ( grep CPU > \" ${ title } / ${ title } _usage.txt\" ) & sleep 1 # save top's PID to control it toppid = $( <pid.txt ) # check if the command is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt # output average data, exclude sleeping time echo -e \"\\nTotal time: $(( $SECONDS - $start - 3 )) seconds\" cat \" ${ title } / ${ title } _usage.txt\" \\ | awk '\\ { sum1 += $2; sum2 += $4; n++} \\ END { printf \"Average: CPU= %d MEM= %d\\n\", sum1/n, sum2/n} \\ ' # draw to terminal gnuplot -e \" \\ set term dumb; \\ set yrange [0:100]; \\ plot \\ ' ${ title } / ${ title } _usage.txt' using 2 title 'CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \" # export to image gnuplot -e \" \\ set term png size 640, 480; \\ set output ' ${ title } / ${ title } _usage.png'; \\ set yrange [0:100]; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ ' ${ title } / ${ title } _usage.txt' using 2 title 'CPU' with lines lw 2, \\ '' using 4 title 'MEM' with lines lw 2 \\ \" ) export -f monitor","title":"Measure CPU and Memory usage of a process"},{"location":"posts/raspberrypi/monitor_usage/#export-a-function-in-bash","text":"Writing a function in bash script is very easy, as you only need to define the function name and its body, you even don't need to declare its params. myfunc.sh #!/bin/bash myfunc () { echo \"Params: $@ \" } export -f myfunc If you run source myfunc.sh , you can use the function myfunc as a normal program, such as myfunc param1 param2 . All params are implicit saved into local macros, such as the first, the second, and the n-th param are saved into $1 , $2 , ..., $n , and the total of param is saved in $# . Here is the list of basic macros: Macro Description $BASHPID Process ID of the current instance of Bash. This is not the same as the $$ variable, but it often gives the same result. $PPID Process ID of the parent process $$ Process ID of the script itself $! Process ID of last job run in background $PWD The directory you are in at the time $FUNCNAME Name of the current function, effective inside a function only $SECONDS The number of seconds the script has been running $1 , $2 , $n The first, the second and the n-th param $# The number of command-line arguments $* All of the positional parameters, seen as a single word, must be quoted $@ Same as $* , but each parameter is a quoted string, that is, the parameters are passed on intact, without interpretation or expansion. This means, among other things, that each parameter in the argument list is seen as a separate word $? Exit status of a command, function, or the script itself Read more in chapter Advanced Bash-Scripting Guide: 9.1. Internal Variables One more thing about Grouping Commands Bash provides two ways to group a list of commands to be executed as a unit. When commands are grouped, re-directions may be applied to the entire command list. For example, the output of all the commands in the list may be redirected to a single stream. ( list ) Placing a list of commands between parentheses causes a sub-shell environment to be created (see Command Execution Environment), and each of the commands in list to be executed in that sub-shell. Since the list is executed in a sub-shell, variable assignments do not remain in effect after the sub-shell completes. { list; } Placing a list of commands between curly braces causes the list to be executed in the current shell context. No sub-shell is created. The semicolon (or newline) following list is required. In addition to the creation of a sub-shell, there is a subtle difference between these two constructs due to historical reasons. The braces are reserved words, so they must be separated from the list by blanks or other shell meta-characters. The parentheses are operators, and are recognized as separate tokens by the shell even if they are not separated from the list by whitespace. The exit status of both of these constructs is the exit status of list. OK, let's start to create a new script","title":"Export a function in bash"},{"location":"posts/raspberrypi/monitor_usage/#run-a-process-and-monitor-it","text":"I need a script to run a process with its params, monitor that process to detect when it is running. The function is created with parentheses () to run in a sub-shell. monitor.sh #!/bin/bash monitor () ( # run process in background echo \"Executing $* \" $* & # get PID of last job in background pid = $! echo \"Executed in PID: $pid \" ps --no-headers -p $pid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do # use ps to get cpu and memory usage ps --no-headers -o '%cpu,%mem' -p $pid sleep 1 done ) export -f monitor","title":"Run a process and monitor it"},{"location":"posts/raspberrypi/monitor_usage/#top-and-ps-cpu-usage-report","text":"When I check the CPU usage using top and ps , I see a big different in the returned values, so that I have to dig deeper into how they work.","title":"top and ps CPU Usage report"},{"location":"posts/raspberrypi/monitor_usage/#ps","text":"Using ps to get the CPU and Memory usage is not exactly what I am looking for. In the NOTES section in man ps , there a small note: CPU usage is currently expressed as the percentage of time spent running during the entire lifetime of a process. This is not ideal, and it does not conform to the standards that ps otherwise conforms to. CPU usage is unlikely to add up to exactly 100%. It means ps does not show the instant CPU usage at the time I run ps , it shows an average CPU usage over the lifetime of the process.","title":"ps"},{"location":"posts/raspberrypi/monitor_usage/#top","text":"Check the manual for top , I see a description for %CPU report: %CPU -- CPU Usage The task's share of the elapsed CPU time since the last screen update, expressed as a percentage of total CPU time So, it means if I set 1 second interval for top , it will report CPU usage for the last 1 second . That is what I want. Let's check top 's options -b : Batch-mode operation Starts top in Batch mode, which could be useful for sending output from top to other programs or to a file. In this mode, top will not accept input and runs until the iterations limit you've set with the `-n' command-line option or until killed. -d : Delay-time interval as: -d ss.t (secs.tenths) Specifies the delay between screen updates, and overrides the corresponding value in one's personal configuration file or the startup default. Later this can be changed with the d or s interactive commands. -p : Monitor-PIDs mode as: -pN1 -pN2 ... or -pN1,N2,N3 ... Monitor only processes with specified process IDs. OK, I switch to use top and grep to get the report line of the process. monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process top -b -d 1 -p $pid & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Example of result: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 top - 02:59:46 up 23:37, 1 user, load average: 0.15, 0.10, 0.04 Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie % Cpu ( s ) : 21 .0 us, 34 .0 sy, 0 .0 ni, 25 .0 id, 16 .0 wa, 0 .0 hi, 4 .0 si, 0 .0 st MiB Mem : 241.7 total, 136.9 free, 32.7 used, 72.1 buff/cache MiB Swap: 100.0 total, 89.2 free, 10.8 used. 161.3 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg frame= 29 fps= 24 q=-0.0 size= 0kB time=00:00:00.83 bitrate= 0.5kbits/s dup=23 drop=0 speed=0.702x The output from top is not good, because it has many unuseful data for me, what I need are %CPU and %MEM , so I have to filter the output of top . That comes a place for grep and awk .","title":"top"},{"location":"posts/raspberrypi/monitor_usage/#export-data-with-grep-and-awk","text":"grep manual: https://www.gnu.org/software/grep/manual/grep.html awk manual: https://www.gnu.org/software/gawk/manual/gawk.html First, I need to extract lines similar to: 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg so I use grep to extract them with keyword being pid number: top -b -d 1 -p $pid | grep $pid & Then I need to cut out 2 columns: %CPU and %MEM from the line after the grep command. By default, awk use space(s) to detect columns, so I count the column number for those 2 values: %CPU at 9th column, and %MEM at top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines # use awk to extract data columns top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Surprisingly, there is no output for CPU and MEM usage reported in the output. monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 CPU MEM Input #0, video4linux2,v4l2, from '/dev/video0': Duration: N/A, start: 456.466868, bitrate: 283115 kb/s Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 1024x768, 283115 kb/s, 30 fps, 30 tbr, 1000k tbn, 1000k tbc Stream mapping: Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (h264_omx)) Press [q] to stop, [?] for help [h264_omx @ 0x1fdc330] Using OMX.broadcom.video_encode Output #0, mp4, to 'test.mp4': Metadata: encoder : Lavf58.64.100 Stream #0:0: Video: h264 (h264_omx) (avc1 / 0x31637661), yuv420p(progressive), 1024x768, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc Metadata: encoder : Lavc58.114.100 h264_omx frame= 300 fps= 30 q=-0.0 Lsize= 264kB time=00:00:09.96 bitrate= 216.9kbits/s dup=250 drop=0 speed=0.984x video:262kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.793225%","title":"Export data with grep and awk"},{"location":"posts/raspberrypi/monitor_usage/#line-buffered-mode","text":"When using pipeline of commands, there is pipeline buffer between them. The output from grep is no longer line buffered but block buffered, usually the block is 4KB, leading to the problem that the next awk cannot see new data immediately on its input. Using man grep , I see that --line-buffered Use line buffering on output. This can cause a performance penalty. and using man awk , I also see that: -W interactive sets un-buffered writes to stdout and line buffered reads from stdin. Records from stdin are lines regardless of the value of RS. Well, combining them together and testing again, I can see the CPU and MEM usage reported. monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data column, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 CPU MEM 20.0 0.8 21.0 3.5 67.3 5.1 89.1 6.0 77.2 9.4 Input #0, video4linux2,v4l2, from '/dev/video0': Duration: N/A, start: 216.047338, bitrate: 283115 kb/s Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 1024x768, 283115 kb/s, 30 fps, 30 tbr, 1000k tbn, 1000k tbc Stream mapping: Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (h264_omx)) Press [q] to stop, [?] for help 45.5 27.5 [h264_omx @ 0x2d53330] Using OMX.broadcom.video_encode Output #0, mp4, to 'test.mp4': Metadata: encoder : Lavf58.64.100 Stream #0:0: Video: h264 (h264_omx) (avc1 / 0x31637661), yuv420p(progressive), 1024x768, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc Metadata: encoder : Lavc58.114.100 h264_omx 16.2 28.423 fps=0.0 q=-0.0 size= 0kB time=00:00:00.63 bitrate= 0.6kbits/s dup=18 drop=0 speed=1.09x 30.7 28.849 fps= 30 q=-0.0 size= 0kB time=00:00:01.50 bitrate= 0.3kbits/s dup=39 drop=0 speed=0.931x 11.8 28.889 fps= 32 q=-0.0 size= 0kB time=00:00:02.83 bitrate= 0.1kbits/s dup=72 drop=0 speed=1.02x 10.8 28.817 fps= 31 q=-0.0 size= 0kB time=00:00:03.76 bitrate= 0.1kbits/s dup=95 drop=0 speed=0.997x 14.3 28.949 fps= 31 q=-0.0 size= 0kB time=00:00:04.83 bitrate= 0.1kbits/s dup=121 drop=0 speed=1.01x 11.9 28.986 fps= 31 q=-0.0 size= 0kB time=00:00:06.06 bitrate= 0.1kbits/s dup=151 drop=0 speed=1.01x 15.7 28.914 fps= 30 q=-0.0 size= 0kB time=00:00:07.00 bitrate= 0.1kbits/s dup=174 drop=0 speed=0.996x 13.9 28.930 fps= 30 q=-0.0 size= 0kB time=00:00:07.53 bitrate= 0.1kbits/s dup=187 drop=0 speed=0.994x 16.8 28.965 fps= 30 q=-0.0 size= 256kB time=00:00:08.70 bitrate= 241.1kbits/s dup=216 drop=0 speed=0.991x frame= 300 fps= 30 q=-0.0 size= 307kB time=00:00:09.96 bitrate= 252.1kbits/s dup=245 drop=0 speed=1.01x video:305kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.681766% 15.5 28.9 22.8 14.3","title":"Line buffered mode"},{"location":"posts/raspberrypi/monitor_usage/#save-log-while-printing-out-with-tee","text":"I want to save the log of the process and the resource usage for later use, but still want to see them printed out in terminal. Here tee comes to do that. Checking man tee , I know that it's very easy to use tee - read from standard input and write to standard output and files then I can use it in my monitor script $* | tee log.txt & top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & and here is the modified script: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and what I got are an empty log.txt file, and an usage.txt log with 0% CPU Usage (which should be about 22% to 99% as shown in previous test). I must have done something wrong! I add some debug line to ps -p $pid to check the process ID monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee > usage.txt & # save top PID to control it toppid = $! ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 Then, it prints out the PID of tee , not the PID of ffmpeg or top . PID TTY TIME CMD 647 pts/0 00:00:00 tee PID TTY TIME CMD 652 pts/0 00:00:00 tee The problem of empty log file, I can see it is caused by ffmpeg prints output on STDERR(2) not on STDOUT(1) so when I create a pipe to tee , only STDOUT(1) is piped. To fix this, I just need to redirect ffmpeg STDERR(2) to STDOUT(1): $* 2 > & 1 | tee log.txt &","title":"Save log while printing out with tee"},{"location":"posts/raspberrypi/monitor_usage/#get-pid-of-a-process-in-pipeline","text":"Move to the problem of getting wrong PID, in bash, pipeline cause commands to run in sub-shells, for example, $* | tee > log.txt & will run $* in a sub-shell, tee > log.txt will run in background and its PID will be saved in the macro $! . To save the PID of the command $* , I have to do that in the sub-shell in which $* is executed. However, I cannot transfer variable to the main function as it is limited in bash shells, so I save PID to a file. Here is the modified code for save and load pid: # save to pid.txt ( $* 2 > & 1 & echo $! > pid.txt ) | tee > log.txt & # load from pid.txt pid = $( <pid.txt ) then apply into the script: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & # get PID of last job in background pid = $( <pid.txt ) ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $( <pid.txt ) ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and I get correct PID for ffmpeg and top . PID TTY TIME CMD 2352 pts/0 00:00:00 ffmpeg PID TTY TIME CMD 2360 pts/0 00:00:00 top","title":"Get PID of a process in pipeline"},{"location":"posts/raspberrypi/monitor_usage/#visualize-resource-usage-with-gnuplot","text":"GnuPlot Gnuplot is a portable command-line driven graphing utility for Linux, OS/2, MS Windows, OSX, VMS, and many other platforms. It can produce many different types of output, including terminal and file. I have seen many example of using gnuplot to visualize data, therefore, I would like to have resource usage in graphical format. I have the usage.txt and then I can use it as the input for gnuplot :","title":"Visualize resource usage with gnuplot"},{"location":"posts/raspberrypi/monitor_usage/#terminal-output","text":"gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \"","title":"Terminal output"},{"location":"posts/raspberrypi/monitor_usage/#png-image-output","text":"gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \" then the script is updated as: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & sleep 1 # get PID of last job in background pid = $( <pid.txt ) # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) \\ | grep --line-buffered $pid \\ | awk -W interactive '{print $9, $10}' \\ | tee usage.txt & sleep 1 # save top PID to control it toppid = $( <pid.txt ) echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt # draw gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" ) export -f monitor It prints out a good graph in terminal and PNG image: monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" 100 +--------------------------------------------------------------------+ | *** + + + + + | 90 |-+ * % CPU *******-| | ** MEM ####### | 80 |-+ +-| | * | 70 |-+ * +-| | * | 60 |-+ * +-| | * | 50 |-+ * +-| | * | 40 |-+ * +-| | * | 30 |-+ ######################################################### | | # * | 20 |-+ ## * +-| | # ****** ************************* | 10 |-+ # ********* ******| | ###### + + + + + | 0 +--------------------------------------------------------------------+ 0 2 4 6 8 10 12 Resource Usage","title":"PNG Image output"},{"location":"posts/raspberrypi/monitor_usage/#use-template-for-naming-commands","text":"I need to test some different commands, so the output should be saved into different filenames. Let's modify the script to accept params in this format monitor \"title\" \"command\" by extracting those params at the beginning of the script monitor () ( # extract params title = $1 command = ${ @: 2 } # get params from the 2nd one I will put all log into a subfolder named $title , so create I also change the output of awk to print out in CPU= X MEM= Y format: awk -W interactive '{printf \"CPU= %d MEM= %d\\n\", $9, $10}' which leads to change the data column index in gnuplot : # *-usage.txt content: # CPU= X MEM= Y # X is at 2nd column, # Y is at 4th column gnuplot -e \" \\ set term dumb; \\ plot \\ ' ${ title } / ${ title } -usage.txt' using 2 title '%CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \" But the output of ffmpeg is overwritten by CPU and MEM usage as below: CPU= 80 MEM= 26=0.0 q=-1.0 size= 1792kB time=00:00:01.59 bitrate=9177.0kbits/s speed=3.16x CPU= 42 MEM= 25= 53 q=-1.0 size= 3072kB time=00:00:02.59 bitrate=9681.1kbits/s speed=1.72x CPU= 9 MEM= 25s= 44 q=-1.0 size= 4352kB time=00:00:03.63 bitrate=9814.3kbits/s speed=1.44x Therefore, I have to tweak the output from awk to write in new line: awk -W interactive '{printf \"\\nCPU= %d MEM= %d\\n\", $9, $10}' and filter empty lines before saving them to usage.txt : tee > ( grep CPU > \" ${ title } / ${ title } _usage.txt\" ) & And here it is","title":"Use template for naming commands"},{"location":"posts/raspberrypi/monitor_usage/#the-final-script","text":"monitor.sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 #!/bin/bash # vuquangtrong@gmail.com # # usage: # monitor \"title\" \"command\" # example # monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" # monitor () ( # extract params title = $1 command = ${ @: 2 } # get params from the 2nd one # create result folder if not existed [ ! -d $title ] && mkdir $title # measure execution time start = $SECONDS # run command in background ( $command 2 > & 1 & echo $! > pid.txt ) | tee \" ${ title } / ${ title } _log.txt\" & sleep 1 # get command's PID of last job in background pid = $( <pid.txt ) # use top to monitor the process # use grep to catch useful lines, using line buffered mode to send output in lines # use awk to extract data columns, reading input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) \\ | grep --line-buffered $pid \\ | awk -W interactive '{printf \"\\nCPU= %d MEM= %d\\n\", $9, $10}' \\ | tee > ( grep CPU > \" ${ title } / ${ title } _usage.txt\" ) & sleep 1 # save top's PID to control it toppid = $( <pid.txt ) # check if the command is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt # output average data, exclude sleeping time echo -e \"\\nTotal time: $(( $SECONDS - $start - 3 )) seconds\" cat \" ${ title } / ${ title } _usage.txt\" \\ | awk '\\ { sum1 += $2; sum2 += $4; n++} \\ END { printf \"Average: CPU= %d MEM= %d\\n\", sum1/n, sum2/n} \\ ' # draw to terminal gnuplot -e \" \\ set term dumb; \\ set yrange [0:100]; \\ plot \\ ' ${ title } / ${ title } _usage.txt' using 2 title 'CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \" # export to image gnuplot -e \" \\ set term png size 640, 480; \\ set output ' ${ title } / ${ title } _usage.png'; \\ set yrange [0:100]; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ ' ${ title } / ${ title } _usage.txt' using 2 title 'CPU' with lines lw 2, \\ '' using 4 title 'MEM' with lines lw 2 \\ \" ) export -f monitor","title":"The final script"},{"location":"posts/raspberrypi/save_power/","text":"Turn off USB \u2693\ufe0e Turn OFF USB chip echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/unbind Turn ON USB chip echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/bind Turn off HDMI \u2693\ufe0e Turn OFF HDMI output sudo /opt/vc/bin/tvservice -o Turn ON HDMI output sudo /opt/vc/bin/tvservice -p Throttle CPU \u2693\ufe0e Reduce the clock of the core by changing some parameters in the /boot/config.txt file: /boot/config.txt arm_freq_min = 250 core_freq_min = 100 sdram_freq_min = 150 over_voltage_min = 0 Disable Wi-Fi & Bluetooth \u2693\ufe0e Starting from Raspberry Pi 3, Wifi and Bluetooth are added on hardware, so Raspbian has its method to control these signals in config.txt file: /boot/config.txt dtoverlay = pi3-disable-wifi dtoverlay = pi3-disable-bt It's correct to use the word pi3 in the params's value. Softblock The rfkill command can be used to softblock the wireless connections: rfkill list # displays the state of the modules rfkill block wifi rfkill block bluetooth but this does not turn the hardware of the WiFi and the Bluetooth module off. They will still draw a little power in the background although the connections are cut. Disable on-board LEDs \u2693\ufe0e /boot/config.txt dtparam = act_led_trigger=none dtparam = act_led_activelow=on","title":"Save Power on Raspberry Pi"},{"location":"posts/raspberrypi/save_power/#turn-off-usb","text":"Turn OFF USB chip echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/unbind Turn ON USB chip echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/bind","title":"Turn off USB"},{"location":"posts/raspberrypi/save_power/#turn-off-hdmi","text":"Turn OFF HDMI output sudo /opt/vc/bin/tvservice -o Turn ON HDMI output sudo /opt/vc/bin/tvservice -p","title":"Turn off HDMI"},{"location":"posts/raspberrypi/save_power/#throttle-cpu","text":"Reduce the clock of the core by changing some parameters in the /boot/config.txt file: /boot/config.txt arm_freq_min = 250 core_freq_min = 100 sdram_freq_min = 150 over_voltage_min = 0","title":"Throttle CPU"},{"location":"posts/raspberrypi/save_power/#disable-wi-fi--bluetooth","text":"Starting from Raspberry Pi 3, Wifi and Bluetooth are added on hardware, so Raspbian has its method to control these signals in config.txt file: /boot/config.txt dtoverlay = pi3-disable-wifi dtoverlay = pi3-disable-bt It's correct to use the word pi3 in the params's value. Softblock The rfkill command can be used to softblock the wireless connections: rfkill list # displays the state of the modules rfkill block wifi rfkill block bluetooth but this does not turn the hardware of the WiFi and the Bluetooth module off. They will still draw a little power in the background although the connections are cut.","title":"Disable Wi-Fi &amp; Bluetooth"},{"location":"posts/raspberrypi/save_power/#disable-on-board-leds","text":"/boot/config.txt dtparam = act_led_trigger=none dtparam = act_led_activelow=on","title":"Disable on-board LEDs"},{"location":"posts/raspberrypi/setup_camera/","text":"This tutorial is for setting up the official Raspberry Pi Camera which is attached with a CSI cable. Other types of USB Camera should work on RPi out-of-the-box. RaspberryPi Camera Module Enable Camera module \u2693\ufe0e Run raspi-config configuration tool: sudo raspi-config Go to Interfacing Options > Camera > Yes This method does the same thing with setting up start_x = 1 in /boot/config.txt raspi-config You can use raspi-config , which is a Raspberry Pi configuration command-line tool, to enable or disable some features in RPi OS. This tool requires root permission, therefore, you have to run it with sudo . User interface of raspi-config Increase GPU memory \u2693\ufe0e In the raspi-config configuration tool: sudo raspi-config Go to Performance Options > GPU Memory > fill in 256 and select OK This method does the same thing with setting up gpu_mem = 256 in /boot/config.txt Test Camera \u2693\ufe0e You can detect the camera connection by running a checking tool vcgencmd get_camera which should print out supported = 1 detected=1 to tell you that your camera is supported and connected. vcgencmd vcgencmd is a command line utility that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. You can check more detail in Raspberry Pi/vcgencmd Raspicam commands has a set of tools to work with the camera module: raspistill , raspivid , and raspiyuv . Capture an image: raspistill -o cam.jpg Record an video: raspivid -o vid.h264 Video for Linux 2 - v4l2 \u2693\ufe0e Under Linux, the standard API for cameras (including web cams) is V4L (Video for Linux), and a number of applications have been written that support any camera with a V4L driver. An independent developer has now written a user space V4L driver for the Raspberry Pi camera but it is closed sourced, and can be a little slow because it runs as a user program rather than a kernel driver. Recognizing that a V4L driver is needed, the Raspberry Pi Foundation reported that they were working with Broadcom to develop an official kernel V4L driver. As a kernel driver, it should be faster than the user space driver. Finally, V4L2 was release under the name bcm2835-v4l2 which is included in to Raspbian OS by default. You can use v4l2-ctl utility tool to capture from your camera too. List devices \u2693\ufe0e v4l2-ctl --list-devices bcm2835-codec-decode (platform:bcm2835-codec): /dev/video10 /dev/video11 /dev/video12 bcm2835-isp (platform:bcm2835-isp): /dev/video13 /dev/video14 /dev/video15 /dev/video16 mmal service 16.1 (platform:bcm2835-v4l2): /dev/video0 Driver info \u2693\ufe0e v4l2-ctl -d /dev/video0 --all Driver Info: Driver name : bm2835 mmal Card type : mmal service 16.1 Bus info : platform:bcm2835-v4l2 Driver version : 5.4.79 Capabilities : 0x85200005 Video Capture Video Overlay Read/Write Streaming Extended Pix Format Device Capabilities Device Caps : 0x05200005 Video Capture Video Overlay Read/Write Streaming Extended Pix Format Priority: 2 Video input : 0 (Camera 0: ok) Format Video Capture: Width/Height : 1024/768 Pixel Format : 'JPEG' (JFIF JPEG) Field : None Bytes per Line : 0 Size Image : 786432 Colorspace : JPEG Transfer Function : Default (maps to sRGB) YCbCr/HSV Encoding: Default (maps to ITU-R 601) Quantization : Default (maps to Full Range) Flags : Format Video Overlay: Left/Top : 150/50 Width/Height: 1024/768 Field : None Chroma Key : 0x00000000 Global Alpha: 0xff Clip Count : 0 Clip Bitmap : No Framebuffer Format: Capability : Extern Overlay Global Alpha Flags : Overlay Matches Capture/Output Size Width : 1024 Height : 768 Pixel Format : 'YU12' Streaming Parameters Video Capture: Capabilities : timeperframe Frames per second: 30.000 (30000/1000) Read buffers : 1 User Controls brightness 0x00980900 (int) : min=0 max=100 step=1 default=50 value=50 flags=slider contrast 0x00980901 (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider saturation 0x00980902 (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider red_balance 0x0098090e (int) : min=1 max=7999 step=1 default=1000 value=1000 flags=slider blue_balance 0x0098090f (int) : min=1 max=7999 step=1 default=1000 value=1000 flags=slider horizontal_flip 0x00980914 (bool) : default=0 value=0 vertical_flip 0x00980915 (bool) : default=0 value=0 power_line_frequency 0x00980918 (menu) : min=0 max=3 default=1 value=1 sharpness 0x0098091b (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider color_effects 0x0098091f (menu) : min=0 max=15 default=0 value=0 rotate 0x00980922 (int) : min=0 max=360 step=90 default=0 value=0 flags=modify-layout color_effects_cbcr 0x0098092a (int) : min=0 max=65535 step=1 default=32896 value=32896 Codec Controls video_bitrate_mode 0x009909ce (menu) : min=0 max=1 default=0 value=0 flags=update video_bitrate 0x009909cf (int) : min=25000 max=25000000 step=25000 default=10000000 value=10000000 repeat_sequence_header 0x009909e2 (bool) : default=0 value=0 h264_i_frame_period 0x00990a66 (int) : min=0 max=2147483647 step=1 default=60 value=60 h264_level 0x00990a67 (menu) : min=0 max=11 default=11 value=11 h264_profile 0x00990a6b (menu) : min=0 max=4 default=4 value=4 Camera Controls auto_exposure 0x009a0901 (menu) : min=0 max=3 default=0 value=0 exposure_time_absolute 0x009a0902 (int) : min=1 max=10000 step=1 default=1000 value=1000 exposure_dynamic_framerate 0x009a0903 (bool) : default=0 value=0 auto_exposure_bias 0x009a0913 (intmenu): min=0 max=24 default=12 value=12 white_balance_auto_preset 0x009a0914 (menu) : min=0 max=10 default=1 value=1 image_stabilization 0x009a0916 (bool) : default=0 value=0 iso_sensitivity 0x009a0917 (intmenu): min=0 max=4 default=0 value=0 iso_sensitivity_auto 0x009a0918 (menu) : min=0 max=1 default=1 value=1 exposure_metering_mode 0x009a0919 (menu) : min=0 max=2 default=0 value=0 scene_mode 0x009a091a (menu) : min=0 max=13 default=0 value=0 JPEG Compression Controls compression_quality 0x009d0903 (int) : min=1 max=100 step=1 default=30 value=30 Supported formats \u2693\ufe0e v4l2-ctl --list-formats ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) [1]: 'YUYV' (YUYV 4:2:2) [2]: 'RGB3' (24-bit RGB 8-8-8) [3]: 'JPEG' (JFIF JPEG, compressed) [4]: 'H264' (H.264, compressed) [5]: 'MJPG' (Motion-JPEG, compressed) [6]: 'YVYU' (YVYU 4:2:2) [7]: 'VYUY' (VYUY 4:2:2) [8]: 'UYVY' (UYVY 4:2:2) [9]: 'NV12' (Y/CbCr 4:2:0) [10]: 'BGR3' (24-bit BGR 8-8-8) [11]: 'YV12' (Planar YVU 4:2:0) [12]: 'NV21' (Y/CrCb 4:2:0) [13]: 'RX24' (32-bit XBGR 8-8-8-8) Please take a note for RGB3 , JPEG , H264 , and MJPEG , which can be used in OpenCV, Streaming directly. Capture JPEG Image \u2693\ufe0e v4l2-ctl --set-fmt-video = width = 2592 ,height = 1944 ,pixelformat = 3 v4l2-ctl --stream-mmap = 3 --stream-count = 1 --stream-to = somefile.jpg Record H264 Video \u2693\ufe0e Note the value height= 1088 , not 1080 v4l2-ctl --set-fmt-video = width = 1920 ,height = 1088 ,pixelformat = 4 v4l2-ctl --stream-mmap = 3 --stream-count = 100 --stream-to = somefile.264 Install ffmpeg \u2693\ufe0e The pre-built ffmpeg package of RPi already enable hardware accelerator support, with OpenMAX IL H.264 video encoder ( h264_omx ). sudo apt-get install ffmpeg -y Compile FFMPEG Manual In case you want FFMPEG with a specific library, you can compile FFMPEG manually by following this topic Compile FFMPEG with Hardware Accelerator Encoders \u2693\ufe0e To see all availabe encoders, you can run ffmpeg -encoders Encoders: V..... = Video A..... = Audio S..... = Subtitle .F.... = Frame-level multithreading ..S... = Slice-level multithreading ...X.. = Codec is experimental ....B. = Supports draw_horiz_band .....D = Supports direct rendering method 1 ------ V..... a64multi Multicolor charset for Commodore 64 (codec a64_multi) V..... a64multi5 Multicolor charset for Commodore 64, extended with 5th color (colram) (codec a64_multi5) V..... alias_pix Alias/Wavefront PIX image V..... amv AMV Video V..... apng APNG (Animated Portable Network Graphics) image V..... asv1 ASUS V1 V..... asv2 ASUS V2 V..X.. libaom-av1 libaom AV1 (codec av1) V..... avrp Avid 1:1 10-bit RGB Packer V..X.. avui Avid Meridien Uncompressed V..... ayuv Uncompressed packed MS 4:4:4:4 V..... bmp BMP (Windows and OS/2 bitmap) V..... libxavs libxavs Chinese AVS (Audio Video Standard) (codec cavs) VF.... cfhd GoPro CineForm HD V..... cinepak Cinepak V..... cljr Cirrus Logic AccuPak V.S... vc2 SMPTE VC-2 (codec dirac) VFS... dnxhd VC3/DNxHD V..... dpx DPX (Digital Picture Exchange) image VFS... dvvideo DV (Digital Video) V.S... ffv1 FFmpeg video codec #1 VF.... ffvhuff Huffyuv FFmpeg variant V..... fits Flexible Image Transport System V..... flashsv Flash Screen Video V..... flashsv2 Flash Screen Video Version 2 V..... flv FLV / Sorenson Spark / Sorenson H.263 (Flash Video) (codec flv1) V..... gif GIF (Graphics Interchange Format) V..... h261 H.261 V..... h263 H.263 / H.263-1996 V..... h263_v4l2m2m V4L2 mem2mem H.263 encoder wrapper (codec h263) V.S... h263p H.263+ / H.263-1998 / H.263 version 2 V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) V..... hap Vidvox Hap V..... libx265 libx265 H.265 / HEVC (codec hevc) V..... hevc_v4l2m2m V4L2 mem2mem HEVC encoder wrapper (codec hevc) V..... libkvazaar libkvazaar H.265 / HEVC (codec hevc) VF.... huffyuv Huffyuv / HuffYUV V..... jpeg2000 JPEG 2000 VF.... libopenjpeg OpenJPEG JPEG 2000 (codec jpeg2000) VF.... jpegls JPEG-LS VF.... ljpeg Lossless JPEG VF.... magicyuv MagicYUV video VFS... mjpeg MJPEG (Motion JPEG) V.S... mpeg1video MPEG-1 video V.S... mpeg2video MPEG-2 video V.S... mpeg4 MPEG-4 part 2 V..... libxvid libxvidcore MPEG-4 part 2 (codec mpeg4) V..... mpeg4_omx OpenMAX IL MPEG-4 video encoder (codec mpeg4) V..... mpeg4_v4l2m2m V4L2 mem2mem MPEG4 encoder wrapper (codec mpeg4) V..... msmpeg4v2 MPEG-4 part 2 Microsoft variant version 2 V..... msmpeg4 MPEG-4 part 2 Microsoft variant version 3 (codec msmpeg4v3) V..... msvideo1 Microsoft Video-1 V..... pam PAM (Portable AnyMap) image V..... pbm PBM (Portable BitMap) image V..... pcx PC Paintbrush PCX image V..... pgm PGM (Portable GrayMap) image V..... pgmyuv PGMYUV (Portable GrayMap YUV) image VF.... png PNG (Portable Network Graphics) image V..... ppm PPM (Portable PixelMap) image VF.... prores Apple ProRes VF.... prores_aw Apple ProRes (codec prores) VFS... prores_ks Apple ProRes (iCodec Pro) (codec prores) V..... qtrle QuickTime Animation (RLE) video V..... r10k AJA Kona 10-bit RGB Codec V..... r210 Uncompressed RGB 10-bit V..... rawvideo raw video V..... roqvideo id RoQ video (codec roq) V..... rpza QuickTime video (RPZA) V..... rv10 RealVideo 1.0 V..... rv20 RealVideo 2.0 V..... sgi SGI image V..... snow Snow V..... speedhq NewTek SpeedHQ V..... sunrast Sun Rasterfile image V..... svq1 Sorenson Vector Quantizer 1 / Sorenson Video 1 / SVQ1 V..... targa Truevision Targa image V..... libtheora libtheora Theora (codec theora) VF.... tiff TIFF image VF.... utvideo Ut Video V..... v210 Uncompressed 4:2:2 10-bit V..... v308 Uncompressed packed 4:4:4 V..... v408 Uncompressed packed QT 4:4:4:4 V..... v410 Uncompressed 4:4:4 10-bit V..... libvpx libvpx VP8 (codec vp8) V..... vp8_v4l2m2m V4L2 mem2mem VP8 encoder wrapper (codec vp8) V..... libvpx-vp9 libvpx VP9 (codec vp9) V..... libwebp_anim libwebp WebP image (codec webp) V..... libwebp libwebp WebP image (codec webp) V..... wmv1 Windows Media Video 7 V..... wmv2 Windows Media Video 8 V..... wrapped_avframe AVFrame to AVPacket passthrough V..... xbm XBM (X BitMap) image V..... xface X-face image V..... xwd XWD (X Window Dump) image V..... y41p Uncompressed YUV 4:1:1 12-bit V..... yuv4 Uncompressed packed 4:2:0 VF.... zlib LCL (LossLess Codec Library) ZLIB V..... zmbv Zip Motion Blocks Video A..... aac AAC (Advanced Audio Coding) A..... libfdk_aac Fraunhofer FDK AAC (codec aac) A..... ac3 ATSC A/52A (AC-3) A..... ac3_fixed ATSC A/52A (AC-3) (codec ac3) A..... adpcm_adx SEGA CRI ADX ADPCM A..... adpcm_argo ADPCM Argonaut Games A..... g722 G.722 ADPCM (codec adpcm_g722) A..... g726 G.726 ADPCM (codec adpcm_g726) A..... g726le G.726 little endian ADPCM (\"right-justified\") (codec adpcm_g726le) A..... adpcm_ima_alp ADPCM IMA High Voltage Software ALP A..... adpcm_ima_amv ADPCM IMA AMV A..... adpcm_ima_apm ADPCM IMA Ubisoft APM A..... adpcm_ima_qt ADPCM IMA QuickTime A..... adpcm_ima_ssi ADPCM IMA Simon & Schuster Interactive A..... adpcm_ima_wav ADPCM IMA WAV A..... adpcm_ms ADPCM Microsoft A..... adpcm_swf ADPCM Shockwave Flash A..... adpcm_yamaha ADPCM Yamaha A..... alac ALAC (Apple Lossless Audio Codec) A..... libopencore_amrnb OpenCORE AMR-NB (Adaptive Multi-Rate Narrow-Band) (codec amr_nb) A..... libvo_amrwbenc Android VisualOn AMR-WB (Adaptive Multi-Rate Wide-Band) (codec amr_wb) A..... aptx aptX (Audio Processing Technology for Bluetooth) A..... aptx_hd aptX HD (Audio Processing Technology for Bluetooth) A..... libcodec2 codec2 encoder using libcodec2 (codec codec2) A..... comfortnoise RFC 3389 comfort noise generator A..X.. dca DCA (DTS Coherent Acoustics) (codec dts) A..... eac3 ATSC A/52 E-AC-3 A..... flac FLAC (Free Lossless Audio Codec) A..... g723_1 G.723.1 A..... libgsm libgsm GSM (codec gsm) A..... libgsm_ms libgsm GSM Microsoft variant (codec gsm_ms) A..X.. mlp MLP (Meridian Lossless Packing) A..... mp2 MP2 (MPEG audio layer 2) A..... mp2fixed MP2 fixed point (MPEG audio layer 2) (codec mp2) A..... libtwolame libtwolame MP2 (MPEG audio layer 2) (codec mp2) A..... libmp3lame libmp3lame MP3 (MPEG audio layer 3) (codec mp3) A..... libshine libshine MP3 (MPEG audio layer 3) (codec mp3) A..... nellymoser Nellymoser Asao A..X.. opus Opus A..... libopus libopus Opus (codec opus) A..... pcm_alaw PCM A-law / G.711 A-law A..... pcm_dvd PCM signed 16|20|24-bit big-endian for DVD media A..... pcm_f32be PCM 32-bit floating point big-endian A..... pcm_f32le PCM 32-bit floating point little-endian A..... pcm_f64be PCM 64-bit floating point big-endian A..... pcm_f64le PCM 64-bit floating point little-endian A..... pcm_mulaw PCM mu-law / G.711 mu-law A..... pcm_s16be PCM signed 16-bit big-endian A..... pcm_s16be_planar PCM signed 16-bit big-endian planar A..... pcm_s16le PCM signed 16-bit little-endian A..... pcm_s16le_planar PCM signed 16-bit little-endian planar A..... pcm_s24be PCM signed 24-bit big-endian A..... pcm_s24daud PCM D-Cinema audio signed 24-bit A..... pcm_s24le PCM signed 24-bit little-endian A..... pcm_s24le_planar PCM signed 24-bit little-endian planar A..... pcm_s32be PCM signed 32-bit big-endian A..... pcm_s32le PCM signed 32-bit little-endian A..... pcm_s32le_planar PCM signed 32-bit little-endian planar A..... pcm_s64be PCM signed 64-bit big-endian A..... pcm_s64le PCM signed 64-bit little-endian A..... pcm_s8 PCM signed 8-bit A..... pcm_s8_planar PCM signed 8-bit planar A..... pcm_u16be PCM unsigned 16-bit big-endian A..... pcm_u16le PCM unsigned 16-bit little-endian A..... pcm_u24be PCM unsigned 24-bit big-endian A..... pcm_u24le PCM unsigned 24-bit little-endian A..... pcm_u32be PCM unsigned 32-bit big-endian A..... pcm_u32le PCM unsigned 32-bit little-endian A..... pcm_u8 PCM unsigned 8-bit A..... pcm_vidc PCM Archimedes VIDC A..... real_144 RealAudio 1.0 (14.4K) (codec ra_144) A..... roq_dpcm id RoQ DPCM A..X.. s302m SMPTE 302M A..... sbc SBC (low-complexity subband codec) A..X.. sonic Sonic A..X.. sonicls Sonic lossless A..... libspeex libspeex Speex (codec speex) A..X.. truehd TrueHD A..... tta TTA (True Audio) A..X.. vorbis Vorbis A..... libvorbis libvorbis (codec vorbis) A..... wavpack WavPack A..... wmav1 Windows Media Audio 1 A..... wmav2 Windows Media Audio 2 S..... ssa ASS (Advanced SubStation Alpha) subtitle (codec ass) S..... ass ASS (Advanced SubStation Alpha) subtitle S..... dvbsub DVB subtitles (codec dvb_subtitle) S..... dvdsub DVD subtitles (codec dvd_subtitle) S..... mov_text 3GPP Timed Text subtitle S..... srt SubRip subtitle (codec subrip) S..... subrip SubRip subtitle S..... text Raw text subtitle S..... webvtt WebVTT subtitle S..... xsub DivX subtitles (XSUB) If you're interested in h264 and mjpeg , you can use grep to search for the specific encoders ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG) Check encoder options Before using an encoder, you can check its options by help command in ffmpeg . For example: ffmpeg -h encoder = h264_omx Encoder h264_omx [OpenMAX IL H.264 video encoder]: General capabilities: delay Threading capabilities: none Supported pixel formats: yuv420p h264_omx AVOptions: -omx_libname <string> ED.V...... OpenMAX library name -omx_libprefix <string> ED.V...... OpenMAX library prefix -zerocopy <int> E..V...... Try to avoid copying input frames if possible (from 0 to 1) (default 1) -profile <int> E..V...... Set the encoding profile (from -99 to 100) (default -99) baseline 66 E..V...... main 77 E..V...... high 100 E..V...... Measure performance \u2693\ufe0e Next, we will try to record some short video (60 seconds) with H264 format using different encoders. For measuring the performance, we use a small tool to check CPU and Memory Usage in monitor - Script to check performance Video side: 1024x768 Framerate: 30 fps Input Length: 60 seconds Note that ffmpeg uses v4l2 driver! Raw to MJPEG (.avi) \u2693\ufe0e ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v mjpeg \\ raw_mjpeg.avi Performance: Total time: 63 seconds Average CPU: 93 (too high) Average MEM: 31 Input FPS: 4.8 (dropped input) Output FPS: 30 Quality: Format : JPEG Codec ID : MJPG Bit rate : 839 kb/s Raw to MJPEG Raw to H264_OMX @8Mbps (.mp4) \u2693\ufe0e ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx.mp4 Performance: Total time: 63 seconds Average CPU: 16 (OK) Average MEM: 27 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GOP: M=1, N=12) Codec ID : avc1 Bit rate : 2 877 kb/s Raw to H264_OMX @8Mbps Raw to H264_V4L2M2M @8Mbps (.mp4) \u2693\ufe0e ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_v4l2m2m \\ -b:v 8M \\ raw_h264v4l2m2m.mp4 Performance: Total time: 62 seconds Average CPU: 23 Average MEM: 27 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 1 783 kb/s Raw to H264_V4L2M2M @8Mbps V4L2 MJPEG direct copy (.avi) \u2693\ufe0e ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format mjpeg \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ mjpeg_avi.avi Performance: Total time: 67 seconds Average CPU: 10 (Good) Average MEM: 21 Input FPS: 30 Output FPS: 30 Quality: Format : JPEG Codec ID : MJPG Bit rate : 10.2 Mb/s (very high bandwidth) Save V4L2 MJPEG strem V4L2 H264 direct copy (.mp4) \u2693\ufe0e ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ h264_mp4.mp4 Performance: Total time: 67 seconds Average CPU: 10 (Good) Average MEM: 24 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 5 506 kb/s (OK) Save V4L2 H264 stream After above tests, I could say that using compressed input format from v4l2 is much more effective than compressing by an encoder. Let's add some timestamp to video by using drawtext filter with built-in expandable localtime variable http://ffmpeg.org/ffmpeg-filters.html#Text-expansion . ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx_text.mp4 Filtering and streamcopy cannot be used together # this will not work ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -input_format h264 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v copy \\ -t 10 \\ h264_mp4_text.mp4 Install picamera \u2693\ufe0e picamera is a pure Python interface to the Raspberry Pi camera module for Python 2.7 (or above) or Python 3.2 (or above). Homepage: https://picamera.readthedocs.io/en/latest/install.html . If you are using the Raspbian distro, you probably have picamera installed by default. You can find out simply by starting Python and trying to import picamera: python -c \"import picamera\" python3 -c \"import picamera\" If you don\u2019t have picamera installed you\u2019ll see something that reports no module named picamera. To install picamera on Raspbian, it is best to use the system\u2019s package manager: sudo apt-get install python-picamera python3-picamera There are a lot of example in the official guide of Picamera at https://picamera.readthedocs.io/en/latest/recipes1.html Get maximum resolution of your camera: import picamera with picamera . PiCamera () as cam : print ( cam . MAX_RESOLUTION ) Take a snapshot: from time import sleep from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) # camera warm-up time sleep ( 2 ) # capture an image camera . capture ( 'snapshot.jpg' ) Record a 60 second video from camera and measure resource usage with monitor , then use ffmpeg to convert raw h264 to mp4. Picamera H264 (.h264) \u2693\ufe0e from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . framerate = 30 # record a video camera . start_recording ( 'picamera.h264' ) camera . wait_recording ( 60 ) camera . stop_recording () ffmpeg -i picamera.h264 \\ -c:v copy picamera.mp4 Performance: Total time: 61 seconds Average CPU: 11 (Good) Average MEM: 5 (Good) Input FPS: 30 Output FPS: 25 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 3 302 kb/s (Good) Picamera Now, I want to try how picamera can draw text on output video. Here is the test code: from picamera import PiCamera import datetime # macro TIMEFMT = '%Y-%m- %d %H:%M:%S. %f ' # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) # record a video camera . start_recording ( 'picamera_text.h264' ) start = datetime . datetime . now () while ( datetime . datetime . now () - start ) . seconds < 60 : camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) camera . wait_recording ( 0.04 ) # 25fps # stop it camera . stop_recording () The CPU uses twice as much as it does in non-overlay text, while the MEM keeps the same percentage. picamera shows an impressive CPU and MEM usage, and it is written in python so I can use it more freely in feature project. Let's check it capabilities in streaming.","title":"Setup Camera with V4L2, FFMPEG, and PiCamera"},{"location":"posts/raspberrypi/setup_camera/#enable-camera-module","text":"Run raspi-config configuration tool: sudo raspi-config Go to Interfacing Options > Camera > Yes This method does the same thing with setting up start_x = 1 in /boot/config.txt raspi-config You can use raspi-config , which is a Raspberry Pi configuration command-line tool, to enable or disable some features in RPi OS. This tool requires root permission, therefore, you have to run it with sudo . User interface of raspi-config","title":"Enable Camera module"},{"location":"posts/raspberrypi/setup_camera/#increase-gpu-memory","text":"In the raspi-config configuration tool: sudo raspi-config Go to Performance Options > GPU Memory > fill in 256 and select OK This method does the same thing with setting up gpu_mem = 256 in /boot/config.txt","title":"Increase GPU memory"},{"location":"posts/raspberrypi/setup_camera/#test-camera","text":"You can detect the camera connection by running a checking tool vcgencmd get_camera which should print out supported = 1 detected=1 to tell you that your camera is supported and connected. vcgencmd vcgencmd is a command line utility that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. You can check more detail in Raspberry Pi/vcgencmd Raspicam commands has a set of tools to work with the camera module: raspistill , raspivid , and raspiyuv . Capture an image: raspistill -o cam.jpg Record an video: raspivid -o vid.h264","title":"Test Camera"},{"location":"posts/raspberrypi/setup_camera/#video-for-linux-2---v4l2","text":"Under Linux, the standard API for cameras (including web cams) is V4L (Video for Linux), and a number of applications have been written that support any camera with a V4L driver. An independent developer has now written a user space V4L driver for the Raspberry Pi camera but it is closed sourced, and can be a little slow because it runs as a user program rather than a kernel driver. Recognizing that a V4L driver is needed, the Raspberry Pi Foundation reported that they were working with Broadcom to develop an official kernel V4L driver. As a kernel driver, it should be faster than the user space driver. Finally, V4L2 was release under the name bcm2835-v4l2 which is included in to Raspbian OS by default. You can use v4l2-ctl utility tool to capture from your camera too.","title":"Video for Linux 2 - v4l2"},{"location":"posts/raspberrypi/setup_camera/#list-devices","text":"v4l2-ctl --list-devices bcm2835-codec-decode (platform:bcm2835-codec): /dev/video10 /dev/video11 /dev/video12 bcm2835-isp (platform:bcm2835-isp): /dev/video13 /dev/video14 /dev/video15 /dev/video16 mmal service 16.1 (platform:bcm2835-v4l2): /dev/video0","title":"List devices"},{"location":"posts/raspberrypi/setup_camera/#driver-info","text":"v4l2-ctl -d /dev/video0 --all Driver Info: Driver name : bm2835 mmal Card type : mmal service 16.1 Bus info : platform:bcm2835-v4l2 Driver version : 5.4.79 Capabilities : 0x85200005 Video Capture Video Overlay Read/Write Streaming Extended Pix Format Device Capabilities Device Caps : 0x05200005 Video Capture Video Overlay Read/Write Streaming Extended Pix Format Priority: 2 Video input : 0 (Camera 0: ok) Format Video Capture: Width/Height : 1024/768 Pixel Format : 'JPEG' (JFIF JPEG) Field : None Bytes per Line : 0 Size Image : 786432 Colorspace : JPEG Transfer Function : Default (maps to sRGB) YCbCr/HSV Encoding: Default (maps to ITU-R 601) Quantization : Default (maps to Full Range) Flags : Format Video Overlay: Left/Top : 150/50 Width/Height: 1024/768 Field : None Chroma Key : 0x00000000 Global Alpha: 0xff Clip Count : 0 Clip Bitmap : No Framebuffer Format: Capability : Extern Overlay Global Alpha Flags : Overlay Matches Capture/Output Size Width : 1024 Height : 768 Pixel Format : 'YU12' Streaming Parameters Video Capture: Capabilities : timeperframe Frames per second: 30.000 (30000/1000) Read buffers : 1 User Controls brightness 0x00980900 (int) : min=0 max=100 step=1 default=50 value=50 flags=slider contrast 0x00980901 (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider saturation 0x00980902 (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider red_balance 0x0098090e (int) : min=1 max=7999 step=1 default=1000 value=1000 flags=slider blue_balance 0x0098090f (int) : min=1 max=7999 step=1 default=1000 value=1000 flags=slider horizontal_flip 0x00980914 (bool) : default=0 value=0 vertical_flip 0x00980915 (bool) : default=0 value=0 power_line_frequency 0x00980918 (menu) : min=0 max=3 default=1 value=1 sharpness 0x0098091b (int) : min=-100 max=100 step=1 default=0 value=0 flags=slider color_effects 0x0098091f (menu) : min=0 max=15 default=0 value=0 rotate 0x00980922 (int) : min=0 max=360 step=90 default=0 value=0 flags=modify-layout color_effects_cbcr 0x0098092a (int) : min=0 max=65535 step=1 default=32896 value=32896 Codec Controls video_bitrate_mode 0x009909ce (menu) : min=0 max=1 default=0 value=0 flags=update video_bitrate 0x009909cf (int) : min=25000 max=25000000 step=25000 default=10000000 value=10000000 repeat_sequence_header 0x009909e2 (bool) : default=0 value=0 h264_i_frame_period 0x00990a66 (int) : min=0 max=2147483647 step=1 default=60 value=60 h264_level 0x00990a67 (menu) : min=0 max=11 default=11 value=11 h264_profile 0x00990a6b (menu) : min=0 max=4 default=4 value=4 Camera Controls auto_exposure 0x009a0901 (menu) : min=0 max=3 default=0 value=0 exposure_time_absolute 0x009a0902 (int) : min=1 max=10000 step=1 default=1000 value=1000 exposure_dynamic_framerate 0x009a0903 (bool) : default=0 value=0 auto_exposure_bias 0x009a0913 (intmenu): min=0 max=24 default=12 value=12 white_balance_auto_preset 0x009a0914 (menu) : min=0 max=10 default=1 value=1 image_stabilization 0x009a0916 (bool) : default=0 value=0 iso_sensitivity 0x009a0917 (intmenu): min=0 max=4 default=0 value=0 iso_sensitivity_auto 0x009a0918 (menu) : min=0 max=1 default=1 value=1 exposure_metering_mode 0x009a0919 (menu) : min=0 max=2 default=0 value=0 scene_mode 0x009a091a (menu) : min=0 max=13 default=0 value=0 JPEG Compression Controls compression_quality 0x009d0903 (int) : min=1 max=100 step=1 default=30 value=30","title":"Driver info"},{"location":"posts/raspberrypi/setup_camera/#supported-formats","text":"v4l2-ctl --list-formats ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) [1]: 'YUYV' (YUYV 4:2:2) [2]: 'RGB3' (24-bit RGB 8-8-8) [3]: 'JPEG' (JFIF JPEG, compressed) [4]: 'H264' (H.264, compressed) [5]: 'MJPG' (Motion-JPEG, compressed) [6]: 'YVYU' (YVYU 4:2:2) [7]: 'VYUY' (VYUY 4:2:2) [8]: 'UYVY' (UYVY 4:2:2) [9]: 'NV12' (Y/CbCr 4:2:0) [10]: 'BGR3' (24-bit BGR 8-8-8) [11]: 'YV12' (Planar YVU 4:2:0) [12]: 'NV21' (Y/CrCb 4:2:0) [13]: 'RX24' (32-bit XBGR 8-8-8-8) Please take a note for RGB3 , JPEG , H264 , and MJPEG , which can be used in OpenCV, Streaming directly.","title":"Supported formats"},{"location":"posts/raspberrypi/setup_camera/#capture-jpeg-image","text":"v4l2-ctl --set-fmt-video = width = 2592 ,height = 1944 ,pixelformat = 3 v4l2-ctl --stream-mmap = 3 --stream-count = 1 --stream-to = somefile.jpg","title":"Capture JPEG Image"},{"location":"posts/raspberrypi/setup_camera/#record-h264-video","text":"Note the value height= 1088 , not 1080 v4l2-ctl --set-fmt-video = width = 1920 ,height = 1088 ,pixelformat = 4 v4l2-ctl --stream-mmap = 3 --stream-count = 100 --stream-to = somefile.264","title":"Record H264 Video"},{"location":"posts/raspberrypi/setup_camera/#install-ffmpeg","text":"The pre-built ffmpeg package of RPi already enable hardware accelerator support, with OpenMAX IL H.264 video encoder ( h264_omx ). sudo apt-get install ffmpeg -y Compile FFMPEG Manual In case you want FFMPEG with a specific library, you can compile FFMPEG manually by following this topic Compile FFMPEG with Hardware Accelerator","title":"Install ffmpeg"},{"location":"posts/raspberrypi/setup_camera/#encoders","text":"To see all availabe encoders, you can run ffmpeg -encoders Encoders: V..... = Video A..... = Audio S..... = Subtitle .F.... = Frame-level multithreading ..S... = Slice-level multithreading ...X.. = Codec is experimental ....B. = Supports draw_horiz_band .....D = Supports direct rendering method 1 ------ V..... a64multi Multicolor charset for Commodore 64 (codec a64_multi) V..... a64multi5 Multicolor charset for Commodore 64, extended with 5th color (colram) (codec a64_multi5) V..... alias_pix Alias/Wavefront PIX image V..... amv AMV Video V..... apng APNG (Animated Portable Network Graphics) image V..... asv1 ASUS V1 V..... asv2 ASUS V2 V..X.. libaom-av1 libaom AV1 (codec av1) V..... avrp Avid 1:1 10-bit RGB Packer V..X.. avui Avid Meridien Uncompressed V..... ayuv Uncompressed packed MS 4:4:4:4 V..... bmp BMP (Windows and OS/2 bitmap) V..... libxavs libxavs Chinese AVS (Audio Video Standard) (codec cavs) VF.... cfhd GoPro CineForm HD V..... cinepak Cinepak V..... cljr Cirrus Logic AccuPak V.S... vc2 SMPTE VC-2 (codec dirac) VFS... dnxhd VC3/DNxHD V..... dpx DPX (Digital Picture Exchange) image VFS... dvvideo DV (Digital Video) V.S... ffv1 FFmpeg video codec #1 VF.... ffvhuff Huffyuv FFmpeg variant V..... fits Flexible Image Transport System V..... flashsv Flash Screen Video V..... flashsv2 Flash Screen Video Version 2 V..... flv FLV / Sorenson Spark / Sorenson H.263 (Flash Video) (codec flv1) V..... gif GIF (Graphics Interchange Format) V..... h261 H.261 V..... h263 H.263 / H.263-1996 V..... h263_v4l2m2m V4L2 mem2mem H.263 encoder wrapper (codec h263) V.S... h263p H.263+ / H.263-1998 / H.263 version 2 V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) V..... hap Vidvox Hap V..... libx265 libx265 H.265 / HEVC (codec hevc) V..... hevc_v4l2m2m V4L2 mem2mem HEVC encoder wrapper (codec hevc) V..... libkvazaar libkvazaar H.265 / HEVC (codec hevc) VF.... huffyuv Huffyuv / HuffYUV V..... jpeg2000 JPEG 2000 VF.... libopenjpeg OpenJPEG JPEG 2000 (codec jpeg2000) VF.... jpegls JPEG-LS VF.... ljpeg Lossless JPEG VF.... magicyuv MagicYUV video VFS... mjpeg MJPEG (Motion JPEG) V.S... mpeg1video MPEG-1 video V.S... mpeg2video MPEG-2 video V.S... mpeg4 MPEG-4 part 2 V..... libxvid libxvidcore MPEG-4 part 2 (codec mpeg4) V..... mpeg4_omx OpenMAX IL MPEG-4 video encoder (codec mpeg4) V..... mpeg4_v4l2m2m V4L2 mem2mem MPEG4 encoder wrapper (codec mpeg4) V..... msmpeg4v2 MPEG-4 part 2 Microsoft variant version 2 V..... msmpeg4 MPEG-4 part 2 Microsoft variant version 3 (codec msmpeg4v3) V..... msvideo1 Microsoft Video-1 V..... pam PAM (Portable AnyMap) image V..... pbm PBM (Portable BitMap) image V..... pcx PC Paintbrush PCX image V..... pgm PGM (Portable GrayMap) image V..... pgmyuv PGMYUV (Portable GrayMap YUV) image VF.... png PNG (Portable Network Graphics) image V..... ppm PPM (Portable PixelMap) image VF.... prores Apple ProRes VF.... prores_aw Apple ProRes (codec prores) VFS... prores_ks Apple ProRes (iCodec Pro) (codec prores) V..... qtrle QuickTime Animation (RLE) video V..... r10k AJA Kona 10-bit RGB Codec V..... r210 Uncompressed RGB 10-bit V..... rawvideo raw video V..... roqvideo id RoQ video (codec roq) V..... rpza QuickTime video (RPZA) V..... rv10 RealVideo 1.0 V..... rv20 RealVideo 2.0 V..... sgi SGI image V..... snow Snow V..... speedhq NewTek SpeedHQ V..... sunrast Sun Rasterfile image V..... svq1 Sorenson Vector Quantizer 1 / Sorenson Video 1 / SVQ1 V..... targa Truevision Targa image V..... libtheora libtheora Theora (codec theora) VF.... tiff TIFF image VF.... utvideo Ut Video V..... v210 Uncompressed 4:2:2 10-bit V..... v308 Uncompressed packed 4:4:4 V..... v408 Uncompressed packed QT 4:4:4:4 V..... v410 Uncompressed 4:4:4 10-bit V..... libvpx libvpx VP8 (codec vp8) V..... vp8_v4l2m2m V4L2 mem2mem VP8 encoder wrapper (codec vp8) V..... libvpx-vp9 libvpx VP9 (codec vp9) V..... libwebp_anim libwebp WebP image (codec webp) V..... libwebp libwebp WebP image (codec webp) V..... wmv1 Windows Media Video 7 V..... wmv2 Windows Media Video 8 V..... wrapped_avframe AVFrame to AVPacket passthrough V..... xbm XBM (X BitMap) image V..... xface X-face image V..... xwd XWD (X Window Dump) image V..... y41p Uncompressed YUV 4:1:1 12-bit V..... yuv4 Uncompressed packed 4:2:0 VF.... zlib LCL (LossLess Codec Library) ZLIB V..... zmbv Zip Motion Blocks Video A..... aac AAC (Advanced Audio Coding) A..... libfdk_aac Fraunhofer FDK AAC (codec aac) A..... ac3 ATSC A/52A (AC-3) A..... ac3_fixed ATSC A/52A (AC-3) (codec ac3) A..... adpcm_adx SEGA CRI ADX ADPCM A..... adpcm_argo ADPCM Argonaut Games A..... g722 G.722 ADPCM (codec adpcm_g722) A..... g726 G.726 ADPCM (codec adpcm_g726) A..... g726le G.726 little endian ADPCM (\"right-justified\") (codec adpcm_g726le) A..... adpcm_ima_alp ADPCM IMA High Voltage Software ALP A..... adpcm_ima_amv ADPCM IMA AMV A..... adpcm_ima_apm ADPCM IMA Ubisoft APM A..... adpcm_ima_qt ADPCM IMA QuickTime A..... adpcm_ima_ssi ADPCM IMA Simon & Schuster Interactive A..... adpcm_ima_wav ADPCM IMA WAV A..... adpcm_ms ADPCM Microsoft A..... adpcm_swf ADPCM Shockwave Flash A..... adpcm_yamaha ADPCM Yamaha A..... alac ALAC (Apple Lossless Audio Codec) A..... libopencore_amrnb OpenCORE AMR-NB (Adaptive Multi-Rate Narrow-Band) (codec amr_nb) A..... libvo_amrwbenc Android VisualOn AMR-WB (Adaptive Multi-Rate Wide-Band) (codec amr_wb) A..... aptx aptX (Audio Processing Technology for Bluetooth) A..... aptx_hd aptX HD (Audio Processing Technology for Bluetooth) A..... libcodec2 codec2 encoder using libcodec2 (codec codec2) A..... comfortnoise RFC 3389 comfort noise generator A..X.. dca DCA (DTS Coherent Acoustics) (codec dts) A..... eac3 ATSC A/52 E-AC-3 A..... flac FLAC (Free Lossless Audio Codec) A..... g723_1 G.723.1 A..... libgsm libgsm GSM (codec gsm) A..... libgsm_ms libgsm GSM Microsoft variant (codec gsm_ms) A..X.. mlp MLP (Meridian Lossless Packing) A..... mp2 MP2 (MPEG audio layer 2) A..... mp2fixed MP2 fixed point (MPEG audio layer 2) (codec mp2) A..... libtwolame libtwolame MP2 (MPEG audio layer 2) (codec mp2) A..... libmp3lame libmp3lame MP3 (MPEG audio layer 3) (codec mp3) A..... libshine libshine MP3 (MPEG audio layer 3) (codec mp3) A..... nellymoser Nellymoser Asao A..X.. opus Opus A..... libopus libopus Opus (codec opus) A..... pcm_alaw PCM A-law / G.711 A-law A..... pcm_dvd PCM signed 16|20|24-bit big-endian for DVD media A..... pcm_f32be PCM 32-bit floating point big-endian A..... pcm_f32le PCM 32-bit floating point little-endian A..... pcm_f64be PCM 64-bit floating point big-endian A..... pcm_f64le PCM 64-bit floating point little-endian A..... pcm_mulaw PCM mu-law / G.711 mu-law A..... pcm_s16be PCM signed 16-bit big-endian A..... pcm_s16be_planar PCM signed 16-bit big-endian planar A..... pcm_s16le PCM signed 16-bit little-endian A..... pcm_s16le_planar PCM signed 16-bit little-endian planar A..... pcm_s24be PCM signed 24-bit big-endian A..... pcm_s24daud PCM D-Cinema audio signed 24-bit A..... pcm_s24le PCM signed 24-bit little-endian A..... pcm_s24le_planar PCM signed 24-bit little-endian planar A..... pcm_s32be PCM signed 32-bit big-endian A..... pcm_s32le PCM signed 32-bit little-endian A..... pcm_s32le_planar PCM signed 32-bit little-endian planar A..... pcm_s64be PCM signed 64-bit big-endian A..... pcm_s64le PCM signed 64-bit little-endian A..... pcm_s8 PCM signed 8-bit A..... pcm_s8_planar PCM signed 8-bit planar A..... pcm_u16be PCM unsigned 16-bit big-endian A..... pcm_u16le PCM unsigned 16-bit little-endian A..... pcm_u24be PCM unsigned 24-bit big-endian A..... pcm_u24le PCM unsigned 24-bit little-endian A..... pcm_u32be PCM unsigned 32-bit big-endian A..... pcm_u32le PCM unsigned 32-bit little-endian A..... pcm_u8 PCM unsigned 8-bit A..... pcm_vidc PCM Archimedes VIDC A..... real_144 RealAudio 1.0 (14.4K) (codec ra_144) A..... roq_dpcm id RoQ DPCM A..X.. s302m SMPTE 302M A..... sbc SBC (low-complexity subband codec) A..X.. sonic Sonic A..X.. sonicls Sonic lossless A..... libspeex libspeex Speex (codec speex) A..X.. truehd TrueHD A..... tta TTA (True Audio) A..X.. vorbis Vorbis A..... libvorbis libvorbis (codec vorbis) A..... wavpack WavPack A..... wmav1 Windows Media Audio 1 A..... wmav2 Windows Media Audio 2 S..... ssa ASS (Advanced SubStation Alpha) subtitle (codec ass) S..... ass ASS (Advanced SubStation Alpha) subtitle S..... dvbsub DVB subtitles (codec dvb_subtitle) S..... dvdsub DVD subtitles (codec dvd_subtitle) S..... mov_text 3GPP Timed Text subtitle S..... srt SubRip subtitle (codec subrip) S..... subrip SubRip subtitle S..... text Raw text subtitle S..... webvtt WebVTT subtitle S..... xsub DivX subtitles (XSUB) If you're interested in h264 and mjpeg , you can use grep to search for the specific encoders ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG) Check encoder options Before using an encoder, you can check its options by help command in ffmpeg . For example: ffmpeg -h encoder = h264_omx Encoder h264_omx [OpenMAX IL H.264 video encoder]: General capabilities: delay Threading capabilities: none Supported pixel formats: yuv420p h264_omx AVOptions: -omx_libname <string> ED.V...... OpenMAX library name -omx_libprefix <string> ED.V...... OpenMAX library prefix -zerocopy <int> E..V...... Try to avoid copying input frames if possible (from 0 to 1) (default 1) -profile <int> E..V...... Set the encoding profile (from -99 to 100) (default -99) baseline 66 E..V...... main 77 E..V...... high 100 E..V......","title":"Encoders"},{"location":"posts/raspberrypi/setup_camera/#measure-performance","text":"Next, we will try to record some short video (60 seconds) with H264 format using different encoders. For measuring the performance, we use a small tool to check CPU and Memory Usage in monitor - Script to check performance Video side: 1024x768 Framerate: 30 fps Input Length: 60 seconds Note that ffmpeg uses v4l2 driver!","title":"Measure performance"},{"location":"posts/raspberrypi/setup_camera/#raw-to-mjpeg-avi","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v mjpeg \\ raw_mjpeg.avi Performance: Total time: 63 seconds Average CPU: 93 (too high) Average MEM: 31 Input FPS: 4.8 (dropped input) Output FPS: 30 Quality: Format : JPEG Codec ID : MJPG Bit rate : 839 kb/s Raw to MJPEG","title":"Raw to MJPEG (.avi)"},{"location":"posts/raspberrypi/setup_camera/#raw-to-h264_omx-8mbps-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx.mp4 Performance: Total time: 63 seconds Average CPU: 16 (OK) Average MEM: 27 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GOP: M=1, N=12) Codec ID : avc1 Bit rate : 2 877 kb/s Raw to H264_OMX @8Mbps","title":"Raw to H264_OMX @8Mbps (.mp4)"},{"location":"posts/raspberrypi/setup_camera/#raw-to-h264_v4l2m2m-8mbps-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_v4l2m2m \\ -b:v 8M \\ raw_h264v4l2m2m.mp4 Performance: Total time: 62 seconds Average CPU: 23 Average MEM: 27 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 1 783 kb/s Raw to H264_V4L2M2M @8Mbps","title":"Raw to H264_V4L2M2M @8Mbps (.mp4)"},{"location":"posts/raspberrypi/setup_camera/#v4l2-mjpeg-direct-copy-avi","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format mjpeg \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ mjpeg_avi.avi Performance: Total time: 67 seconds Average CPU: 10 (Good) Average MEM: 21 Input FPS: 30 Output FPS: 30 Quality: Format : JPEG Codec ID : MJPG Bit rate : 10.2 Mb/s (very high bandwidth) Save V4L2 MJPEG strem","title":"V4L2 MJPEG direct copy (.avi)"},{"location":"posts/raspberrypi/setup_camera/#v4l2-h264-direct-copy-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ h264_mp4.mp4 Performance: Total time: 67 seconds Average CPU: 10 (Good) Average MEM: 24 Input FPS: 30 Output FPS: 30 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 5 506 kb/s (OK) Save V4L2 H264 stream After above tests, I could say that using compressed input format from v4l2 is much more effective than compressing by an encoder. Let's add some timestamp to video by using drawtext filter with built-in expandable localtime variable http://ffmpeg.org/ffmpeg-filters.html#Text-expansion . ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx_text.mp4 Filtering and streamcopy cannot be used together # this will not work ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -input_format h264 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v copy \\ -t 10 \\ h264_mp4_text.mp4","title":"V4L2 H264 direct copy (.mp4)"},{"location":"posts/raspberrypi/setup_camera/#install-picamera","text":"picamera is a pure Python interface to the Raspberry Pi camera module for Python 2.7 (or above) or Python 3.2 (or above). Homepage: https://picamera.readthedocs.io/en/latest/install.html . If you are using the Raspbian distro, you probably have picamera installed by default. You can find out simply by starting Python and trying to import picamera: python -c \"import picamera\" python3 -c \"import picamera\" If you don\u2019t have picamera installed you\u2019ll see something that reports no module named picamera. To install picamera on Raspbian, it is best to use the system\u2019s package manager: sudo apt-get install python-picamera python3-picamera There are a lot of example in the official guide of Picamera at https://picamera.readthedocs.io/en/latest/recipes1.html Get maximum resolution of your camera: import picamera with picamera . PiCamera () as cam : print ( cam . MAX_RESOLUTION ) Take a snapshot: from time import sleep from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) # camera warm-up time sleep ( 2 ) # capture an image camera . capture ( 'snapshot.jpg' ) Record a 60 second video from camera and measure resource usage with monitor , then use ffmpeg to convert raw h264 to mp4.","title":"Install picamera"},{"location":"posts/raspberrypi/setup_camera/#picamera-h264-h264","text":"from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . framerate = 30 # record a video camera . start_recording ( 'picamera.h264' ) camera . wait_recording ( 60 ) camera . stop_recording () ffmpeg -i picamera.h264 \\ -c:v copy picamera.mp4 Performance: Total time: 61 seconds Average CPU: 11 (Good) Average MEM: 5 (Good) Input FPS: 30 Output FPS: 25 Quality: Format : AVC (GPO: M=1, N=60) Codec ID : avc1 Bit rate : 3 302 kb/s (Good) Picamera Now, I want to try how picamera can draw text on output video. Here is the test code: from picamera import PiCamera import datetime # macro TIMEFMT = '%Y-%m- %d %H:%M:%S. %f ' # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) # record a video camera . start_recording ( 'picamera_text.h264' ) start = datetime . datetime . now () while ( datetime . datetime . now () - start ) . seconds < 60 : camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) camera . wait_recording ( 0.04 ) # 25fps # stop it camera . stop_recording () The CPU uses twice as much as it does in non-overlay text, while the MEM keeps the same percentage. picamera shows an impressive CPU and MEM usage, and it is written in python so I can use it more freely in feature project. Let's check it capabilities in streaming.","title":"Picamera H264 (.h264)"},{"location":"posts/raspberrypi/setup_headless/","text":"Headless Mode means system runs without any primary input and output such as keyboard or monitor. Your system won't use desktop environment and therefore GUI application will not run. 1. Download OS Image \u2693\ufe0e Official images for recommended operating systems are available to download from the Raspberry Pi website download page . In Headless mode, you don't need to use Graphical User Interface, therefore, you can remove many applications which are only for desktop version. I recommend to use a lite version which is shipped with only core packages. To download a Raspberry Pi OS Lite version, such as 2020-08-20-raspios-buster-armhf-lite.zip , please follow the guide in the official download page. 2. Burn Image to SDCard \u2693\ufe0e balenaEtcher from Balena is a very good writer, download and install it, then run it. You will see a simple and easy to understand UI. Just follow the guided steps. Etcher is writing OS image After you flash (burn) the image, File Explorer may have trouble seeing it. A simple fix is to pull the SD card out then plug it back in. It should appear with the name boot followed by a drive letter. 3. Enable SSH \u2693\ufe0e For security reasons, ssh is no longer enabled by default. To enable it you need to place a blank text file called ssh in the root of the boot partition on the SDCard. 4. Add Wifi Network Info \u2693\ufe0e To add network info you need to create a second text file called wpa_supplicant.conf and place that in the root of the boot partition on SDCard too. wpa_supplicant.conf country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Added ssh and wpa_supplicant.conf in boot partition 5. Login to RPi \u2693\ufe0e Power it up and wait for the power led gets stable. You can use any Network Scanner to detect the IP of the RPi. I use a plugin on MobaXterm . Scan for RPi IP For the official Raspberry Pi OS, the default user name is pi , with password raspberry , on the host raspberrypi . Login on ssh to RPi Review Network Settings This command should list your network in the first line for wlan0 : iwconfig This command should show info for wlan0 : ifconfig This command should list your wlan0 network with details iwlist wlan0 scan To edit or review your wifi settings, run this command: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Connect to an other Wifi network Open the wpa-supplicant configuration file in nano: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Go to the bottom of the file and add the following: network={ ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Reconfigure the interface with wpa_cli -i wlan0 reconfigure You can verify whether it has successfully connected using ifconfig wlan0 6. Update system \u2693\ufe0e (optional) If you want to get the latest version of RPi OS and its packages, please update your system by entering below commands: sudo apt-get update sudo apt-get upgrade -y 7. Expand Filesystem \u2693\ufe0e (optional) To use all of available space on your SDCard, you should expand the filesystem, by running sudo raspi-config Go to Advanced Options > Expand Filesystem Then reboot the system. 8. Disable unnecessary components \u2693\ufe0e (optional) Please read in Save Power post. Show who is logged on and what they are doing You can use w command from procps package. 08 :53:52 up 2 :21, 2 users, load average: 0 .02, 0 .06, 0 .07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT pi pts/0 fe80::1936:b4d4: 06 :34 0 .00s 1 .54s 0 .05s w pi pts/1 fe80::1936:b4d4: 06 :34 2 :18m 0 .74s 0 .74s -bash","title":"Setup Raspberry Pi in headless mode"},{"location":"posts/raspberrypi/setup_headless/#1-download-os-image","text":"Official images for recommended operating systems are available to download from the Raspberry Pi website download page . In Headless mode, you don't need to use Graphical User Interface, therefore, you can remove many applications which are only for desktop version. I recommend to use a lite version which is shipped with only core packages. To download a Raspberry Pi OS Lite version, such as 2020-08-20-raspios-buster-armhf-lite.zip , please follow the guide in the official download page.","title":"1. Download OS Image"},{"location":"posts/raspberrypi/setup_headless/#2-burn-image-to-sdcard","text":"balenaEtcher from Balena is a very good writer, download and install it, then run it. You will see a simple and easy to understand UI. Just follow the guided steps. Etcher is writing OS image After you flash (burn) the image, File Explorer may have trouble seeing it. A simple fix is to pull the SD card out then plug it back in. It should appear with the name boot followed by a drive letter.","title":"2. Burn Image to SDCard"},{"location":"posts/raspberrypi/setup_headless/#3-enable-ssh","text":"For security reasons, ssh is no longer enabled by default. To enable it you need to place a blank text file called ssh in the root of the boot partition on the SDCard.","title":"3. Enable SSH"},{"location":"posts/raspberrypi/setup_headless/#4-add-wifi-network-info","text":"To add network info you need to create a second text file called wpa_supplicant.conf and place that in the root of the boot partition on SDCard too. wpa_supplicant.conf country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Added ssh and wpa_supplicant.conf in boot partition","title":"4. Add Wifi Network Info"},{"location":"posts/raspberrypi/setup_headless/#5-login-to-rpi","text":"Power it up and wait for the power led gets stable. You can use any Network Scanner to detect the IP of the RPi. I use a plugin on MobaXterm . Scan for RPi IP For the official Raspberry Pi OS, the default user name is pi , with password raspberry , on the host raspberrypi . Login on ssh to RPi Review Network Settings This command should list your network in the first line for wlan0 : iwconfig This command should show info for wlan0 : ifconfig This command should list your wlan0 network with details iwlist wlan0 scan To edit or review your wifi settings, run this command: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Connect to an other Wifi network Open the wpa-supplicant configuration file in nano: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Go to the bottom of the file and add the following: network={ ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Reconfigure the interface with wpa_cli -i wlan0 reconfigure You can verify whether it has successfully connected using ifconfig wlan0","title":"5. Login to RPi"},{"location":"posts/raspberrypi/setup_headless/#6-update-system","text":"(optional) If you want to get the latest version of RPi OS and its packages, please update your system by entering below commands: sudo apt-get update sudo apt-get upgrade -y","title":"6. Update system"},{"location":"posts/raspberrypi/setup_headless/#7-expand-filesystem","text":"(optional) To use all of available space on your SDCard, you should expand the filesystem, by running sudo raspi-config Go to Advanced Options > Expand Filesystem Then reboot the system.","title":"7. Expand Filesystem"},{"location":"posts/raspberrypi/setup_headless/#8-disable-unnecessary-components","text":"(optional) Please read in Save Power post. Show who is logged on and what they are doing You can use w command from procps package. 08 :53:52 up 2 :21, 2 users, load average: 0 .02, 0 .06, 0 .07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT pi pts/0 fe80::1936:b4d4: 06 :34 0 .00s 1 .54s 0 .05s w pi pts/1 fe80::1936:b4d4: 06 :34 2 :18m 0 .74s 0 .74s -bash","title":"8. Disable unnecessary components"},{"location":"posts/raspberrypi/setup_wifi_ap/","text":"1. Update the system \u2693\ufe0e Ensure you update your system to the latest version: sudo apt-get update sudo apt-get upgrade -y and then reboot your Pi. 2. Install necessary packages \u2693\ufe0e Next, in order to work as an access point, the Raspberry Pi needs to have the hostapd access point software package installed: sudo apt-get install hostapd Enable the wireless access point service and set it to start when your Raspberry Pi boots: sudo systemctl unmask hostapd sudo systemctl enable hostapd In order to provide network management services (DNS, DHCP) to wireless clients, the Raspberry Pi needs to have the dnsmasq software package installed: sudo apt-get install dnsmasq Finally, install netfilter-persistent and its plugin iptables-persistent . This utility helps by saving firewall rules and restoring them when the Raspberry Pi boots: sudo DEBIAN_FRONTEND = noninteractive apt-get install -y netfilter-persistent iptables-persistent 3. Setup Wifi Interface IP \u2693\ufe0e The Raspberry Pi runs a DHCP server for the wireless network; this requires static IP configuration for the wireless interface ( wlan0 ) in the Raspberry Pi. The Raspberry Pi also acts as the router on the wireless network, and as is customary, we will give it the first IP address in the network, e.g: 192.168.4.1 . sudo nano /etc/dhcpcd.conf Add below line to the file and save it: /etc/dhcpcd.conf interface wlan0 static ip_address = 192.168.4.1/24 nohook wpa_supplicant 4. Setup DHCP and DNS \u2693\ufe0e Rename the default configuration file and edit a new one: sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig sudo nano /etc/dnsmasq.conf Add the following to the file and save it: /etc/dnsmasq.conf # Listening interface interface = wlan0 # Pool of IP addresses served via DHCP dhcp-range = 192.168.4.2,192.168.4.20,255.255.255.0,24h # Local wireless DNS domain domain = wlan # Alias for this router address = /gw.wlan/192.168.4.1 The Raspberry Pi will deliver IP addresses between 192.168.4.2 and 192.168.4.20 , with a lease time of 24 hours, to wireless DHCP clients. You should be able to reach the Raspberry Pi under the name gw.wlan from wireless clients. 5. Turn on Wifi \u2693\ufe0e To ensure WiFi radio is not blocked on your Raspberry Pi, execute the following command: sudo rfkill unblock wlan 6. Setup Access Point \u2693\ufe0e Create the hostapd configuration file, located at /etc/hostapd/hostapd.conf, to add the various parameters for your new wireless network. sudo nano /etc/hostapd/hostapd.conf Add the information below to the configuration file. This configuration assumes we are using channel 7 , with a network name of NameOfNetwork , and a password AardvarkBadgerHedgehog . Note that the name and password should not have quotes around them. The passphrase should be between 8 and 64 characters in length. /etc/hostapd/hostapd.conf country_code = US interface = wlan0 ssid = NameOfNetwork hw_mode = g channel = 7 macaddr_acl = 0 auth_algs = 1 ignore_broadcast_ssid = 0 wpa = 2 wpa_passphrase = AardvarkBadgerHedgehog wpa_key_mgmt = WPA-PSK wpa_pairwise = TKIP rsn_pairwise = CCMP Now restart your Raspberry Pi and verify that the wireless access point becomes automatically available. sudo systemctl reboot Once your Raspberry Pi has restarted, search for wireless networks with your wireless client. The network SSID you specified in file /etc/hostapd/hostapd.conf should now be present, and it should be accessible with the specified password. If SSH is enabled on the Raspberry Pi, it should be possible to connect to it from your wireless client as follows, assuming the pi account is present: ssh pi@192.168.4.1 or ssh pi@gw.wlan .","title":"Setup Wifi Access Point"},{"location":"posts/raspberrypi/setup_wifi_ap/#1-update-the-system","text":"Ensure you update your system to the latest version: sudo apt-get update sudo apt-get upgrade -y and then reboot your Pi.","title":"1. Update the system"},{"location":"posts/raspberrypi/setup_wifi_ap/#2-install-necessary-packages","text":"Next, in order to work as an access point, the Raspberry Pi needs to have the hostapd access point software package installed: sudo apt-get install hostapd Enable the wireless access point service and set it to start when your Raspberry Pi boots: sudo systemctl unmask hostapd sudo systemctl enable hostapd In order to provide network management services (DNS, DHCP) to wireless clients, the Raspberry Pi needs to have the dnsmasq software package installed: sudo apt-get install dnsmasq Finally, install netfilter-persistent and its plugin iptables-persistent . This utility helps by saving firewall rules and restoring them when the Raspberry Pi boots: sudo DEBIAN_FRONTEND = noninteractive apt-get install -y netfilter-persistent iptables-persistent","title":"2. Install necessary packages"},{"location":"posts/raspberrypi/setup_wifi_ap/#3-setup-wifi-interface-ip","text":"The Raspberry Pi runs a DHCP server for the wireless network; this requires static IP configuration for the wireless interface ( wlan0 ) in the Raspberry Pi. The Raspberry Pi also acts as the router on the wireless network, and as is customary, we will give it the first IP address in the network, e.g: 192.168.4.1 . sudo nano /etc/dhcpcd.conf Add below line to the file and save it: /etc/dhcpcd.conf interface wlan0 static ip_address = 192.168.4.1/24 nohook wpa_supplicant","title":"3. Setup Wifi Interface IP"},{"location":"posts/raspberrypi/setup_wifi_ap/#4-setup-dhcp-and-dns","text":"Rename the default configuration file and edit a new one: sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig sudo nano /etc/dnsmasq.conf Add the following to the file and save it: /etc/dnsmasq.conf # Listening interface interface = wlan0 # Pool of IP addresses served via DHCP dhcp-range = 192.168.4.2,192.168.4.20,255.255.255.0,24h # Local wireless DNS domain domain = wlan # Alias for this router address = /gw.wlan/192.168.4.1 The Raspberry Pi will deliver IP addresses between 192.168.4.2 and 192.168.4.20 , with a lease time of 24 hours, to wireless DHCP clients. You should be able to reach the Raspberry Pi under the name gw.wlan from wireless clients.","title":"4. Setup DHCP and DNS"},{"location":"posts/raspberrypi/setup_wifi_ap/#5-turn-on-wifi","text":"To ensure WiFi radio is not blocked on your Raspberry Pi, execute the following command: sudo rfkill unblock wlan","title":"5. Turn on Wifi"},{"location":"posts/raspberrypi/setup_wifi_ap/#6-setup-access-point","text":"Create the hostapd configuration file, located at /etc/hostapd/hostapd.conf, to add the various parameters for your new wireless network. sudo nano /etc/hostapd/hostapd.conf Add the information below to the configuration file. This configuration assumes we are using channel 7 , with a network name of NameOfNetwork , and a password AardvarkBadgerHedgehog . Note that the name and password should not have quotes around them. The passphrase should be between 8 and 64 characters in length. /etc/hostapd/hostapd.conf country_code = US interface = wlan0 ssid = NameOfNetwork hw_mode = g channel = 7 macaddr_acl = 0 auth_algs = 1 ignore_broadcast_ssid = 0 wpa = 2 wpa_passphrase = AardvarkBadgerHedgehog wpa_key_mgmt = WPA-PSK wpa_pairwise = TKIP rsn_pairwise = CCMP Now restart your Raspberry Pi and verify that the wireless access point becomes automatically available. sudo systemctl reboot Once your Raspberry Pi has restarted, search for wireless networks with your wireless client. The network SSID you specified in file /etc/hostapd/hostapd.conf should now be present, and it should be accessible with the specified password. If SSH is enabled on the Raspberry Pi, it should be possible to connect to it from your wireless client as follows, assuming the pi account is present: ssh pi@192.168.4.1 or ssh pi@gw.wlan .","title":"6. Setup Access Point"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/","text":"Delay when streaming in HLS protocol Delay when streaming in HLS protocol Big Buck Bunny movie, (c) 2008, Blender Foundation / www.bigbuckbunny.org Download stream_ffmpeg_hls.zip Install FFMPEG \u2693\ufe0e Installing FFMPEG from package manager: sudo apt-get install ffmpeg -y or compiling your own executable file by following Compile ffmpeg script guide, it is up to your choice. At the finally, you will have ffmpeg as the main tool for your streaming system. HLS vs. MPEG-DASH \u2693\ufe0e A streaming protocol is a type of technology that is designed to transport video files over the internet. In the past, online video was delivered primarily via the RTMP protocol. RTMP is a Flash-based standard that\u2019s still used today for sending video from your encoder to your online video platform. However, Flash-based video is no longer appropriate for delivering video to users. The Flash plugin has been depreciated and fewer and fewer devices support this aging protocol each year. The RTMP has slowly been replaced by the HLS and MPEG-DASH protocol HLS \u2693\ufe0e HLS is short for HTTP Live Streaming. It is a protocol used to stream live video over the internet. Originally developed by Apple, the purpose of HLS was to make the iPhone capable of accessing live streams. At first, HLS was exclusive to iPhones, but today almost every device supports this protocol, so it has become a proprietary format. As the name implies, HLS delivers content via standard HTTP web servers. This means that no special infrastructure is needed to deliver HLS content. Any standard web server or CDN will work. Additionally, content is less likely to be blocked by firewalls with this protocol, which is a plus. HLS can play video encoded with the H.264 or HEVC/H.265 codecs. How it works is video is chopped up into 10-second segments. Latency for delivery tends to be in the 45-second range. With some settings applied, the delay can be reduced to 3-5 seconds. This protocol also includes several other built-in features. For example, HLS is an adaptive bitrate protocol. This means that the client device and server dynamically detect the internet speed of the user and adjusts video quality accordingly. MPEG-DASH \u2693\ufe0e As a newer standard, MPEG-DASH is an up-and-coming competitor to HLS. This protocol was created as a response to fragmentation in the video streaming market. At the time, Apple\u2019s HLS was competing with several other streaming protocols. The outcome was uncertain, which led standards organizations to develop MPEG-DASH as an alternative, unifying streaming protocol. MPEG-DASH is an open-source standard. Like the HLS streaming protocol, MPEG-DASH is an adaptive bitrate video method. It also supports advertising, and the technology for this is rapidly advancing. However, MPEG-DASH is not supported on the mobile Safari browser. HLS is simply much more widely compatible than MPEG-DASH. Setup web server \u2693\ufe0e Because HLS and MPEG-DASH are HTTP-based protocols, there is no need to install a special web server, what you need is just a simple web server which can serve video chunk files. Apache \u2693\ufe0e Apache is a popular web server application you can install on the Raspberry Pi to allow it to serve web pages. On its own, Apache can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. Apache's design architecture: Process Driven Approach Creates a new thread for each request. sudo apt-get install apache2 -y By default, Apache puts a test HTML file in the web folder /var/www/html/index.html . This default web page is served when you browse to http://localhost on the Pi itself or http://pi's_ip from other device's browsers. NGINX \u2693\ufe0e NGINX (pronounced engine x) is a popular lightweight web server application you can install on the Raspberry Pi to allow it to serve web pages. Like Apache, NGINX can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. NGINX's design architecture: Event-Driven approach Handles multiple requests within one thread Nginx can work very fast and wide with limited resources. sudo apt-get install nginx -y Similar to Apache, NGINX also serves web pages in /var/www/html . You can confirm the default page location at /etc/nginx/sites-available on the line which starts with 'root', should you need to. As the article Apache Vs NGINX \u2013 Which Is The Best Web Server for You? mentioned, if you are going to serve static web page with high traffic (requests), you are better to go with NGINX. I haven't tested both, so I will choose NGINX for streaming. Stream live video \u2693\ufe0e MPEG-DASH and HLS both create playlist files whose content are list of video chunks. I will use ffmpeg to read from camera and write video chunks as well as update the playlist. To speed up and to protect SDCard, I'd like write video chunks in memory. When the number of chunks go high, I'll clear the old ones. Let's do it with HLS first! Create video chunks storage folder \u2693\ufe0e Create a new folder in shared memory mkdir -p /dev/shm/hls and make a softlink to the web folder ln -s /dev/shm/hls /var/www/html/hls Use ffmpeg to create HLS playlist: -input_format h264 -i /dev/video0 : input from /dev/video0 (Pi Camera) with V4L2 H264 format (see more in V4L2 H264 direct copy ) -c:v copy : directly use H264 video from V4L2 driver -f hls : output in HLS format -hls_time 1 : video chunks are saved in 1-second segments -hls_list_size 30 : playlist has 30 segments -hls_flags delete_segments : delete segments not in the playlist /dev/shm/hls/live.m3u8 : the location of playlist file and video segments ffmpeg -y \\ -input_format h264 -i /dev/video0 \\ -c:v copy \\ -f hls \\ -hls_time 1 \\ -hls_list_size 30 \\ -hls_flags delete_segments \\ /dev/shm/hls/live.m3u8 Create web page to show HLS stream \u2693\ufe0e I will use hls.js to play HLS stream. /var/www/html/hls.html <!DOCTYPE html> < html > < head > < meta charset = utf-8 /> < title > HLS Live Stream </ title > </ head > < body > < h1 > HLS Live Stream </ h1 > < script src = \"hls.js\" ></ script > < video id = \"video\" controls autoplay ></ video > < script > var video = document . getElementById ( 'video' ); var videoSrc = 'hls/live.m3u8' ; // First check for native browser HLS support if ( video . canPlayType ( 'application/vnd.apple.mpegurl' )) { video . src = videoSrc ; } // If no native HLS support, check if hls.js is supported else if ( Hls . isSupported ()) { var hls = new Hls (); hls . loadSource ( videoSrc ); hls . attachMedia ( video ); } </ script > </ body > </ html > HLS Performance HLS is good to stream over HTTP but it has delay. At 1024x768 30fps stream with 1-second segments, it still shows a delay of ~10 seconds . You can measure the performance by play your HLS playlist in HLS testing site: https://hls-js.netlify.app/demo/ (need to enable CORS). Move to MPEG-DASH \u2693\ufe0e DASH is the same as HLS, the difference is in the playlist format and the container of segments. Create a new folder in shared memory mkdir -p /dev/shm/dash and make a softlink to the web folder ln -s /dev/shm/dash /var/www/html/dash ffmpeg -y \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -seg_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ /dev/shm/dash/live.mpd /var/www/html/dash.html <!doctype html> < html > < head > < meta charset = utf-8 /> < title > MPEG-DASH Live Stream </ title > </ head > < body > < h1 > MPEG-DASH Live Stream </ h1 > < script src = \"dash.all.min.js\" ></ script > < video id = \"videoPlayer\" controls ></ video > < script > ( function (){ var url = \"dash/live.mpd\" ; var player = dashjs . MediaPlayer (). create (); player . initialize ( document . querySelector ( \"#videoPlayer\" ), url , true ); player . updateSettings ({ streaming : { lowLatencyEnabled : true , liveDelay : 2 , liveCatchup : { minDrift : 0.05 , playbackRate : 1 , latencyThreshold : 30 , } } }); })(); </ script > </ body > </ html > MPEG-DASH Performance MPEG-DASH can achieve ~3 seconds of delay , which is much better than HLS. However, it is still far from real-time live stream. I still need to try Low Latency settings for HLS and MPEG-DASH A simple Python Web Server \u2693\ufe0e I am going to make a simple Python HTTP server to stream HLS files. class http . server . SimpleHTTPRequestHandler serves files from its current directory and below, directly mapping the directory structure to HTTP requests. index.html Use hls.js to play HLS Stream. There is extra HLS configs: var config = Hls . DefaultConfig ; config . liveSyncDurationCount = 1 ; config . startFragPrefetch = true ; console . log ( config ); var hls = new Hls ( config ); hls.js HLS Stream player written in Javascript for web server.py This implements a simple HTTP Request Handler based on SimpleHTTPRequestHandler run.sh This script creates a temporary folder in shared memory to store video segments. Then it runs ffmpeg to read camera and write video chunks. Finally it calls HLS_server.py to serve the web. I use ffmpeg to generate both HLS and DASH segments, with some options to reduce latency. ffmpeg -y \\ -input_format h264 \\ -f video4linux2 \\ -framerate 25 \\ -use_wallclock_as_timestamps 1 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -ldash 1 \\ -seg_duration 1 \\ -frag_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ -strict experimental -lhls 1 \\ -hls_playlist 1 -hls_master_name live.m3u8 \\ -utc_timing_url https://time.akamai.com/?iso \\ -write_prft 1 \\ -target_latency 1 \\ /dev/shm/hls/live.mpd & The result is not good as I expected, as there is still about 3.3 seconds of delay in a LAN. Delay in HLS streaming You can't bind to port numbers lower than 1024 as a unprivileged user So you should either: Use a port number larger than 1024 (recommended) Or run the script as a privileged user Harder, but more secure solution if it's really necessary to accept from port numbers lower than 1024: Run the as unprivileged on a higher port, and forward that port to lower port externally. Download stream_ffmpeg_hls.zip","title":"Stream camera using HLS and DASH format"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#install-ffmpeg","text":"Installing FFMPEG from package manager: sudo apt-get install ffmpeg -y or compiling your own executable file by following Compile ffmpeg script guide, it is up to your choice. At the finally, you will have ffmpeg as the main tool for your streaming system.","title":"Install FFMPEG"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#hls-vs-mpeg-dash","text":"A streaming protocol is a type of technology that is designed to transport video files over the internet. In the past, online video was delivered primarily via the RTMP protocol. RTMP is a Flash-based standard that\u2019s still used today for sending video from your encoder to your online video platform. However, Flash-based video is no longer appropriate for delivering video to users. The Flash plugin has been depreciated and fewer and fewer devices support this aging protocol each year. The RTMP has slowly been replaced by the HLS and MPEG-DASH protocol","title":"HLS vs. MPEG-DASH"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#hls","text":"HLS is short for HTTP Live Streaming. It is a protocol used to stream live video over the internet. Originally developed by Apple, the purpose of HLS was to make the iPhone capable of accessing live streams. At first, HLS was exclusive to iPhones, but today almost every device supports this protocol, so it has become a proprietary format. As the name implies, HLS delivers content via standard HTTP web servers. This means that no special infrastructure is needed to deliver HLS content. Any standard web server or CDN will work. Additionally, content is less likely to be blocked by firewalls with this protocol, which is a plus. HLS can play video encoded with the H.264 or HEVC/H.265 codecs. How it works is video is chopped up into 10-second segments. Latency for delivery tends to be in the 45-second range. With some settings applied, the delay can be reduced to 3-5 seconds. This protocol also includes several other built-in features. For example, HLS is an adaptive bitrate protocol. This means that the client device and server dynamically detect the internet speed of the user and adjusts video quality accordingly.","title":"HLS"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#mpeg-dash","text":"As a newer standard, MPEG-DASH is an up-and-coming competitor to HLS. This protocol was created as a response to fragmentation in the video streaming market. At the time, Apple\u2019s HLS was competing with several other streaming protocols. The outcome was uncertain, which led standards organizations to develop MPEG-DASH as an alternative, unifying streaming protocol. MPEG-DASH is an open-source standard. Like the HLS streaming protocol, MPEG-DASH is an adaptive bitrate video method. It also supports advertising, and the technology for this is rapidly advancing. However, MPEG-DASH is not supported on the mobile Safari browser. HLS is simply much more widely compatible than MPEG-DASH.","title":"MPEG-DASH"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#setup-web-server","text":"Because HLS and MPEG-DASH are HTTP-based protocols, there is no need to install a special web server, what you need is just a simple web server which can serve video chunk files.","title":"Setup web server"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#apache","text":"Apache is a popular web server application you can install on the Raspberry Pi to allow it to serve web pages. On its own, Apache can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. Apache's design architecture: Process Driven Approach Creates a new thread for each request. sudo apt-get install apache2 -y By default, Apache puts a test HTML file in the web folder /var/www/html/index.html . This default web page is served when you browse to http://localhost on the Pi itself or http://pi's_ip from other device's browsers.","title":"Apache"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#nginx","text":"NGINX (pronounced engine x) is a popular lightweight web server application you can install on the Raspberry Pi to allow it to serve web pages. Like Apache, NGINX can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. NGINX's design architecture: Event-Driven approach Handles multiple requests within one thread Nginx can work very fast and wide with limited resources. sudo apt-get install nginx -y Similar to Apache, NGINX also serves web pages in /var/www/html . You can confirm the default page location at /etc/nginx/sites-available on the line which starts with 'root', should you need to. As the article Apache Vs NGINX \u2013 Which Is The Best Web Server for You? mentioned, if you are going to serve static web page with high traffic (requests), you are better to go with NGINX. I haven't tested both, so I will choose NGINX for streaming.","title":"NGINX"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#stream-live-video","text":"MPEG-DASH and HLS both create playlist files whose content are list of video chunks. I will use ffmpeg to read from camera and write video chunks as well as update the playlist. To speed up and to protect SDCard, I'd like write video chunks in memory. When the number of chunks go high, I'll clear the old ones. Let's do it with HLS first!","title":"Stream live video"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#create-video-chunks-storage-folder","text":"Create a new folder in shared memory mkdir -p /dev/shm/hls and make a softlink to the web folder ln -s /dev/shm/hls /var/www/html/hls Use ffmpeg to create HLS playlist: -input_format h264 -i /dev/video0 : input from /dev/video0 (Pi Camera) with V4L2 H264 format (see more in V4L2 H264 direct copy ) -c:v copy : directly use H264 video from V4L2 driver -f hls : output in HLS format -hls_time 1 : video chunks are saved in 1-second segments -hls_list_size 30 : playlist has 30 segments -hls_flags delete_segments : delete segments not in the playlist /dev/shm/hls/live.m3u8 : the location of playlist file and video segments ffmpeg -y \\ -input_format h264 -i /dev/video0 \\ -c:v copy \\ -f hls \\ -hls_time 1 \\ -hls_list_size 30 \\ -hls_flags delete_segments \\ /dev/shm/hls/live.m3u8","title":"Create video chunks storage folder"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#create-web-page-to-show-hls-stream","text":"I will use hls.js to play HLS stream. /var/www/html/hls.html <!DOCTYPE html> < html > < head > < meta charset = utf-8 /> < title > HLS Live Stream </ title > </ head > < body > < h1 > HLS Live Stream </ h1 > < script src = \"hls.js\" ></ script > < video id = \"video\" controls autoplay ></ video > < script > var video = document . getElementById ( 'video' ); var videoSrc = 'hls/live.m3u8' ; // First check for native browser HLS support if ( video . canPlayType ( 'application/vnd.apple.mpegurl' )) { video . src = videoSrc ; } // If no native HLS support, check if hls.js is supported else if ( Hls . isSupported ()) { var hls = new Hls (); hls . loadSource ( videoSrc ); hls . attachMedia ( video ); } </ script > </ body > </ html > HLS Performance HLS is good to stream over HTTP but it has delay. At 1024x768 30fps stream with 1-second segments, it still shows a delay of ~10 seconds . You can measure the performance by play your HLS playlist in HLS testing site: https://hls-js.netlify.app/demo/ (need to enable CORS).","title":"Create web page to show HLS stream"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#move-to-mpeg-dash","text":"DASH is the same as HLS, the difference is in the playlist format and the container of segments. Create a new folder in shared memory mkdir -p /dev/shm/dash and make a softlink to the web folder ln -s /dev/shm/dash /var/www/html/dash ffmpeg -y \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -seg_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ /dev/shm/dash/live.mpd /var/www/html/dash.html <!doctype html> < html > < head > < meta charset = utf-8 /> < title > MPEG-DASH Live Stream </ title > </ head > < body > < h1 > MPEG-DASH Live Stream </ h1 > < script src = \"dash.all.min.js\" ></ script > < video id = \"videoPlayer\" controls ></ video > < script > ( function (){ var url = \"dash/live.mpd\" ; var player = dashjs . MediaPlayer (). create (); player . initialize ( document . querySelector ( \"#videoPlayer\" ), url , true ); player . updateSettings ({ streaming : { lowLatencyEnabled : true , liveDelay : 2 , liveCatchup : { minDrift : 0.05 , playbackRate : 1 , latencyThreshold : 30 , } } }); })(); </ script > </ body > </ html > MPEG-DASH Performance MPEG-DASH can achieve ~3 seconds of delay , which is much better than HLS. However, it is still far from real-time live stream. I still need to try Low Latency settings for HLS and MPEG-DASH","title":"Move to MPEG-DASH"},{"location":"posts/raspberrypi/stream_ffmpeg_hls_dash/#a-simple-python-web-server","text":"I am going to make a simple Python HTTP server to stream HLS files. class http . server . SimpleHTTPRequestHandler serves files from its current directory and below, directly mapping the directory structure to HTTP requests. index.html Use hls.js to play HLS Stream. There is extra HLS configs: var config = Hls . DefaultConfig ; config . liveSyncDurationCount = 1 ; config . startFragPrefetch = true ; console . log ( config ); var hls = new Hls ( config ); hls.js HLS Stream player written in Javascript for web server.py This implements a simple HTTP Request Handler based on SimpleHTTPRequestHandler run.sh This script creates a temporary folder in shared memory to store video segments. Then it runs ffmpeg to read camera and write video chunks. Finally it calls HLS_server.py to serve the web. I use ffmpeg to generate both HLS and DASH segments, with some options to reduce latency. ffmpeg -y \\ -input_format h264 \\ -f video4linux2 \\ -framerate 25 \\ -use_wallclock_as_timestamps 1 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -ldash 1 \\ -seg_duration 1 \\ -frag_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ -strict experimental -lhls 1 \\ -hls_playlist 1 -hls_master_name live.m3u8 \\ -utc_timing_url https://time.akamai.com/?iso \\ -write_prft 1 \\ -target_latency 1 \\ /dev/shm/hls/live.mpd & The result is not good as I expected, as there is still about 3.3 seconds of delay in a LAN. Delay in HLS streaming You can't bind to port numbers lower than 1024 as a unprivileged user So you should either: Use a port number larger than 1024 (recommended) Or run the script as a privileged user Harder, but more secure solution if it's really necessary to accept from port numbers lower than 1024: Run the as unprivileged on a higher port, and forward that port to lower port externally. Download stream_ffmpeg_hls.zip","title":"A simple Python Web Server"},{"location":"posts/raspberrypi/stream_mjpeg/","text":"Low latency streaming using MJPEG format Low latency streaming using MJPEG format Big Buck Bunny movie, (c) 2008, Blender Foundation / www.bigbuckbunny.org Download stream_picamera_mjpeg.zip There are many choices to start streaming with MJPEG (MJPG) format. The basic method is to send a series of JPEG (JPG) image to the user's webpage and display it in an <img> tag. If you just want to get the stream, you can go with mjpg-streamer , but if you want to handle each frame before sending out, you can use a Python package named picamera . To setup picamera , please see more in Setup Camera Base start Picamera has an example to stream MJPEG at Web streaming section. You can copy and run their code to see how it works. Record video to a stream \u2693\ufe0e This is a basic step to write video to a buffered memory. Python has io package which provides binary I/O which expects bytes-like objects and produces bytes objects. No encoding, decoding, or newline translation is performed. from io import BytesIO from picamera import PiCamera # create in-memory stream stream = BytesIO () # create camera object (instance) camera = PiCamera () # config camera camera . resolution = ( 640 , 480 ) # start recording to stream camera . start_recording ( stream , format = 'h264' , quality = 23 ) # wait camera . wait_recording ( 15 ) # stop recording camera . stop_recording () That's very easy. Frame buffer \u2693\ufe0e I will create a custom output to used in PiCamera.start_recording() method. Custom outputs Building a custom output object is extremely easy and in certain cases very useful. A file-like object (as far as picamera is concerned) is simply an object with a write(b) method which must accept a single parameter consisting of a byte-string, and which can optionally return the number of bytes written. The object can optionally implement a flush() method with no parameters, which will be called at the end of output. Custom outputs are particularly useful with video recording as the custom output\u2019s write method will be called (at least) once for every frame that is output, allowing you to implement code that reacts to each and every frame without going to the bother of a full custom encoder. However, one should bear in mind that because the write method is called so frequently, its implementation must be sufficiently rapid that it doesn\u2019t stall the encoder (it must perform its processing and return before the next write is due to arrive if you wish to avoid dropping frames). I will write a class FrameBuffer() like below: import io class FrameBuffer ( object ): def __init__ ( self ): # store each frame self . frame = None # buffer to hold incoming frame self . buffer = io . BytesIO () def write ( self , buf ): # if it's a JPEG image if buf . startswith ( b ' \\xff\\xd8 ' ): # write to buffer self . buffer . seek ( 0 ) self . buffer . write ( buf ) # extract frame self . buffer . truncate () self . frame = self . buffer . getvalue () I will use FrameBuffer.frame in other object which will send the frame to user's webpage. Streaming Web server \u2693\ufe0e Python has built-in a simple HTTP Server, which is ready to run by providing a server address and a request handler class. from http.server import HTTPServer , BaseHTTPRequestHandler def run ( server_class = HTTPServer , handler_class = BaseHTTPRequestHandler ): server_address = ( '' , 8000 ) httpd = server_class ( server_address , handler_class ) httpd . serve_forever () Now, look at some pre-defined Request Handler classes: class http . server . BaseHTTPRequestHandler ( request , client_address , server ) This class is used to handle the HTTP requests that arrive at the server. By itself, it cannot respond to any actual HTTP requests; it must be subclassed to handle each request method (e.g. GET or POST). BaseHTTPRequestHandler provides a number of class and instance variables, and methods for use by subclasses. The handler will parse the request and the headers, then call a method specific to the request type. The method name is constructed from the request. For example, for the request method SPAM , the do_SPAM() method will be called with no arguments. All of the relevant information is stored in instance variables of the handler. Subclasses should not need to override or extend the __init__() method. class http . server . SimpleHTTPRequestHandler ( request , client_address , server , directory = None ) This class serves files from the current directory and below, directly mapping the directory structure to HTTP requests. A lot of the work, such as parsing the request, is done by the base class BaseHTTPRequestHandler . This class implements the do_GET() and do_HEAD() functions. class http . server . CGIHTTPRequestHandler ( request , client_address , server ) This class is used to serve either files or output of CGI scripts from the current directory and below. Note that mapping HTTP hierarchic structure to local directory structure is exactly as in SimpleHTTPRequestHandler . The class will however, run the CGI script, instead of serving it as a file, if it guesses it to be a CGI script. Only directory-based CGI are used \u2014 the other common server configuration is to treat special extensions as denoting CGI scripts. The do_GET() and do_HEAD() functions are modified to run CGI scripts and serve the output, instead of serving files, if the request leads to somewhere below the cgi_directories path. Well, the class BaseHTTPRequestHandler is not simple enough to use at this moment, the CGIHTTPRequestHandler is the thing I haven't have any idea about it yet, so let's start with SimpleHTTPRequestHandler . Request Handler \u2693\ufe0e Based on SimpleHTTPRequestHandler , I create a new class StreamingHandler and only override based do_GET() method to just print requested path and then call the base method as it is already implemented. from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): print ( self . path ) # call to parent's method super () . do_GET () SimpleHTTPRequestHandler will serve files in GET requests, and it will looking for index.html for the homepage. I create it with an <img> tag which will request a file named stream.mjpg . < html > < head > < title > Picamea MJPEG Live Stream </ title > </ head > < body > <!-- Request MJPEG stream --> < img src = \"stream.mjpg\" /> </ body > </ html > There is no stream.mjpg file! What I want to do is when the web page request stream.mjpg , web serve should return a stream, not a single file, so I have to write some code to handle this special request of stream.mjpg file: Send response with HTTP Status Code 200 (Successful responses), read more at HTTP response status codes Send header with information to notify web client about type of responded content, read more at Content-Type Send the content in a stream format (loop forever!), send content type of each frame, send the actual frame from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : # response self . send_response ( 200 ) # header self . send_header ( 'Age' , 0 ) self . send_header ( 'Cache-Control' , 'no-cache, private' ) self . send_header ( 'Pragma' , 'no-cache' ) self . send_header ( 'Content-Type' , 'multipart/x-mixed-replace; boundary=FRAME' ) self . end_headers () try : while True : frame = frame_buffer . frame # need frame_buffer as global self . wfile . write ( b '--FRAME \\r\\n ' ) self . send_header ( 'Content-Type' , 'image/jpeg' ) self . send_header ( 'Content-Length' , len ( frame )) self . end_headers () self . wfile . write ( frame ) self . wfile . write ( b ' \\r\\n ' ) except Exception as e : print ( str ( e )) else : super () . do_GET () Here we go, create instances of FrameBuffer, PiCamera, HTTPServer to start streaming: frame_buffer = FrameBuffer () camera = PiCamera ( resolution = '640x480' , framerate = 24 ) camera . start_recording ( frame_buffer , format = 'mjpeg' ) server_address = ( '' , 8000 ) handler_class = StreamingHandler # alias try : httpd = HTTPServer ( server_address , handler_class ) httpd . serve_forever () finally : camera . stop_recording () When I run the above code, the web page shows up but with only one frame displayed, CPU is locked up at 100%, then I think the while True : loop causes the problem. I need to find a way to synchronize between camera thread and web server thread: send a frame only when it is availabe. Synchronize between threads \u2693\ufe0e Python has implemented a lock mechanism between threads: class threading . Condition ( lock = None ) This class implements condition variable objects. A condition variable allows one or more threads to wait until they are notified by another thread. If the lock argument is given and not None , it must be a Lock or RLock object, and it is used as the underlying lock. Otherwise, a new RLock object is created and used as the underlying lock. wait ( timeout = None ) Wait until notified or until a timeout occurs. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. This method releases the underlying lock , and then blocks until it is awakened by a notify() or notify_all() call for the same condition variable in another thread, or until the optional timeout occurs. Once awakened or timed out, it re-acquires the lock and returns. notify_all () Wake up all threads waiting on this condition. This method acts like notify() , but wakes up all waiting threads instead of one. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. I need to add a Condition object in FrameBuffer , and use it in StreamingHandler : from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () # synchronize between threads self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\xff\\xd8 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () # notify other threads self . condition . notify_all () class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : ... try : while True : with frame_buffer . condition : # wait for a new frame frame_buffer . condition . wait () frame = frame_buffer . frame # access global variable, need to change later Wow, it works!!! The latency is just about 200ms which is unachievable with HLS/ MPEG-DASH A low latency in MJPEG streaming However, the CPU usage is quite high, Pi Zero W only can handle 6 clients at the same time with video quality at 640x480 @25fps. Some updates in the script \u2693\ufe0e The instance frame_buffer is used a global variable in the StreamingHandler , it is not good if there is another FrameBuffer used for other stream. I need to pass an instance of FrameBuffer into the instance of StreamingHandler . It can be done by adding Instance variable that holds reference to an instance of FrameBuffer , but can not be done using Class variable . Let's check how they work. Class variable \u2693\ufe0e Class variable is shared by all instance, therefore it acts like a global static attribute of the class. class StreamingHandler ( SimpleHTTPRequestHandler ): # class variable refers to an instance of FrameBuffer my_frame_buffer = None def do_GET ( self ): ... frame = self . my_frame_buffer . frame # create an instance of FrameBuffer frame_buffer = FrameBuffer () handler_class = StreamingHandler # alias # assign class variable handler_class . my_frame_buffer = frame_buffer # all instance will share first_handler = StreamingHandler () second_handler = StreamingHandler () # first_handler.my_frame_buffer will be the same as second_handler.my_frame_buffer Instance variable \u2693\ufe0e Instance variables are for the data unique to each instance, they are create in the constructor of that class __init()__ class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , request , client_address , server , directory = None ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , client_address , server , directory ) def do_GET (): ... However, with this modification, I cannot use StreamingHandler to initialize ThreadingHTTPServer anymore, because it expects to call a request handler with only required positional arguments (request, client_address, server) , not with frame_buffer . I need to write a function that convert expected params list to new params list: frame_buffer = FrameBuffer () def getStreamingHandler ( request , client_address , server ): return StreamingHandler ( frame_buffer , request , client_address , server ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) Well, it works, but my convert function actually drop the param directory in original constructor of SimpleHTTPRequestHandler . I need to reseve all params for possible calls, by using *args and **kwargs *args and **kwargs \u2693\ufe0e *args and **kwargs allow you to pass multiple arguments or keyword arguments to a function. Read about them in here . I change the param list (request, client_address, server, ...) to *args in my code, it looks better: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , * args ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , * args ) frame_buffer = FrameBuffer () def getStreamingHandler ( * args ): return StreamingHandler ( frame_buffer , * args ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) lambda function \u2693\ufe0e Python and other languages like Java, C#, and even C++ have had lambda functions added to their syntax, whereas languages like LISP or the ML family of languages, Haskell, OCaml, and F#, use lambdas as a core concept. Read more in here Ok, I can reduce the function getStreamingHandler to a lambda function which can be declared in-line when creating ThreadingHTTPServer instance: frame_buffer = FrameBuffer () httpd = ThreadingHTTPServer ( address , lambda * args : StreamingHandler ( frame_buffer , * args )) Measure FPS \u2693\ufe0e In the while loop of sending frames, I can use frame_count variable to count the number of processed frames. Using with time package, it is easy to calculate FPS over a defined period, for example, 5 seconds in below code: try : # tracking serving time start_time = time . time () frame_count = 0 # endless stream while True : with self . frames_buffer . condition : # wait for a new frame self . frames_buffer . condition . wait () # it's available, pick it up frame = self . frames_buffer . frame # send it ... # count frames frame_count += 1 # calculate FPS every 5s if ( time . time () - start_time ) > 5 : print ( \"FPS: \" , frame_count / ( time . time () - start_time )) frame_count = 0 start_time = time . time () ... Download stream_picamera_mjpeg.zip","title":"Stream camera using MJPEG format"},{"location":"posts/raspberrypi/stream_mjpeg/#record-video-to-a-stream","text":"This is a basic step to write video to a buffered memory. Python has io package which provides binary I/O which expects bytes-like objects and produces bytes objects. No encoding, decoding, or newline translation is performed. from io import BytesIO from picamera import PiCamera # create in-memory stream stream = BytesIO () # create camera object (instance) camera = PiCamera () # config camera camera . resolution = ( 640 , 480 ) # start recording to stream camera . start_recording ( stream , format = 'h264' , quality = 23 ) # wait camera . wait_recording ( 15 ) # stop recording camera . stop_recording () That's very easy.","title":"Record video to a stream"},{"location":"posts/raspberrypi/stream_mjpeg/#frame-buffer","text":"I will create a custom output to used in PiCamera.start_recording() method. Custom outputs Building a custom output object is extremely easy and in certain cases very useful. A file-like object (as far as picamera is concerned) is simply an object with a write(b) method which must accept a single parameter consisting of a byte-string, and which can optionally return the number of bytes written. The object can optionally implement a flush() method with no parameters, which will be called at the end of output. Custom outputs are particularly useful with video recording as the custom output\u2019s write method will be called (at least) once for every frame that is output, allowing you to implement code that reacts to each and every frame without going to the bother of a full custom encoder. However, one should bear in mind that because the write method is called so frequently, its implementation must be sufficiently rapid that it doesn\u2019t stall the encoder (it must perform its processing and return before the next write is due to arrive if you wish to avoid dropping frames). I will write a class FrameBuffer() like below: import io class FrameBuffer ( object ): def __init__ ( self ): # store each frame self . frame = None # buffer to hold incoming frame self . buffer = io . BytesIO () def write ( self , buf ): # if it's a JPEG image if buf . startswith ( b ' \\xff\\xd8 ' ): # write to buffer self . buffer . seek ( 0 ) self . buffer . write ( buf ) # extract frame self . buffer . truncate () self . frame = self . buffer . getvalue () I will use FrameBuffer.frame in other object which will send the frame to user's webpage.","title":"Frame buffer"},{"location":"posts/raspberrypi/stream_mjpeg/#streaming-web-server","text":"Python has built-in a simple HTTP Server, which is ready to run by providing a server address and a request handler class. from http.server import HTTPServer , BaseHTTPRequestHandler def run ( server_class = HTTPServer , handler_class = BaseHTTPRequestHandler ): server_address = ( '' , 8000 ) httpd = server_class ( server_address , handler_class ) httpd . serve_forever () Now, look at some pre-defined Request Handler classes: class http . server . BaseHTTPRequestHandler ( request , client_address , server ) This class is used to handle the HTTP requests that arrive at the server. By itself, it cannot respond to any actual HTTP requests; it must be subclassed to handle each request method (e.g. GET or POST). BaseHTTPRequestHandler provides a number of class and instance variables, and methods for use by subclasses. The handler will parse the request and the headers, then call a method specific to the request type. The method name is constructed from the request. For example, for the request method SPAM , the do_SPAM() method will be called with no arguments. All of the relevant information is stored in instance variables of the handler. Subclasses should not need to override or extend the __init__() method. class http . server . SimpleHTTPRequestHandler ( request , client_address , server , directory = None ) This class serves files from the current directory and below, directly mapping the directory structure to HTTP requests. A lot of the work, such as parsing the request, is done by the base class BaseHTTPRequestHandler . This class implements the do_GET() and do_HEAD() functions. class http . server . CGIHTTPRequestHandler ( request , client_address , server ) This class is used to serve either files or output of CGI scripts from the current directory and below. Note that mapping HTTP hierarchic structure to local directory structure is exactly as in SimpleHTTPRequestHandler . The class will however, run the CGI script, instead of serving it as a file, if it guesses it to be a CGI script. Only directory-based CGI are used \u2014 the other common server configuration is to treat special extensions as denoting CGI scripts. The do_GET() and do_HEAD() functions are modified to run CGI scripts and serve the output, instead of serving files, if the request leads to somewhere below the cgi_directories path. Well, the class BaseHTTPRequestHandler is not simple enough to use at this moment, the CGIHTTPRequestHandler is the thing I haven't have any idea about it yet, so let's start with SimpleHTTPRequestHandler .","title":"Streaming Web server"},{"location":"posts/raspberrypi/stream_mjpeg/#request-handler","text":"Based on SimpleHTTPRequestHandler , I create a new class StreamingHandler and only override based do_GET() method to just print requested path and then call the base method as it is already implemented. from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): print ( self . path ) # call to parent's method super () . do_GET () SimpleHTTPRequestHandler will serve files in GET requests, and it will looking for index.html for the homepage. I create it with an <img> tag which will request a file named stream.mjpg . < html > < head > < title > Picamea MJPEG Live Stream </ title > </ head > < body > <!-- Request MJPEG stream --> < img src = \"stream.mjpg\" /> </ body > </ html > There is no stream.mjpg file! What I want to do is when the web page request stream.mjpg , web serve should return a stream, not a single file, so I have to write some code to handle this special request of stream.mjpg file: Send response with HTTP Status Code 200 (Successful responses), read more at HTTP response status codes Send header with information to notify web client about type of responded content, read more at Content-Type Send the content in a stream format (loop forever!), send content type of each frame, send the actual frame from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : # response self . send_response ( 200 ) # header self . send_header ( 'Age' , 0 ) self . send_header ( 'Cache-Control' , 'no-cache, private' ) self . send_header ( 'Pragma' , 'no-cache' ) self . send_header ( 'Content-Type' , 'multipart/x-mixed-replace; boundary=FRAME' ) self . end_headers () try : while True : frame = frame_buffer . frame # need frame_buffer as global self . wfile . write ( b '--FRAME \\r\\n ' ) self . send_header ( 'Content-Type' , 'image/jpeg' ) self . send_header ( 'Content-Length' , len ( frame )) self . end_headers () self . wfile . write ( frame ) self . wfile . write ( b ' \\r\\n ' ) except Exception as e : print ( str ( e )) else : super () . do_GET () Here we go, create instances of FrameBuffer, PiCamera, HTTPServer to start streaming: frame_buffer = FrameBuffer () camera = PiCamera ( resolution = '640x480' , framerate = 24 ) camera . start_recording ( frame_buffer , format = 'mjpeg' ) server_address = ( '' , 8000 ) handler_class = StreamingHandler # alias try : httpd = HTTPServer ( server_address , handler_class ) httpd . serve_forever () finally : camera . stop_recording () When I run the above code, the web page shows up but with only one frame displayed, CPU is locked up at 100%, then I think the while True : loop causes the problem. I need to find a way to synchronize between camera thread and web server thread: send a frame only when it is availabe.","title":"Request Handler"},{"location":"posts/raspberrypi/stream_mjpeg/#synchronize-between-threads","text":"Python has implemented a lock mechanism between threads: class threading . Condition ( lock = None ) This class implements condition variable objects. A condition variable allows one or more threads to wait until they are notified by another thread. If the lock argument is given and not None , it must be a Lock or RLock object, and it is used as the underlying lock. Otherwise, a new RLock object is created and used as the underlying lock. wait ( timeout = None ) Wait until notified or until a timeout occurs. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. This method releases the underlying lock , and then blocks until it is awakened by a notify() or notify_all() call for the same condition variable in another thread, or until the optional timeout occurs. Once awakened or timed out, it re-acquires the lock and returns. notify_all () Wake up all threads waiting on this condition. This method acts like notify() , but wakes up all waiting threads instead of one. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. I need to add a Condition object in FrameBuffer , and use it in StreamingHandler : from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () # synchronize between threads self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\xff\\xd8 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () # notify other threads self . condition . notify_all () class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : ... try : while True : with frame_buffer . condition : # wait for a new frame frame_buffer . condition . wait () frame = frame_buffer . frame # access global variable, need to change later Wow, it works!!! The latency is just about 200ms which is unachievable with HLS/ MPEG-DASH A low latency in MJPEG streaming However, the CPU usage is quite high, Pi Zero W only can handle 6 clients at the same time with video quality at 640x480 @25fps.","title":"Synchronize between threads"},{"location":"posts/raspberrypi/stream_mjpeg/#some-updates-in-the-script","text":"The instance frame_buffer is used a global variable in the StreamingHandler , it is not good if there is another FrameBuffer used for other stream. I need to pass an instance of FrameBuffer into the instance of StreamingHandler . It can be done by adding Instance variable that holds reference to an instance of FrameBuffer , but can not be done using Class variable . Let's check how they work.","title":"Some updates in the script"},{"location":"posts/raspberrypi/stream_mjpeg/#class-variable","text":"Class variable is shared by all instance, therefore it acts like a global static attribute of the class. class StreamingHandler ( SimpleHTTPRequestHandler ): # class variable refers to an instance of FrameBuffer my_frame_buffer = None def do_GET ( self ): ... frame = self . my_frame_buffer . frame # create an instance of FrameBuffer frame_buffer = FrameBuffer () handler_class = StreamingHandler # alias # assign class variable handler_class . my_frame_buffer = frame_buffer # all instance will share first_handler = StreamingHandler () second_handler = StreamingHandler () # first_handler.my_frame_buffer will be the same as second_handler.my_frame_buffer","title":"Class variable"},{"location":"posts/raspberrypi/stream_mjpeg/#instance-variable","text":"Instance variables are for the data unique to each instance, they are create in the constructor of that class __init()__ class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , request , client_address , server , directory = None ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , client_address , server , directory ) def do_GET (): ... However, with this modification, I cannot use StreamingHandler to initialize ThreadingHTTPServer anymore, because it expects to call a request handler with only required positional arguments (request, client_address, server) , not with frame_buffer . I need to write a function that convert expected params list to new params list: frame_buffer = FrameBuffer () def getStreamingHandler ( request , client_address , server ): return StreamingHandler ( frame_buffer , request , client_address , server ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) Well, it works, but my convert function actually drop the param directory in original constructor of SimpleHTTPRequestHandler . I need to reseve all params for possible calls, by using *args and **kwargs","title":"Instance variable"},{"location":"posts/raspberrypi/stream_mjpeg/#args-and-kwargs","text":"*args and **kwargs allow you to pass multiple arguments or keyword arguments to a function. Read about them in here . I change the param list (request, client_address, server, ...) to *args in my code, it looks better: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , * args ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , * args ) frame_buffer = FrameBuffer () def getStreamingHandler ( * args ): return StreamingHandler ( frame_buffer , * args ) httpd = ThreadingHTTPServer ( address , getStreamingHandler )","title":"*args and **kwargs"},{"location":"posts/raspberrypi/stream_mjpeg/#lambda-function","text":"Python and other languages like Java, C#, and even C++ have had lambda functions added to their syntax, whereas languages like LISP or the ML family of languages, Haskell, OCaml, and F#, use lambdas as a core concept. Read more in here Ok, I can reduce the function getStreamingHandler to a lambda function which can be declared in-line when creating ThreadingHTTPServer instance: frame_buffer = FrameBuffer () httpd = ThreadingHTTPServer ( address , lambda * args : StreamingHandler ( frame_buffer , * args ))","title":"lambda function"},{"location":"posts/raspberrypi/stream_mjpeg/#measure-fps","text":"In the while loop of sending frames, I can use frame_count variable to count the number of processed frames. Using with time package, it is easy to calculate FPS over a defined period, for example, 5 seconds in below code: try : # tracking serving time start_time = time . time () frame_count = 0 # endless stream while True : with self . frames_buffer . condition : # wait for a new frame self . frames_buffer . condition . wait () # it's available, pick it up frame = self . frames_buffer . frame # send it ... # count frames frame_count += 1 # calculate FPS every 5s if ( time . time () - start_time ) > 5 : print ( \"FPS: \" , frame_count / ( time . time () - start_time )) frame_count = 0 start_time = time . time () ... Download stream_picamera_mjpeg.zip","title":"Measure FPS"},{"location":"posts/stm32/intro/","text":"ARM Based Processors \u2693\ufe0e ARM processors use Reduced Instruction Set Computing (RISC) architectures, and nowadays have many revisions (ARMv6, ARMv6-M, ARMv7, ARMv7-A, etc.,). An ARM architecture is a set of specifications regarding the instruction set , the execution model, the memory organization and layout, the instruction cycles and more, which describes precisely a machine that will implement said architecture. ARM Cortex is a wide set of 32/64-bit architectures and cores really popular in the embedded world. Cortex microcontrollers are divided into three main subfamilies: Cortex-A, which stands for Application, is a series of processors providing a range of solutions for devices undertaking complex computing tasks, such as hosting a rich Operating System (OS) platform (Linux and its derivative Android are the most common ones), and supporting multiple software applications. Cortex-M, which stands for eMbedded, is a range of scalable, compatible, energy efficient and easy to use processors designed for the low-cost embedded market. The Cortex-M family is optimized for cost and power sensitive MCUs suitable for single applications on small devices. Cortex-R, which stand for Real-Time, is a series of processors offering high-performance computing solutions for embedded systems where reliability, high availability, fault tolerance, maintainability and deterministic real-time response are essential. Core Registers \u2693\ufe0e Like all RISC architectures, Cortex-M processors perform operations on CPU registers and load/save data from/to memory locations. There are some General Purpose Registers numbered as R0 to R12 and some Specific Registers have alias names such as R13 (Stack Pointer) or R15 (Program Counter) . ARM Contex-M Registers Memory Map \u2693\ufe0e ARM defines a standardized memory address space common to all Cortex-M cores, which ensures code portability among different silicon manufacturer. The address space is 4 GB wide, and it is organized in several sub-regions with different logical functionalities, such as the first 512 MB are dedicated to code area. All Cortex-M processors map the code area starting at address 0x00000000 which has the pointers to the beginning of the Stack , to the Reset Handler , and Vectors Table for MCUs to start. The internal MCU flash memory is the area where program code resides, and it locates at 0x08000000 . In the Code Area, there are Flash space, System Memory (in ROM) space, and Options Bytes (in Flash) space, which are used for storing firmware code, bootloader, and system configurations. Depending on BOOT configuration (BOOT pins, and Boot Option in Option Bytes), system will boot from either SRAM, or FLash, or System Memory. Because system always boots at the startup address 0x00000000 , there is a mapping method to make SRAM, Flash, or System Memory be aliased from the startup address. It means, fox example, data on the aliased Flash area with offset 0x00001234 can be refereed from either the original address 0x08001234 or from the aliased address 0x00001234 . ARM Cortex-M Memory Map ARM Cortex-M Memory Map in Code Area Exceptions Handling \u2693\ufe0e Interrupts and Exceptions are asynchronous events that alter the program flow. When an exception or an interrupt occurs, the CPU suspends the execution of the current task, saves its context (that is, its stack pointer) and starts the execution of a routine designed to handle the interrupting event. This routine is called Exception Handler in case of exceptions and Interrupt Service Routine (ISR) in case of an interrupt. After the exception or interrupt has been handled, the CPU resumes the previous execution flow, and the previous task can continue its execution. In the ARM architecture, interrupts are one type of exception. Interrupts are usually generated from on-chip peripherals (e.g., a timer) or external inputs (e.g. a tactile switch connected to a GPIO), and in some cases they can be triggered by software. Exceptions are, instead, related to software execution, and the CPU itself can be a source of exceptions. These could be fault events such as an attempt to access an invalid memory location, or events generated by the Operating System, if any. Each exception (and hence interrupt) has a number which uniquely identifies it. This number reflects the position of the exception handler routine inside the vector table, where the actual address of the routine is stored. Number Exception Type Priority Function 1 Reset -3 Reset Handler 2 NMI -2 Non-maskable Interrupt 3 Hard Fault -1 All classes of Fault which is not handled 4 Memory Management Configurable MPU Fault 5 Bus Fault Configurable Pre-fetch or Memory access Fault 6 Usage Fault Configurable Undefined instruction or Illegal state 7~10 - - Reserved 11 SVCall Configurable System Call 12 Debug Monitor Configurable Software-based Debugger 13 - - Reserved 14 Pending SV Configurable Pending request for System Service 15 SysTick Configurable System Timer has fired every tick 16~ IRQ Configurable Interrupt Request CMIS \u2693\ufe0e Cortex Microcontroller Software Interface Standard (CMSIS) is a vendor-independent hardware abstraction layer for the Cortex-M processor series and specifies debugger interfaces. The CMSIS consists of the following components: CMSIS-CORE: API for the Cortex-M processor core and peripherals. It provides a standardized interface for Cortex-M0/3/4/7 CMSIS-Driver: defines generic peripheral driver interfaces for middleware making them reusable across supported devices. The API is RTOS independent and connects microcontroller peripherals to middleware which implements, amongst other things, communication stacks, file systems or graphical user interfaces CMSIS-RTOS: Common APIs for Real-Time Operating Systems . It provides a standardized programming interface which is portable to many RTOS and therefore enables software templates, middleware, libraries, and other components which can work across supported RTOS systems. STM32 MCUs \u2693\ufe0e MCU Families \u2693\ufe0e STM32 is a broad range of microcontrollers divided in nine sub-families, each one with its features. Internally, each microcontroller consists of the processor core, static RAM, flash memory, debugging interface, and various other peripherals. Some MCUs provide additional types of memory (EEPROM, CCM, etc.), and a whole line of devices targeting low-power applications is continuously growing. Here are advantages of using STM32 MCUs: Cortex-M based MCUs with large community, free tool-chain, and many shared knowledge articles. Pin-to-Pin compatibility for most of STM32 MCUs, which helps you to change the MCU while keeping pin assignments 5 V tolerant means you can interface with other devices which do not use 3.3 V without using level shifter. Cheap is an advantage of using STM32 MCUs with ARM based processors and supported RTOS. Integrated bootloader is shipped with internal ROM which allows to reprogram the internal flash memory using some communication peripherals (USART, I\u00b2C, etc.) STM32 F051 Discovery Board STM32 L0538 Discovery Board STM32 Nucleo family boards You can choose any board to try but it is recommended to start with F0 families as it is easy to learn with small number of pins, and then you can move to F4 families to learn most of available features in STM32 MCUs. Here is some brief information about STM32 MCUs families: STM32 Families Features F0 ARM Cortex-M0 core at a maximum clock rate of 48 MHz Up-to 32 KB SRAM, 256 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) F1 ARM Cortex-M3 core at a maximum clock rate ranging from 24 MHz to 72 MHz Up-to 96 KB SRAM, 256 KB Flash, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 80 fast I/Os, 5 V tolerant F2 ARM Cortex-M3 core at a maximum clock rate of 120 MHz Up-to 128 KB SRAM, 1024 KB Flash, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant F3 ARM Cortex-M4F core at a maximum clock rate of 72 MHz Up-to 80 KB SRAM, 512 KB Flash, 128 B Backup Memory, 8 KB Core Coupled Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant Ultra-fast comparators (25 ns) Op-amp with programmable gain Ultra-fast 12-bit ADCs Precise 16-bit sigma-delta ADC F4 ARM Cortex-M4F core at a maximum clock ranging from 84 to 180 MHz Up-to 384 KB SRAM, 2048 KB Flash, 64 KB Coupled Memory, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant I2S and Audio PLL F7 ARM Cortex-M7 core at a maximum clock of 216 MHz Up-to 512 Kb SRAM, 2048 KB Flash, 16 KB + 16 KB L1 Cache Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 164 fast I/Os, 5 V tolerant Double-precision FPU, SAI, Audio PLL, CAN, USB OTG, HDMI-ECE, Ethernet H7 ARM Cortex-M7 core at a maximum clock of 400 MHz Up-to 1024 KB SRAM, 2048 KB Flash, 16 KB + 16 KB L1 Cache Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 164 fast I/Os, 5 V tolerant 14-bit ADC, SAI, Double-precision FPU, CAN, Audio PLL Support to SDMMC and FSMC interfaces L0 ARM Cortex-M0+ core at a maximum clock rate of 32 MHz Up-to 8 KB SRAM, 64 KB Flash, 20 B Backup Memory, 2 KB EEPROM Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Ultra-low-power mode + backup register: 250 nA Wake-up time: 3.5 \u00b5s L1 ARM Cortex-M3 core with FPU at a maximum clock rate of 32 MHz Up-to 320 KB SRAM, 1024 KB Flash, 20 B Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Ultra-low-power mode + backup register: 250 nA Wake-up time: 3.5 \u00b5s L4 ARM Cortex-M4F core with FPU at a maximum clock rate of 80 MHz Up-to 320 KB SRAM, 1024 KB Flash, 20 B Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to SDMMC and FSMC interfaces Ultra-low-power mode: 30 nA baseline of current comsumption L4+ ARM Cortex-M4F core with FPU at a maximum clock rate of 120 MHz. Up-to 640 KB SRAM, 2048 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to SDMMC and FSMC interfaces Ultra-low-power mode: 20 nA baseline of current comsumption Wake-up time: 5 \u03bcs. Dynamic run mode: down to 43 \u03bcA/MHz. WB ARM Cortex-M4F core with FPU at a maximum clock rate of 64 MHz, or ARM Cortex-M0+ core a maximum clock rate of 32 MHz Up-to 256 KB SRAM, 1024 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to Quad-SPI interface BLE 5.0 compatible radio front-end and stack. IEEE 802.15.4 compatible radio front-end ART(tm) Accelerator Select your MCU \u2693\ufe0e If you are going to develop a CPU intensive application , focused on multimedia and graphic applications, then you have to shift our attention to the High-Performance group of STM32 microcontrollers. If, on the other hand, the computing power is not the main requirement of our electronic device, you can focus on the Mainstream segment, giving a close look at the STM32F1 series which offers the most extensive selection to choose from. If you need to interact with the external world through an Ethernet connection or other industrial protocols such as a CAN bus , and our application has to be responsive and able to deal with several Internet Protocols , then the STM32F4 portfolio is probably your best option. If you are going to develop a battery-powered device, then you have to look at the STM32L selection. STM32CubeIDE \u2693\ufe0e While there are many Integrated Development Environment (IDE) software can be used to develop applications on ARM Cortex-M MCUs, ST has their own free STM32CubeIDE , easy-to-use, fully-featured IDE for STM32 MCUs. STM32CubeIDE is an advanced C/C++ development platform with peripheral configuration , code generation , code navigation , code compilation , programmer and debugger for STM32 microcontrollers and microprocessors. It is based on the Eclipse\u00ae/CDT framework and GCC toolchain for the development, and GDB for the debugging. It allows the integration of the hundreds of existing plugins that complete the features of the Eclipse\u00ae IDE. Download at: https://www.st.com/en/development-tools/stm32cubeide.html STM32CubeIDE is a complete toolchain for ST's STM32 MCUs, you can read more about ARM Toolchain & Makefile . Key Features Integration of services from STM32CubeMX: STM32 microcontroller, microprocessor, development platform and example project selection Pinout, clock, peripheral, and middleware configuration Project creation and generation of the initialization code Software and middleware completed with enhanced STM32Cube Expansion Packages Based on Eclipse\u00ae/CDT, with support of Eclipse\u00ae add-ons, GNU C/C++ for Arm\u00ae toolchain and GDB debugger Additional advanced debug features including: CPU core, peripheral register, and memory views Live variable watch view System analysis and real-time tracing (SWV) CPU fault analysis tool Support of ST-LINK (STMicroelectronics) and J-Link (SEGGER) debug probes Import project from Atollic\u00ae TrueSTUDIO\u00ae and AC6 System Workbench for STM32 (SW4STM32) Multi-OS support: Windows\u00ae, Linux\u00ae, and macOS\u00ae, 64-bit versions only Create a new project \u2693\ufe0e 1. Start new project \u2693\ufe0e It is recommended to start a new project with STM32CudeIDE as it will automatically configure your project for your target MCU. you also can convert other type of projects to STM32CudeIDE project. Sometimes, you have to re-configure settings manually if the IDE cannot do it for you. Welcome screen of STM32CudeIDE 2. Choose the target MCU \u2693\ufe0e You can search for your target MCU by using Selectors: MCU/MPU Name, Board, Example, or Customer Filters. Select your target MCU 3. Select Firmware Library Package \u2693\ufe0e You will be able to choose the Targeted Language as C or C++, Binary Type , and the Firmware Package Setup settings for a new project At the beginning level, it is recommended to let STM32CubeIDE initialize all peripherals with their default mode. If you select a discovery board, the IDE will assign pins and generate code based on the settings on your selected boards, such as LEDs, Buttons, and Serial Wire Debug (SWD). 4. Configure target device \u2693\ufe0e You will be started with Device Configuration Tool which is known as STM32CubeMX to start setting up your MCU with interactive components. The first tab is Pinout & Configuration in which you can select on available modules to configure them. Pinout View is a great view to see the pin assignment for your MCU. you can quickly assign a function to a pin by left click on that pin. There will be a popup with a list of functions which can be assigned. If you right click on the pin, you can assign a readable friendly name for it. Pin assignment If you click on a specific module, there is a detail page for you to config that modules, including Name, Pin, Pin Type, Interrupt, DMA, or any other available settings. GPIO configuration The Clock Configuration show the clock paths across your devices from the clock source to the modules. It also allows you to change the multiplier of clock path to increase or decrease the clock frequency. Clock Configuration In the Project Manager tab, you can change some advanced functions of STM32CubeMX such as the size of Heap and Stack, Code Generation. You should leave them default unless you understand about these settings. Project Manager 5. Generate Code \u2693\ufe0e If you save your project ( Ctrl + S ) in Device Configuration Tool it will automatically generate code for you, based on your settings. you can press Alt + K or choose the menu Project > Generate Code too. When you choose to use a Firmware Library in your project, IDE automatically uses ST Hardware Abstract Layer (HAL) library as the main way of controlling your processor. HAL also makes use of CMSIS library to access processor's registers. Let's an example of using STM32F0 MCU: Code dependency starts from your startup_stm32f0xx.s file. This file include main.h which then includes HAL files which eventually include CMSIS files. The startup file also call to your main function in main.c to run your program. Generated Code Structure #table1 table, #table2 table { table-layout: fixed; } File Description stm32f0xx_hal.h This file is used for HAL initialization and contains DBGMCU, Time Delay based on SysTick APIs. This also include stm32f0xx_hal_def.h stm32f0xx_hal_def.h Common HAL resources such as common define statements, enumerations, structures and macros. This includes CMSIS. headers stm32f0xx_hal_ppp.h/.c Main peripheral/module driver file. It includes the APIs that are common to all STM32 devices. Example: stm32f0xx_hal_adc.c , stm32f0xx_hal_irda.c . stm32f0xx_hal_ppp_ex.h/.c Extension file of the peripheral/module ppp driver. It includes the specific APIs for a given part number or family, as well as the newly defined APIs that overwrite the default generic APIs if the internal process is implemented in different way. Example: stm32f0xx_hal_adc_ex.c , stm32f0xx_hal_flash_ex.c . The minimum files required to build an application using the HAL are listed in the table below: File Description startup_stm32f0xx.s Toolchain specific file that contains reset handler and exception vectors. For some toolchains, it allows adapting the stack/heap size to fit the application requirements system_stm32f0xx.c This file contains SystemInit() which is called at startup just after reset and before branching to the main program. It does not configure the system clock at startup (contrary to the standard library). This is to be done using the HAL APIs in the user files. It allows relocating the vector table in internal SRAM. stm32f0xx_hal_conf.h This file allows the user to customize the HAL drivers for a specific application. It is not mandatory to modify this configuration. The application can use the default configuration without any modification. This call to STM32F0 HAL headers. stm32f0xx_hal_msp.c This file contains the MSP initialization and de-initialization (main routine and callbacks) of the peripheral used in the user application. stm32f0xx_it.h/.c This file contains the exceptions handler and peripherals interrupt service routine, and calls HAL_IncTick() at regular time intervals to increment a local variable (declared in stm32f0xx_hal.c ) used as HAL timebase. By default, this function is called each 1ms in SysTick ISR. The PPP_IRQHandler() routine must call HAL_PPP_IRQHandler() if an interrupt based process is used within the application. main.h/.c This file contains the main program routine, mainly: \u2022 Call to HAL_Init() \u2022 assert_failed() implementation \u2022 system clock configuration \u2022 peripheral HAL initialization and user application code. 6. Write your code \u2693\ufe0e The generayed code has some block marked with pairs of comments /* USER CODE BEGIN */ and /* USER CODE END */ . Inside those pairs, you can write your code and they will be untouched by STM32CubeMX when it it re-generates new code. For example: main.c /* Private includes */ /* USER CODE BEGIN Includes */ < YOUR CODE HERE > #include <stdio.h> /* USER CODE END Includes */ /* Private define */ /* USER CODE BEGIN PD */ < YOUR CODE HERE > #define SECRET_NUMBER 0x12345678 /* USER CODE END PD */ /* Private variables */ /* USER CODE BEGIN PV */ < YOUR CODE HERE > uint8_t key = 0xFF ; /* USER CODE END PV */ int main ( void ) { HAL_Init (); SystemClock_Config (); MX_GPIO_Init (); /* Infinite loop */ /* USER CODE BEGIN WHILE */ < YOUR CODE HERE > HAL_GPIO_WritePin ( Green_Led_GPIO_Port , Green_Led_Pin , GPIO_PIN_SET ); while ( 1 ) { < YOUR CODE HERE > HAL_GPIO_TogglePin ( Blue_Led_GPIO_Port , Blue_Led_Pin ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ < YOUR CODE HERE > } /* USER CODE END 3 */ } 7. Run on board \u2693\ufe0e First, you must compile your code by press Ctrl + B , or menu Project > Build Project Memory report after compilation Then after you connect the cable from your board to your computer, press F11 or Run > Debug to download your code to board and start debugging session. Your application will paused at the main() function by default. Press F8 to Resume . Related documents \u2693\ufe0e In embedded programming, documents have a very important role as they are the main reference source for developer to know how the processor works and how to configure it. Those documents mainly come from the processor manufacture, it means you can download it from the manufacture website. STM32CudeIDE has a better way to list all related documents of selected processor, and it can download documents for you. you can find the documents in menu Help > Target device docs and resources . Open documents browser Related documents for selected STM32F051R8 MCUs Here is the list of important documents you have to read in order to understand about the processor and its peripherals: Example documents are for STM32F051 MCUs. Board Manual & Schematic \u2693\ufe0e UM1525 - Discovery kit for STM32F0 microcontrollers https://my.st.com/resource/en/user_manual/dm00050135-stm32f0discovery-discovery-kit-for-stm32-f0-microcontrollers-stmicroelectronics.pdf Main content includes: Hardware components and their locations and markers Pinouts and jumpers for connections or configurations Solder Bridges for enabling/disabling features or hardware connections MB1034 RevB.0 - STM32F0-DISCOVERY Schematic https://my.st.com/resource/en/schematic_pack/stm32f0discovery_sch.zip This document show the wires between all hardware components. Reading this document can help to understand: Input and Output characteristics (Pull-up, Pull-down, Open, Voltage level) Connection points (internal wires, connectors) Working conditions (Power level, Voltage Level torelance) Processor Datasheet \u2693\ufe0e PM0215 - STM32F0xxx Cortex-M0 programming manual https://my.st.com/resource/en/programming_manual/dm00051352-stm32f0xxx-cortexm0-programming-manual-stmicroelectronics.pdf The main content is: Processor modes: in application and interruption routine Stacks: manage context's data Core Registers: contain instruction's data and result, system status Memory Model: fixed memory map with address ranges Vector Table: start address, stack pointer, and interruption handlers Sleep mode: condition about clock, data rate, register mode Instruction set: assembly mnemonic for instructions Core registers: Address and Name of registers used in core and peripherals. This is the based for progamming the processor. It also have API function name for accessing the registers using CMSIS. DS8668 - STM32F051x4/6/8 Datasheet https://www.st.com/resource/en/datasheet/stm32f051r8.pdf This document shows below information: Functional features Memory Mapping, Boot Mode Pinouts and alternative functions Core and Peripherals' diagrams, protocols RM0091 - Reference manual for STM32F0x1/STM32F0x2/STM32F0x8 advanced ARM-based 32-bit MCUs https://www.st.com/resource/en/reference_manual/dm00031936-stm32f0x1stm32f0x2stm32f0x8-advanced-armbased-32bit-mcus-stmicroelectronics.pdf This is a very important document as it defines all register structure, bit-fields to control core and peripherals . This document includes: System Architecture, Register-Level designs Memory Mapping and Boot configuration Register name and bit-fields for all accessible registers Library Manual \u2693\ufe0e UM1785 - Description of STM32F0 HAL and low-layer drivers https://www.st.com/resource/en/user_manual/dm00122015-description-of-stm32f0-hal-and-lowlayer-drivers-stmicroelectronics.pdf This document describes HAL and LL APIs for programming. Those functions wrap all internal registers and settings, and create a friendly function names and data structure for developer. The HAL drivers include a set of driver modules, each module being linked to a standalone peripheral. The HAL main features are the following: Cross-family portable set of APIs covering the common peripheral features as well as extension APIs in case of specific peripheral features. Three API programming models: polling, interrupt and DMA. APIs are RTOS compliant: Fully reentrant APIs Systematic usage of timeouts in polling mode Support of peripheral multi-instance allowing concurrent API calls for multiple instances of a given peripheral (USART1, USART2...) All HAL APIs implement user-callback functions mechanism: Peripheral Init/DeInit HAL APIs can call user-callback functions to perform peripheral system level. Initialization/De-Initialization (clock, GPIOs, interrupt, DMA) Peripherals interrupt events Error events Object locking mechanism: safe hardware access to prevent multiple spurious accesses to shared resources Timeout used for all blocking processes: the timeout can be a simple counter or a timebase UM1722 - Developing applications on STM32Cube with RTOS https://www.st.com/resource/en/user_manual/dm00105262-developing-applications-on-stm32cube-with-rtos-stmicroelectronics.pdf This document is a reference to program user application in RTOS. This document has below content: FreeRTOS: overview, APIs, memory management, low power managements, and configuration CMSIS-RTOS: a higher layer to communicate between CMSIS and FreeRTOS Usage to create thread, use Semaphore, Queues, and Timer CMSIS - Cortex Microcontroller Software Interface Standard https://developer.arm.com/tools-and-software/embedded/cmsis https://developer.arm.com/embedded/cmsis/cmsis-packs/devices/STMicroelectronics/STM32F051R8 ARM develops the Cortex Microcontroller Software Interface Standard (CMSIS) to allow microcontroller and software vendor to use a consistent software infrastructure to develop software solutions for Cortex-M microcontroller. It is a set of APIs for application or middleware developers to access the features on the Cortex-M processor regardless of the microcontroller devices or toolchain used. To use the CMSIS-Core (Cortex-M) the following files are added to the embedded application: Startup File startup_<device>.c with reset handler and exception vectors. System Configuration Files system_<device>.c and system_<device>.h with general device configuration (i.e. for clock and BUS setup). Device Header File <device.h> gives access to processor core and all peripherals. Register names and bit-fields are defined in the Reference Manual of the process Conclusion \u2693\ufe0e By reading to this point, I hope you can get an overview of what STM32 MCUs are, how to run a simple project with STM32CubeIDE, and where to find more information about your target MCUs.","title":"Introduction to STM32 MCUs"},{"location":"posts/stm32/intro/#arm-based-processors","text":"ARM processors use Reduced Instruction Set Computing (RISC) architectures, and nowadays have many revisions (ARMv6, ARMv6-M, ARMv7, ARMv7-A, etc.,). An ARM architecture is a set of specifications regarding the instruction set , the execution model, the memory organization and layout, the instruction cycles and more, which describes precisely a machine that will implement said architecture. ARM Cortex is a wide set of 32/64-bit architectures and cores really popular in the embedded world. Cortex microcontrollers are divided into three main subfamilies: Cortex-A, which stands for Application, is a series of processors providing a range of solutions for devices undertaking complex computing tasks, such as hosting a rich Operating System (OS) platform (Linux and its derivative Android are the most common ones), and supporting multiple software applications. Cortex-M, which stands for eMbedded, is a range of scalable, compatible, energy efficient and easy to use processors designed for the low-cost embedded market. The Cortex-M family is optimized for cost and power sensitive MCUs suitable for single applications on small devices. Cortex-R, which stand for Real-Time, is a series of processors offering high-performance computing solutions for embedded systems where reliability, high availability, fault tolerance, maintainability and deterministic real-time response are essential.","title":"ARM Based Processors"},{"location":"posts/stm32/intro/#core-registers","text":"Like all RISC architectures, Cortex-M processors perform operations on CPU registers and load/save data from/to memory locations. There are some General Purpose Registers numbered as R0 to R12 and some Specific Registers have alias names such as R13 (Stack Pointer) or R15 (Program Counter) . ARM Contex-M Registers","title":"Core Registers"},{"location":"posts/stm32/intro/#memory-map","text":"ARM defines a standardized memory address space common to all Cortex-M cores, which ensures code portability among different silicon manufacturer. The address space is 4 GB wide, and it is organized in several sub-regions with different logical functionalities, such as the first 512 MB are dedicated to code area. All Cortex-M processors map the code area starting at address 0x00000000 which has the pointers to the beginning of the Stack , to the Reset Handler , and Vectors Table for MCUs to start. The internal MCU flash memory is the area where program code resides, and it locates at 0x08000000 . In the Code Area, there are Flash space, System Memory (in ROM) space, and Options Bytes (in Flash) space, which are used for storing firmware code, bootloader, and system configurations. Depending on BOOT configuration (BOOT pins, and Boot Option in Option Bytes), system will boot from either SRAM, or FLash, or System Memory. Because system always boots at the startup address 0x00000000 , there is a mapping method to make SRAM, Flash, or System Memory be aliased from the startup address. It means, fox example, data on the aliased Flash area with offset 0x00001234 can be refereed from either the original address 0x08001234 or from the aliased address 0x00001234 . ARM Cortex-M Memory Map ARM Cortex-M Memory Map in Code Area","title":"Memory Map"},{"location":"posts/stm32/intro/#exceptions-handling","text":"Interrupts and Exceptions are asynchronous events that alter the program flow. When an exception or an interrupt occurs, the CPU suspends the execution of the current task, saves its context (that is, its stack pointer) and starts the execution of a routine designed to handle the interrupting event. This routine is called Exception Handler in case of exceptions and Interrupt Service Routine (ISR) in case of an interrupt. After the exception or interrupt has been handled, the CPU resumes the previous execution flow, and the previous task can continue its execution. In the ARM architecture, interrupts are one type of exception. Interrupts are usually generated from on-chip peripherals (e.g., a timer) or external inputs (e.g. a tactile switch connected to a GPIO), and in some cases they can be triggered by software. Exceptions are, instead, related to software execution, and the CPU itself can be a source of exceptions. These could be fault events such as an attempt to access an invalid memory location, or events generated by the Operating System, if any. Each exception (and hence interrupt) has a number which uniquely identifies it. This number reflects the position of the exception handler routine inside the vector table, where the actual address of the routine is stored. Number Exception Type Priority Function 1 Reset -3 Reset Handler 2 NMI -2 Non-maskable Interrupt 3 Hard Fault -1 All classes of Fault which is not handled 4 Memory Management Configurable MPU Fault 5 Bus Fault Configurable Pre-fetch or Memory access Fault 6 Usage Fault Configurable Undefined instruction or Illegal state 7~10 - - Reserved 11 SVCall Configurable System Call 12 Debug Monitor Configurable Software-based Debugger 13 - - Reserved 14 Pending SV Configurable Pending request for System Service 15 SysTick Configurable System Timer has fired every tick 16~ IRQ Configurable Interrupt Request","title":"Exceptions Handling"},{"location":"posts/stm32/intro/#cmis","text":"Cortex Microcontroller Software Interface Standard (CMSIS) is a vendor-independent hardware abstraction layer for the Cortex-M processor series and specifies debugger interfaces. The CMSIS consists of the following components: CMSIS-CORE: API for the Cortex-M processor core and peripherals. It provides a standardized interface for Cortex-M0/3/4/7 CMSIS-Driver: defines generic peripheral driver interfaces for middleware making them reusable across supported devices. The API is RTOS independent and connects microcontroller peripherals to middleware which implements, amongst other things, communication stacks, file systems or graphical user interfaces CMSIS-RTOS: Common APIs for Real-Time Operating Systems . It provides a standardized programming interface which is portable to many RTOS and therefore enables software templates, middleware, libraries, and other components which can work across supported RTOS systems.","title":"CMIS"},{"location":"posts/stm32/intro/#stm32-mcus","text":"","title":"STM32 MCUs"},{"location":"posts/stm32/intro/#mcu-families","text":"STM32 is a broad range of microcontrollers divided in nine sub-families, each one with its features. Internally, each microcontroller consists of the processor core, static RAM, flash memory, debugging interface, and various other peripherals. Some MCUs provide additional types of memory (EEPROM, CCM, etc.), and a whole line of devices targeting low-power applications is continuously growing. Here are advantages of using STM32 MCUs: Cortex-M based MCUs with large community, free tool-chain, and many shared knowledge articles. Pin-to-Pin compatibility for most of STM32 MCUs, which helps you to change the MCU while keeping pin assignments 5 V tolerant means you can interface with other devices which do not use 3.3 V without using level shifter. Cheap is an advantage of using STM32 MCUs with ARM based processors and supported RTOS. Integrated bootloader is shipped with internal ROM which allows to reprogram the internal flash memory using some communication peripherals (USART, I\u00b2C, etc.) STM32 F051 Discovery Board STM32 L0538 Discovery Board STM32 Nucleo family boards You can choose any board to try but it is recommended to start with F0 families as it is easy to learn with small number of pins, and then you can move to F4 families to learn most of available features in STM32 MCUs. Here is some brief information about STM32 MCUs families: STM32 Families Features F0 ARM Cortex-M0 core at a maximum clock rate of 48 MHz Up-to 32 KB SRAM, 256 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) F1 ARM Cortex-M3 core at a maximum clock rate ranging from 24 MHz to 72 MHz Up-to 96 KB SRAM, 256 KB Flash, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 80 fast I/Os, 5 V tolerant F2 ARM Cortex-M3 core at a maximum clock rate of 120 MHz Up-to 128 KB SRAM, 1024 KB Flash, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant F3 ARM Cortex-M4F core at a maximum clock rate of 72 MHz Up-to 80 KB SRAM, 512 KB Flash, 128 B Backup Memory, 8 KB Core Coupled Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant Ultra-fast comparators (25 ns) Op-amp with programmable gain Ultra-fast 12-bit ADCs Precise 16-bit sigma-delta ADC F4 ARM Cortex-M4F core at a maximum clock ranging from 84 to 180 MHz Up-to 384 KB SRAM, 2048 KB Flash, 64 KB Coupled Memory, 4 KB Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 136 fast I/Os, 5 V tolerant I2S and Audio PLL F7 ARM Cortex-M7 core at a maximum clock of 216 MHz Up-to 512 Kb SRAM, 2048 KB Flash, 16 KB + 16 KB L1 Cache Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 164 fast I/Os, 5 V tolerant Double-precision FPU, SAI, Audio PLL, CAN, USB OTG, HDMI-ECE, Ethernet H7 ARM Cortex-M7 core at a maximum clock of 400 MHz Up-to 1024 KB SRAM, 2048 KB Flash, 16 KB + 16 KB L1 Cache Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Up-to 164 fast I/Os, 5 V tolerant 14-bit ADC, SAI, Double-precision FPU, CAN, Audio PLL Support to SDMMC and FSMC interfaces L0 ARM Cortex-M0+ core at a maximum clock rate of 32 MHz Up-to 8 KB SRAM, 64 KB Flash, 20 B Backup Memory, 2 KB EEPROM Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Ultra-low-power mode + backup register: 250 nA Wake-up time: 3.5 \u00b5s L1 ARM Cortex-M3 core with FPU at a maximum clock rate of 32 MHz Up-to 320 KB SRAM, 1024 KB Flash, 20 B Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Ultra-low-power mode + backup register: 250 nA Wake-up time: 3.5 \u00b5s L4 ARM Cortex-M4F core with FPU at a maximum clock rate of 80 MHz Up-to 320 KB SRAM, 1024 KB Flash, 20 B Backup Memory Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to SDMMC and FSMC interfaces Ultra-low-power mode: 30 nA baseline of current comsumption L4+ ARM Cortex-M4F core with FPU at a maximum clock rate of 120 MHz. Up-to 640 KB SRAM, 2048 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to SDMMC and FSMC interfaces Ultra-low-power mode: 20 nA baseline of current comsumption Wake-up time: 5 \u03bcs. Dynamic run mode: down to 43 \u03bcA/MHz. WB ARM Cortex-M4F core with FPU at a maximum clock rate of 64 MHz, or ARM Cortex-M0+ core a maximum clock rate of 32 MHz Up-to 256 KB SRAM, 1024 KB Flash Basic Peripherals (WDT, CRC, RTC, TMR, ADC, DMA, USART, SWD, SPI, I2C) Support to Quad-SPI interface BLE 5.0 compatible radio front-end and stack. IEEE 802.15.4 compatible radio front-end ART(tm) Accelerator","title":"MCU Families"},{"location":"posts/stm32/intro/#select-your-mcu","text":"If you are going to develop a CPU intensive application , focused on multimedia and graphic applications, then you have to shift our attention to the High-Performance group of STM32 microcontrollers. If, on the other hand, the computing power is not the main requirement of our electronic device, you can focus on the Mainstream segment, giving a close look at the STM32F1 series which offers the most extensive selection to choose from. If you need to interact with the external world through an Ethernet connection or other industrial protocols such as a CAN bus , and our application has to be responsive and able to deal with several Internet Protocols , then the STM32F4 portfolio is probably your best option. If you are going to develop a battery-powered device, then you have to look at the STM32L selection.","title":"Select your MCU"},{"location":"posts/stm32/intro/#stm32cubeide","text":"While there are many Integrated Development Environment (IDE) software can be used to develop applications on ARM Cortex-M MCUs, ST has their own free STM32CubeIDE , easy-to-use, fully-featured IDE for STM32 MCUs. STM32CubeIDE is an advanced C/C++ development platform with peripheral configuration , code generation , code navigation , code compilation , programmer and debugger for STM32 microcontrollers and microprocessors. It is based on the Eclipse\u00ae/CDT framework and GCC toolchain for the development, and GDB for the debugging. It allows the integration of the hundreds of existing plugins that complete the features of the Eclipse\u00ae IDE. Download at: https://www.st.com/en/development-tools/stm32cubeide.html STM32CubeIDE is a complete toolchain for ST's STM32 MCUs, you can read more about ARM Toolchain & Makefile .","title":"STM32CubeIDE"},{"location":"posts/stm32/intro/#create-a-new-project","text":"","title":"Create a new project"},{"location":"posts/stm32/intro/#1-start-new-project","text":"It is recommended to start a new project with STM32CudeIDE as it will automatically configure your project for your target MCU. you also can convert other type of projects to STM32CudeIDE project. Sometimes, you have to re-configure settings manually if the IDE cannot do it for you. Welcome screen of STM32CudeIDE","title":"1. Start new project"},{"location":"posts/stm32/intro/#2-choose-the-target-mcu","text":"You can search for your target MCU by using Selectors: MCU/MPU Name, Board, Example, or Customer Filters. Select your target MCU","title":"2. Choose the target MCU"},{"location":"posts/stm32/intro/#3-select-firmware-library-package","text":"You will be able to choose the Targeted Language as C or C++, Binary Type , and the Firmware Package Setup settings for a new project At the beginning level, it is recommended to let STM32CubeIDE initialize all peripherals with their default mode. If you select a discovery board, the IDE will assign pins and generate code based on the settings on your selected boards, such as LEDs, Buttons, and Serial Wire Debug (SWD).","title":"3. Select Firmware Library Package"},{"location":"posts/stm32/intro/#4-configure-target-device","text":"You will be started with Device Configuration Tool which is known as STM32CubeMX to start setting up your MCU with interactive components. The first tab is Pinout & Configuration in which you can select on available modules to configure them. Pinout View is a great view to see the pin assignment for your MCU. you can quickly assign a function to a pin by left click on that pin. There will be a popup with a list of functions which can be assigned. If you right click on the pin, you can assign a readable friendly name for it. Pin assignment If you click on a specific module, there is a detail page for you to config that modules, including Name, Pin, Pin Type, Interrupt, DMA, or any other available settings. GPIO configuration The Clock Configuration show the clock paths across your devices from the clock source to the modules. It also allows you to change the multiplier of clock path to increase or decrease the clock frequency. Clock Configuration In the Project Manager tab, you can change some advanced functions of STM32CubeMX such as the size of Heap and Stack, Code Generation. You should leave them default unless you understand about these settings. Project Manager","title":"4. Configure target device"},{"location":"posts/stm32/intro/#5-generate-code","text":"If you save your project ( Ctrl + S ) in Device Configuration Tool it will automatically generate code for you, based on your settings. you can press Alt + K or choose the menu Project > Generate Code too. When you choose to use a Firmware Library in your project, IDE automatically uses ST Hardware Abstract Layer (HAL) library as the main way of controlling your processor. HAL also makes use of CMSIS library to access processor's registers. Let's an example of using STM32F0 MCU: Code dependency starts from your startup_stm32f0xx.s file. This file include main.h which then includes HAL files which eventually include CMSIS files. The startup file also call to your main function in main.c to run your program. Generated Code Structure #table1 table, #table2 table { table-layout: fixed; } File Description stm32f0xx_hal.h This file is used for HAL initialization and contains DBGMCU, Time Delay based on SysTick APIs. This also include stm32f0xx_hal_def.h stm32f0xx_hal_def.h Common HAL resources such as common define statements, enumerations, structures and macros. This includes CMSIS. headers stm32f0xx_hal_ppp.h/.c Main peripheral/module driver file. It includes the APIs that are common to all STM32 devices. Example: stm32f0xx_hal_adc.c , stm32f0xx_hal_irda.c . stm32f0xx_hal_ppp_ex.h/.c Extension file of the peripheral/module ppp driver. It includes the specific APIs for a given part number or family, as well as the newly defined APIs that overwrite the default generic APIs if the internal process is implemented in different way. Example: stm32f0xx_hal_adc_ex.c , stm32f0xx_hal_flash_ex.c . The minimum files required to build an application using the HAL are listed in the table below: File Description startup_stm32f0xx.s Toolchain specific file that contains reset handler and exception vectors. For some toolchains, it allows adapting the stack/heap size to fit the application requirements system_stm32f0xx.c This file contains SystemInit() which is called at startup just after reset and before branching to the main program. It does not configure the system clock at startup (contrary to the standard library). This is to be done using the HAL APIs in the user files. It allows relocating the vector table in internal SRAM. stm32f0xx_hal_conf.h This file allows the user to customize the HAL drivers for a specific application. It is not mandatory to modify this configuration. The application can use the default configuration without any modification. This call to STM32F0 HAL headers. stm32f0xx_hal_msp.c This file contains the MSP initialization and de-initialization (main routine and callbacks) of the peripheral used in the user application. stm32f0xx_it.h/.c This file contains the exceptions handler and peripherals interrupt service routine, and calls HAL_IncTick() at regular time intervals to increment a local variable (declared in stm32f0xx_hal.c ) used as HAL timebase. By default, this function is called each 1ms in SysTick ISR. The PPP_IRQHandler() routine must call HAL_PPP_IRQHandler() if an interrupt based process is used within the application. main.h/.c This file contains the main program routine, mainly: \u2022 Call to HAL_Init() \u2022 assert_failed() implementation \u2022 system clock configuration \u2022 peripheral HAL initialization and user application code.","title":"5. Generate Code"},{"location":"posts/stm32/intro/#6-write-your-code","text":"The generayed code has some block marked with pairs of comments /* USER CODE BEGIN */ and /* USER CODE END */ . Inside those pairs, you can write your code and they will be untouched by STM32CubeMX when it it re-generates new code. For example: main.c /* Private includes */ /* USER CODE BEGIN Includes */ < YOUR CODE HERE > #include <stdio.h> /* USER CODE END Includes */ /* Private define */ /* USER CODE BEGIN PD */ < YOUR CODE HERE > #define SECRET_NUMBER 0x12345678 /* USER CODE END PD */ /* Private variables */ /* USER CODE BEGIN PV */ < YOUR CODE HERE > uint8_t key = 0xFF ; /* USER CODE END PV */ int main ( void ) { HAL_Init (); SystemClock_Config (); MX_GPIO_Init (); /* Infinite loop */ /* USER CODE BEGIN WHILE */ < YOUR CODE HERE > HAL_GPIO_WritePin ( Green_Led_GPIO_Port , Green_Led_Pin , GPIO_PIN_SET ); while ( 1 ) { < YOUR CODE HERE > HAL_GPIO_TogglePin ( Blue_Led_GPIO_Port , Blue_Led_Pin ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ < YOUR CODE HERE > } /* USER CODE END 3 */ }","title":"6. Write your code"},{"location":"posts/stm32/intro/#7-run-on-board","text":"First, you must compile your code by press Ctrl + B , or menu Project > Build Project Memory report after compilation Then after you connect the cable from your board to your computer, press F11 or Run > Debug to download your code to board and start debugging session. Your application will paused at the main() function by default. Press F8 to Resume .","title":"7. Run on board"},{"location":"posts/stm32/intro/#related-documents","text":"In embedded programming, documents have a very important role as they are the main reference source for developer to know how the processor works and how to configure it. Those documents mainly come from the processor manufacture, it means you can download it from the manufacture website. STM32CudeIDE has a better way to list all related documents of selected processor, and it can download documents for you. you can find the documents in menu Help > Target device docs and resources . Open documents browser Related documents for selected STM32F051R8 MCUs Here is the list of important documents you have to read in order to understand about the processor and its peripherals: Example documents are for STM32F051 MCUs.","title":"Related documents"},{"location":"posts/stm32/intro/#board-manual--schematic","text":"UM1525 - Discovery kit for STM32F0 microcontrollers https://my.st.com/resource/en/user_manual/dm00050135-stm32f0discovery-discovery-kit-for-stm32-f0-microcontrollers-stmicroelectronics.pdf Main content includes: Hardware components and their locations and markers Pinouts and jumpers for connections or configurations Solder Bridges for enabling/disabling features or hardware connections MB1034 RevB.0 - STM32F0-DISCOVERY Schematic https://my.st.com/resource/en/schematic_pack/stm32f0discovery_sch.zip This document show the wires between all hardware components. Reading this document can help to understand: Input and Output characteristics (Pull-up, Pull-down, Open, Voltage level) Connection points (internal wires, connectors) Working conditions (Power level, Voltage Level torelance)","title":"Board Manual &amp; Schematic"},{"location":"posts/stm32/intro/#processor-datasheet","text":"PM0215 - STM32F0xxx Cortex-M0 programming manual https://my.st.com/resource/en/programming_manual/dm00051352-stm32f0xxx-cortexm0-programming-manual-stmicroelectronics.pdf The main content is: Processor modes: in application and interruption routine Stacks: manage context's data Core Registers: contain instruction's data and result, system status Memory Model: fixed memory map with address ranges Vector Table: start address, stack pointer, and interruption handlers Sleep mode: condition about clock, data rate, register mode Instruction set: assembly mnemonic for instructions Core registers: Address and Name of registers used in core and peripherals. This is the based for progamming the processor. It also have API function name for accessing the registers using CMSIS. DS8668 - STM32F051x4/6/8 Datasheet https://www.st.com/resource/en/datasheet/stm32f051r8.pdf This document shows below information: Functional features Memory Mapping, Boot Mode Pinouts and alternative functions Core and Peripherals' diagrams, protocols RM0091 - Reference manual for STM32F0x1/STM32F0x2/STM32F0x8 advanced ARM-based 32-bit MCUs https://www.st.com/resource/en/reference_manual/dm00031936-stm32f0x1stm32f0x2stm32f0x8-advanced-armbased-32bit-mcus-stmicroelectronics.pdf This is a very important document as it defines all register structure, bit-fields to control core and peripherals . This document includes: System Architecture, Register-Level designs Memory Mapping and Boot configuration Register name and bit-fields for all accessible registers","title":"Processor Datasheet"},{"location":"posts/stm32/intro/#library-manual","text":"UM1785 - Description of STM32F0 HAL and low-layer drivers https://www.st.com/resource/en/user_manual/dm00122015-description-of-stm32f0-hal-and-lowlayer-drivers-stmicroelectronics.pdf This document describes HAL and LL APIs for programming. Those functions wrap all internal registers and settings, and create a friendly function names and data structure for developer. The HAL drivers include a set of driver modules, each module being linked to a standalone peripheral. The HAL main features are the following: Cross-family portable set of APIs covering the common peripheral features as well as extension APIs in case of specific peripheral features. Three API programming models: polling, interrupt and DMA. APIs are RTOS compliant: Fully reentrant APIs Systematic usage of timeouts in polling mode Support of peripheral multi-instance allowing concurrent API calls for multiple instances of a given peripheral (USART1, USART2...) All HAL APIs implement user-callback functions mechanism: Peripheral Init/DeInit HAL APIs can call user-callback functions to perform peripheral system level. Initialization/De-Initialization (clock, GPIOs, interrupt, DMA) Peripherals interrupt events Error events Object locking mechanism: safe hardware access to prevent multiple spurious accesses to shared resources Timeout used for all blocking processes: the timeout can be a simple counter or a timebase UM1722 - Developing applications on STM32Cube with RTOS https://www.st.com/resource/en/user_manual/dm00105262-developing-applications-on-stm32cube-with-rtos-stmicroelectronics.pdf This document is a reference to program user application in RTOS. This document has below content: FreeRTOS: overview, APIs, memory management, low power managements, and configuration CMSIS-RTOS: a higher layer to communicate between CMSIS and FreeRTOS Usage to create thread, use Semaphore, Queues, and Timer CMSIS - Cortex Microcontroller Software Interface Standard https://developer.arm.com/tools-and-software/embedded/cmsis https://developer.arm.com/embedded/cmsis/cmsis-packs/devices/STMicroelectronics/STM32F051R8 ARM develops the Cortex Microcontroller Software Interface Standard (CMSIS) to allow microcontroller and software vendor to use a consistent software infrastructure to develop software solutions for Cortex-M microcontroller. It is a set of APIs for application or middleware developers to access the features on the Cortex-M processor regardless of the microcontroller devices or toolchain used. To use the CMSIS-Core (Cortex-M) the following files are added to the embedded application: Startup File startup_<device>.c with reset handler and exception vectors. System Configuration Files system_<device>.c and system_<device>.h with general device configuration (i.e. for clock and BUS setup). Device Header File <device.h> gives access to processor core and all peripherals. Register names and bit-fields are defined in the Reference Manual of the process","title":"Library Manual"},{"location":"posts/stm32/intro/#conclusion","text":"By reading to this point, I hope you can get an overview of what STM32 MCUs are, how to run a simple project with STM32CubeIDE, and where to find more information about your target MCUs.","title":"Conclusion"},{"location":"posts/stm32/semihost/","text":"Semihosting is a mechanism that allows target boards to \"exchange messages\" from the embedded firmware to a host computer running a debugger attached to it. This mechanism enables some functions in the C library, such as printf() and scanf() , to use the screen and keyboard of the host instead of having a screen and keyboard on the target system. Semihosting is implemented by a set of defined software instructions, for example, SVCs , that generate exceptions from program control. The application invokes the appropriate semihosting call and the debug agent then handles the exception. The debug agent provides the required communication with the host. Semihost overview The semihosting interface is common across all debug agents provided by ARM. Semihosted operations only work when the target board is under debugging session and connected to semihosting-enabled development platform. ARM processors prior to ARMv7 use the SVC instructions, formerly known as SWI instructions, to make semihosting calls. However, if you are compiling for an ARMv6-M or ARMv7-M, for example a Cortex-M1 or Cortex-M3 processor, semihosting is implemented using the BKPT instruction. Semihosting is resource intensive and very slow. However, every ARM controller should have semihosting available, which can be a lifesaver if that\u2019s all you have. Application or interrupt code will NOT run while semihosting transfers are active, so you can miss interrupts. The easiest method to use semihosting is to compile your application with --specs=rdimon.specs and rdimon library which already implements instructions to handle semihosting functional calls. rdimon rdimon library implements interrupt for some special system calls, which pause the processor and interract with debugger host to exchange data, such as SYS_WRITE (0x05) or SYS_READ (0x06) . Linker settings \u2693\ufe0e Start a new project if needed! Firstly, you should check which libraries are linked to you program. Open Project > Properties to show the Properties dialog, go to C/C++ Build > Settings , then select Tool Settings tab, then MCU GCC Linker . By default, STM32CubeIDE will compile your project with --specs=nano.specs and --specs=nosys.specs . Library: newlib and newlib-nano \u2693\ufe0e There are several implementations of the C Standard Library, and Newlib is an implementation targeted at bare-metal embedded systems that is maintained by RedHat . It has become the standard in embedded software because it is complete, has optimizations for a wide range of architectures, and produces relatively small code. Newlib is enabled by default when you build a project with arm-none-eabi-gcc . However, the toolchain is released with two prebuilt C libraries based on newlib: The standard newlib , included by default The optimized for code size newlib-nano , included when you use an additional liker option --specs=nano.specs . Formatted input/output of floating-point number are implemented as weak symbol in newlib-nano . If you want to use %f , you have to pull in the symbol by explicitly specifying -u _printf_float and -u _scanf_float command options Library: nosys and rdimon \u2693\ufe0e NewLib maps standard C functions to a specific implementation environment through a chain of functions for example: application uses printf() which calls write() system function write() invokes _write_r() with the current re-entrancy context (e.g. thread/task-unique errno); _write_r() invokes _write() and copies errno appropriately; _write() must be provided by something to finally write out data If nothing provides an implementation of _write() but the application requires one, the application will fail to link. The standard solution for newlib is to add -specs=nosys.specs to the gcc linker command line. This links in a separate library with implementations for all required system functions. Most of them simply return an error; some (like _sbrk() ) provide a usable definition. When enabling rdimon , this library already implements all required system functions in which it interacts with debugger to exchange messages. Therefore, you can remove nosys.specs when you use rdimon . In addition, STM32CubeIDE automatically generates syscalls.c with a simple implementation for nosys.specs . you must exclude syscalls.c from build to avoid compilation error of duplicated function definition . GCC Linker settings Here are steps to enable semihost in linker: In MCU GCC Linker > Libraries menu, add rdimon into Libraries (-l) options In MCU GCC Linker > Miscellaneous menu, add --specs=rdimon.specs into Other Flags options (Optional) In MCU GCC Linker > General menu, choose Do not use system call from library in System Calls options. Finally, you must exclude syscalls.c from build script by right click on that file and choose Properties , check on Exclude resource from build option. Steps to enable semihost Debugger settings \u2693\ufe0e Another side that makes semihost work is Debugger. As mentioned above, semihost on firmware will call to function in debugger to run funcationalities of exchanging message, therefore, you need a debugger that supports semihosting functions. Open Debug Configuration window from Run menu In tab Debugger , set Debug Probe to ST-LINK OpenOCD , and click on Show generator options and choose Reset Mode to Software system reset In tab Startup , add monitor arm semihosting enable into Initialization Commands options. Setup debugger for semihost Code settings \u2693\ufe0e Before you can use semihosting functions, you must enable it. In the main.c file, add reference to the function initialise_monitor_handles () and call that function at the begining of the main () function. Now, you should write some simple code to see how semihost works. It can be printing a counting up counter as below example code. main.c /* USER CODE BEGIN PFP */ extern void initialise_monitor_handles ( void ); /* USER CODE END PFP */ int main ( void ) { /* USER CODE BEGIN 1 */ uint8_t counter = 0 ; // init semihost initialise_monitor_handles (); /* USER CODE END 1 */ /* Infinite loop */ /* USER CODE BEGIN WHILE */ while ( 1 ) { printf ( \"counter=%d \\n \" , counter ++ ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */ Build and Debug \u2693\ufe0e Compile your project and start a debug session by pressing F11 , your program will start to and pause at main function. Press F8 to resume the program and check the output in debug console. Output from semihosting Semihost and newline character Output on debugger is buffered, that means prinf() only pushes character to semihost debug console when it reaches the newline character \\n . Be ware to add newline characters! You can use scanf() to get user input too. Let's write some code: main.c /* USER CODE BEGIN PFP */ extern void initialise_monitor_handles ( void ); /* USER CODE END PFP */ int main ( void ) { /* USER CODE BEGIN 1 */ uint8_t counter = 0 ; // init semihost initialise_monitor_handles (); /* USER CODE END 1 */ /* Infinite loop */ /* USER CODE BEGIN WHILE */ printf ( \"Please enter your name: \\n \" ); scanf ( \"%s\" , buffer ); printf ( \" \\n Ah, I know you, %s! \\n \" , buffer ); while ( 1 ) { printf ( \"counter=%d \\n \" , counter ++ ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */ Using scanf() with semihost Note \u2693\ufe0e Applications built with semihosting output active normally cannot be executed without the debugger connected and active, since they use BKPT to communicate with the host. However, with a carefully written HardFault_Handler() , the semihosting BKPT calls can be processed, making possible to run semihosting applications as standalone, without being terminated with hardware faults.","title":"Semihosting on ARM MCUs"},{"location":"posts/stm32/semihost/#linker-settings","text":"Start a new project if needed! Firstly, you should check which libraries are linked to you program. Open Project > Properties to show the Properties dialog, go to C/C++ Build > Settings , then select Tool Settings tab, then MCU GCC Linker . By default, STM32CubeIDE will compile your project with --specs=nano.specs and --specs=nosys.specs .","title":"Linker settings"},{"location":"posts/stm32/semihost/#library-newlib-and-newlib-nano","text":"There are several implementations of the C Standard Library, and Newlib is an implementation targeted at bare-metal embedded systems that is maintained by RedHat . It has become the standard in embedded software because it is complete, has optimizations for a wide range of architectures, and produces relatively small code. Newlib is enabled by default when you build a project with arm-none-eabi-gcc . However, the toolchain is released with two prebuilt C libraries based on newlib: The standard newlib , included by default The optimized for code size newlib-nano , included when you use an additional liker option --specs=nano.specs . Formatted input/output of floating-point number are implemented as weak symbol in newlib-nano . If you want to use %f , you have to pull in the symbol by explicitly specifying -u _printf_float and -u _scanf_float command options","title":"Library: newlib and newlib-nano"},{"location":"posts/stm32/semihost/#library-nosys-and-rdimon","text":"NewLib maps standard C functions to a specific implementation environment through a chain of functions for example: application uses printf() which calls write() system function write() invokes _write_r() with the current re-entrancy context (e.g. thread/task-unique errno); _write_r() invokes _write() and copies errno appropriately; _write() must be provided by something to finally write out data If nothing provides an implementation of _write() but the application requires one, the application will fail to link. The standard solution for newlib is to add -specs=nosys.specs to the gcc linker command line. This links in a separate library with implementations for all required system functions. Most of them simply return an error; some (like _sbrk() ) provide a usable definition. When enabling rdimon , this library already implements all required system functions in which it interacts with debugger to exchange messages. Therefore, you can remove nosys.specs when you use rdimon . In addition, STM32CubeIDE automatically generates syscalls.c with a simple implementation for nosys.specs . you must exclude syscalls.c from build to avoid compilation error of duplicated function definition . GCC Linker settings Here are steps to enable semihost in linker: In MCU GCC Linker > Libraries menu, add rdimon into Libraries (-l) options In MCU GCC Linker > Miscellaneous menu, add --specs=rdimon.specs into Other Flags options (Optional) In MCU GCC Linker > General menu, choose Do not use system call from library in System Calls options. Finally, you must exclude syscalls.c from build script by right click on that file and choose Properties , check on Exclude resource from build option. Steps to enable semihost","title":"Library: nosys and rdimon"},{"location":"posts/stm32/semihost/#debugger-settings","text":"Another side that makes semihost work is Debugger. As mentioned above, semihost on firmware will call to function in debugger to run funcationalities of exchanging message, therefore, you need a debugger that supports semihosting functions. Open Debug Configuration window from Run menu In tab Debugger , set Debug Probe to ST-LINK OpenOCD , and click on Show generator options and choose Reset Mode to Software system reset In tab Startup , add monitor arm semihosting enable into Initialization Commands options. Setup debugger for semihost","title":"Debugger settings"},{"location":"posts/stm32/semihost/#code-settings","text":"Before you can use semihosting functions, you must enable it. In the main.c file, add reference to the function initialise_monitor_handles () and call that function at the begining of the main () function. Now, you should write some simple code to see how semihost works. It can be printing a counting up counter as below example code. main.c /* USER CODE BEGIN PFP */ extern void initialise_monitor_handles ( void ); /* USER CODE END PFP */ int main ( void ) { /* USER CODE BEGIN 1 */ uint8_t counter = 0 ; // init semihost initialise_monitor_handles (); /* USER CODE END 1 */ /* Infinite loop */ /* USER CODE BEGIN WHILE */ while ( 1 ) { printf ( \"counter=%d \\n \" , counter ++ ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */","title":"Code settings"},{"location":"posts/stm32/semihost/#build-and-debug","text":"Compile your project and start a debug session by pressing F11 , your program will start to and pause at main function. Press F8 to resume the program and check the output in debug console. Output from semihosting Semihost and newline character Output on debugger is buffered, that means prinf() only pushes character to semihost debug console when it reaches the newline character \\n . Be ware to add newline characters! You can use scanf() to get user input too. Let's write some code: main.c /* USER CODE BEGIN PFP */ extern void initialise_monitor_handles ( void ); /* USER CODE END PFP */ int main ( void ) { /* USER CODE BEGIN 1 */ uint8_t counter = 0 ; // init semihost initialise_monitor_handles (); /* USER CODE END 1 */ /* Infinite loop */ /* USER CODE BEGIN WHILE */ printf ( \"Please enter your name: \\n \" ); scanf ( \"%s\" , buffer ); printf ( \" \\n Ah, I know you, %s! \\n \" , buffer ); while ( 1 ) { printf ( \"counter=%d \\n \" , counter ++ ); HAL_Delay ( 1000 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */ Using scanf() with semihost","title":"Build and Debug"},{"location":"posts/stm32/semihost/#note","text":"Applications built with semihosting output active normally cannot be executed without the debugger connected and active, since they use BKPT to communicate with the host. However, with a carefully written HardFault_Handler() , the semihosting BKPT calls can be processed, making possible to run semihosting applications as standalone, without being terminated with hardware faults.","title":"Note"},{"location":"posts/stm32/toolchain/","text":"Toolchain \u2693\ufe0e Before you can start developing applications for the STM32 MCUs, you need a complete toolchain. A toolchain is a set of programs, compilers, and tools that allows you: to write down your code and to navigate inside source files of your application; to navigate inside the application code, allowing you to inspect variables, function definitions/declarations, and so on; to compile the source code using a cross-platform compiler; to upload and debug your application on the target board Example of a toolchain In the post Introduction to STM32 MCUs , you are guided to install STM32CubeIDE which actually is a complete toolchain for ST's STM32 MCUs. STM32CubeMX is used for Device Configuration and Code Generation Eclipse IDE is an source code editor and manager which supports many plugins in which we use C/C++ Development Platform, GCC Cross Compiler, GDB Hardware Debugger, Make and build script GNU ARM Cross-compiler with ST patch for STM32 MCUs compiles our code to executable and linkable file (.elf) or binary file (.bin, .hex) STM32 Cube Programmer downloads our .elf or .bin file to the target MCU's flash ST-LINK GDB or ST-LINK openOCD debugger to probe our target MCUs What Is a Cross-Compiler? You usually refer to term compiler as a tool able to generate machine code for the processor in our PC. A compiler is just a \u201clanguage translator\u201d from a given programming language (C in our case) to a low-level machine language, also known as assembly . For example, if you are working on Intel x86 machine, you use a compiler to generate x86 assembly code from the C programming language. For the sake of completeness, you have to say that nowadays a compiler is a more complex tool that addresses both the specific target hardware processor and the Operating System you are using (e.g. Windows 7). A cross-platform compiler is a compiler able to generate machine code for a hardware machine different from the one you are using to develop our applications. In our a case, the GCC ARM Embedded compiler generates machine code for Cortex-M processors while compiling on an x86 machine with a given OS (e.g. Windows or Mac OSX). Example of Cross-Compiler for MIPS on Linux GNU ARM Embedded Toolchain \u2693\ufe0e In this section, you will know how to install a general GNU ARM Toolchain for Windows machines and use it to compile a simple program for STM32 MCUs. Download the latest GNU ARM Embedded Toolchain from the official ARM site, such as gcc-arm-none-eabi-9-2020-q2-update-win32.exe and start to install. Please note that we must select GNU-RM version for ARM Cortext-M processors. Install GNU ARM Toolchain You should add GNU into the system PATH to use GCC tools directly in terminal without the need of changing the current working directory to the GNU installation folder. To test GNU CC for ARM, you can try to compile a simple program in C: main.c void main ( void ) { }","title":"ARM Toolchain & Makefile"},{"location":"posts/stm32/toolchain/#toolchain","text":"Before you can start developing applications for the STM32 MCUs, you need a complete toolchain. A toolchain is a set of programs, compilers, and tools that allows you: to write down your code and to navigate inside source files of your application; to navigate inside the application code, allowing you to inspect variables, function definitions/declarations, and so on; to compile the source code using a cross-platform compiler; to upload and debug your application on the target board Example of a toolchain In the post Introduction to STM32 MCUs , you are guided to install STM32CubeIDE which actually is a complete toolchain for ST's STM32 MCUs. STM32CubeMX is used for Device Configuration and Code Generation Eclipse IDE is an source code editor and manager which supports many plugins in which we use C/C++ Development Platform, GCC Cross Compiler, GDB Hardware Debugger, Make and build script GNU ARM Cross-compiler with ST patch for STM32 MCUs compiles our code to executable and linkable file (.elf) or binary file (.bin, .hex) STM32 Cube Programmer downloads our .elf or .bin file to the target MCU's flash ST-LINK GDB or ST-LINK openOCD debugger to probe our target MCUs What Is a Cross-Compiler? You usually refer to term compiler as a tool able to generate machine code for the processor in our PC. A compiler is just a \u201clanguage translator\u201d from a given programming language (C in our case) to a low-level machine language, also known as assembly . For example, if you are working on Intel x86 machine, you use a compiler to generate x86 assembly code from the C programming language. For the sake of completeness, you have to say that nowadays a compiler is a more complex tool that addresses both the specific target hardware processor and the Operating System you are using (e.g. Windows 7). A cross-platform compiler is a compiler able to generate machine code for a hardware machine different from the one you are using to develop our applications. In our a case, the GCC ARM Embedded compiler generates machine code for Cortex-M processors while compiling on an x86 machine with a given OS (e.g. Windows or Mac OSX). Example of Cross-Compiler for MIPS on Linux","title":"Toolchain"},{"location":"posts/stm32/toolchain/#gnu-arm-embedded-toolchain","text":"In this section, you will know how to install a general GNU ARM Toolchain for Windows machines and use it to compile a simple program for STM32 MCUs. Download the latest GNU ARM Embedded Toolchain from the official ARM site, such as gcc-arm-none-eabi-9-2020-q2-update-win32.exe and start to install. Please note that we must select GNU-RM version for ARM Cortext-M processors. Install GNU ARM Toolchain You should add GNU into the system PATH to use GCC tools directly in terminal without the need of changing the current working directory to the GNU installation folder. To test GNU CC for ARM, you can try to compile a simple program in C: main.c void main ( void ) { }","title":"GNU ARM Embedded Toolchain"}]}